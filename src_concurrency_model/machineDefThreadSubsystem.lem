(*========================================================================================*)
(*                                                                                        *)
(*                rmem executable model                                                   *)
(*                =====================                                                   *)
(*                                                                                        *)
(*  This file is:                                                                         *)
(*                                                                                        *)
(*  Copyright Shaked Flur, University of Cambridge                            2014-2018   *)
(*  Copyright Peter Sewell, University of Cambridge                           2014-2017   *)
(*  Copyright Christopher Pulte, University of Cambridge                      2015-2018   *)
(*  Copyright Robert Norton-Wright, University of Cambridge                   2016-2017   *)
(*  Copyright Susmit Sarkar, University of St Andrews                              2014   *)
(*  Copyright Kathy Gray, University of Cambridge (when this work was done)   2014-2017   *)
(*  Copyright Jon French, University of Cambridge                             2016-2017   *)
(*  Copyright Linden Ralph, University of Cambridge (when this work was done)      2017   *)
(*  Copyright Ohad Kammar, University of Cambridge (when this work was done)  2013-2014   *)
(*                                                                                        *)
(*  All rights reserved.                                                                  *)
(*                                                                                        *)
(*  It is part of the rmem tool, distributed under the 2-clause BSD licence in            *)
(*  LICENCE.txt.                                                                          *)
(*                                                                                        *)
(*========================================================================================*)

(* emacs fontification -*-caml-*- *)

open import Pervasives_extra
open import Sail_impl_base
open import Utils
open import Fragments
open import FreshIds
open import ExceptionTypes
open import Events
open import Debug
open import Params
open import InstructionSemantics
open import Isa
open import RegUtils
open import InstructionKindPredicates
open import MachineDefThreadSubsystemUtils
open import MachineDefTypes
open ListMonad

(* SF: ???? *)
(* NEWTODO: the old machineDefInstructionSemantics.write_possibly_done_by
checks that "w (a write-read-from by some read) is by thread tid and
has the same address and value as some write in the behaviour s".  Why
do we do that instead of checking identity of writes?  Here I do that,
and also note that I'm only looking at the pending events - is that
right?  Shaked says that it has to be the former way*)


(** Initial thread state ********************************************)

let init_pldi11_thread_substate = <| unacknowledged_syncs = {}; |>
let init_pop_thread_substate = <| read_issuing_order = relonEmpty; |>

let initial_thread_state
    (params:         thread_params)
    (tid :           thread_id)
    (return_address: address)
    (rd:             registerdata)
    (irv:            reg_base_name -> register_value)
    (initial_fetch:  maybe address)
  =
  <| thread                     = tid;
     id_state                   = FreshIds.initial_id_state tid;
     return_address             = return_address;
     register_data              = rd;
     initial_register_state     = irv;
     initial_fetch_address      = initial_fetch;
     old_instructions           = [];
     instruction_tree           = T [];

     thread_substate =
        match params.thread_model with
        | PLDI11_thread_model    -> PLDI11_thread init_pldi11_thread_substate
        | POP_thread_model _     -> POP_thread init_pop_thread_substate
        | TSO_thread_model       -> No_substate
        | Promising_thread_model -> fail
        | Relaxed_thread_model   -> No_substate
        end;
  |>

(********************************************************************)
(* record things that might affect (over-approximate) the value being
written to the register *)
let current_reg_write_dependencies
    (instruction: instruction_instance 'i)
    : list register_write_dependency
  =
  let reg_deps =
    instruction.reg_reads >>= fun (reg_name, register_read_sources, _) ->
    register_read_sources >>= function
    (* for each reg_name and each of its register_read_sources .. *)
    | RRS_instruction ioid reg_names _ -> [(RWD_reg_write ioid reg_names)]
    | RRS_initial_state _              -> []
    | RRS_pseudoregister               -> []
    end
  in
  match instruction.subreads.sr_assembled_value with
  | Nothing -> reg_deps
  | Just _  -> RWD_mem_read :: reg_deps
  end

(* iic_prefix is active_prefix ++ old_prefix *)
let paired_atomic_load_aux
      (iic_instance : instruction_instance 'i)
      prefix : maybe (instruction_instance 'i) =
  if is_memory_rmw (ik iic_instance) then Just iic_instance 
  else
    (* let prefix = iic.active_prefix ++ iic.old_prefix in *)
    let atomic i = (is_atomic_load i || is_atomic_store i) && not (is_memory_rmw i) in
    Maybe.bind (List.find (fun i -> atomic (ik i)) prefix) $ fun inst ->
    if is_atomic_load (ik inst) then Just inst else Nothing

let paired_atomic_load (iic: instruction_in_context 'i) : maybe (instruction_instance 'i) =
  paired_atomic_load_aux
    iic.iic_instance
    (iic.active_prefix ++ iic.old_prefix)


let rec paired_atomic_stores_helper (T its: instruction_tree 'i) : list (instruction_instance 'i) =
  its >>= fun (i, it) ->
  if is_atomic_load (ik i) && not (is_memory_rmw (ik i)) then []
  else if is_atomic_store (ik i) && not (is_memory_rmw (ik i)) then [i]
  else paired_atomic_stores_helper it

let rec paired_atomic_stores (i: instruction_instance 'i) (it: instruction_tree 'i)
        : list (instruction_instance 'i) =
  if is_memory_rmw (ik i) then [i]
  else paired_atomic_stores_helper it

(* registers_final_state: find the registers state when thread has reached its
   final state.
   NOTE: 'state' might be a deadlock state, hence we find a registers snapshot
   for each path in the tree and join them together (register with multiple
   values is mapped to Nothing) *)
let registers_final_state (state: thread_state 'i) : list (reg_base_name * maybe register_value) =
  (* get a register snapshot for each path in the instructions tree *)
  let reg_states =
    instruction_tree_fold_root
      (fun acc _ i _ -> i :: acc)
      state.old_instructions [] state.instruction_tree
    $> Set.map (find_register_snapshot state.register_data state.initial_register_state)
  in

  if Set.size reg_states = 0 then
    (* there must be at least one path in the tree *)
    fail
  else if Set.size reg_states = 1 then
    Set_extra.choose reg_states
  else
    (* merge all the snapshots into one *)
    let (s, reg_states') =
      let s = Set_extra.choose reg_states in
      (s, reg_states \ {s})
    in
    List.map
      (fun (rbn, v) ->
        if forall (s' IN reg_states'). List.lookup rbn s' = Just v then
          (* rbn is mapped to the same value in all snapshots *)
          (rbn, v)
        else
          (rbn, Nothing))
      s

(** Instruction instance predicates *)

(* A failed store-conditional/exclusive is not considered a memory access after it is finished *)
let is_viable_memory_store_ii (i: instruction_instance 'i) : bool =
  is_memory_store_instruction (ik i) &&
  not (i.successful_atomic_store = Just false && i.finished)

let is_viable_memory_access_ii (i: instruction_instance 'i) : bool =
  is_memory_load_instruction (ik i) || is_viable_memory_store_ii i

let is_cond_branch_ii (i: instruction_instance 'i) : bool =
  Set.size i.nias > 1

let is_indirect_branch_ii (i: instruction_instance 'i) : bool =
  exists (nia IN i.nias). nia = NIA_indirect_address



(** Possible Reads and Writes of Instruction ************************)

(* Return Nothing if the read footprint is not determined yet, or Just
   applied to the set of read addresses otherwise. If the memory read
   has already been requested then this information is in the
   micro-op-state; if not, the footprint is only determined if the
   instruction has a Mem_read outcome in the next state. (This depends
   on the fact that the only register in the Sail code for loads is
   for determining the data, after that the read can go ahead. *)
let read_footprint_of_load instruction : maybe footprint =
  match instruction.subreads.sr_addr with
  | Just fp -> Just fp
  | Nothing ->
      match instruction.micro_op_state with
      | MOS_plain (Read_mem ((read_kind: read_kind),(addr_lifted: address_lifted),(size: nat)) _,_) ->
          let addr = ensure_just (address_of_address_lifted addr_lifted) "read_footprint_of_load: bad address" in
          Just (addr, size)
      | _ ->  Nothing
      end
  end


let possibly_reads_address
    (instruction: instruction_instance 'i)
    (fps:         set footprint)
    : bool
  =
  is_memory_load_instruction (ik instruction) &&
  match read_footprint_of_load instruction with
  | Just fp -> non_empty_intersection_set fps {fp}
  | Nothing -> exists ((_, s) IN fps). s <> 0
  end


let possibly_writes_address
    (instruction: instruction_instance 'i)
    (fps:         set footprint)
    : bool
  =
  is_viable_memory_store_ii instruction &&
  match instruction.subwrites.sw_addr with
  | Just fp -> non_empty_intersection_set fps {fp}
  | Nothing -> exists ((_, s) IN fps). s <> 0
  end


(* Return 'true' iff 'instruction' might read or write from/to a footprint
intersecting with 'fps'. In particular, return 'true' if the footprint of
'instruction' can't be determined.
NOTE: we check the instruction in its current state, i.e., if the
pseudocode has not made enough steps yet to make the reads/writes avilable
the function returns 'true' for any (non-empty) 'fps', and we don't consider
what can happen if the instruction is restarted. *)
let possibly_reads_or_writes_address
    (inst: instruction_instance 'i)
    (fps:  set footprint)
    : bool
  =
  possibly_reads_address inst fps || possibly_writes_address inst fps

(* return true iff the sail code has already generated its memory-read event for
   the instruction. This guarantees that the instruction's memory read is
   recorded in the instruction_instance state. *)
let all_reads_are_calculated inst : bool =
  is_memory_load_instruction (ik inst) --> read_initiated inst

let all_writes_are_calculated inst : bool =
  is_viable_memory_store_ii inst --> write_initiated inst

(* return true iff the sail code has already generated all the memory-read/write
   events (except AArch64 write-mem-value, i.e., E_write_memv) for the
   instruction. This guarantees that any memory read/write footprint of the
   instruction is recorded in the instruction_instance state. *)
let all_writes_reads_are_calculated inst : bool =
  (* for efficiency, first check if 'inst' is unfinished *)
  inst.finished ||
  (all_reads_are_calculated inst && all_writes_are_calculated inst)

let is_entirely_satisfied_load (i: instruction_instance 'i) : bool =
  all_reads_are_calculated i && read_satisfied i

let finished_load_part inst : bool =
  inst.finished || inst.rmw_finished_load_snapshot <> Nothing





(** Instruction restart machinery ***********************************)

(* When a store is finished, POP needs to know if po-previous reads
to the same address might be restarted. We try to share as much code
as possible between the functions that do restarts and the function
that determines if a po-previous read might be restarted. *)


(* calculate the set of instructions in the tree 'it' that should be
restarted if 'roots' (presumed within 'it') are restarted *)
let dependent_suffix_to_restart
    (roots: set ioid)
    (it:    instruction_tree 'i)
    : set ioid
  =
  let restart_fold
      (restarts: set ioid)
      (prefix:   list (instruction_instance 'i))
      (inst:     instruction_instance 'i)
      (_:        instruction_tree 'i)
      : set ioid
    =
    let register_dependent = fun () ->
      undetermined_reg_writes_read_from prefix inst.reg_reads
      $> Set.intersection restarts
      $> Set.null
      $> not
    in

    let forward_dependent = fun () ->
      exists ((write, _) MEM (writes_read_from inst)).
        write.w_ioid IN restarts
    in

    let after_load_acquire = fun () ->
      is_memory_load_instruction (ik inst) &&
      exists (prev_inst MEM prefix).
        (is_AArch64_load_acquire (ik prev_inst) || is_RISCV_load_acquire (ik prev_inst))
        && not (finished_load_part prev_inst)
        && prev_inst.instance_ioid IN restarts
    in

    let after_RISCV_fence_sr = fun () ->
      is_memory_load_instruction (ik inst) &&
      exists_iprev_with_prefix prefix $ fun prev_inst prev_active_prefix ->
        is_RISCV_fence_sr (ik prev_inst)
        && is_RISCV_fence_pr (ik prev_inst)
        && not (is_RISCV_fence_pw (ik prev_inst))
        && not prev_inst.finished
        && exists (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
            && not (finished_load_part prev_prev_inst)
            && prev_prev_inst.instance_ioid IN restarts
    in

    let after_RISCV_fence_tso = fun () ->
      is_memory_load_instruction (ik inst) &&
      exists_iprev_with_prefix prefix $ fun prev_inst prev_active_prefix ->
        is_RISCV_fence_tso (ik prev_inst)
        && not prev_inst.finished
        && exists (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
            && not (finished_load_part prev_prev_inst)
            && prev_prev_inst.instance_ioid IN restarts
    in

    if inst.instance_ioid IN roots
        || register_dependent ()
        || forward_dependent ()
        || after_load_acquire ()
        || after_RISCV_fence_sr ()
        || after_RISCV_fence_tso ()
    then {inst.instance_ioid} union restarts
    else restarts
  in

  instruction_tree_fold_root restart_fold {} [] it
  $> bigunion

(* return a pair, the instruction tree after restarting 'irestart_roots' and
their dependants, and the set of instructions that were restarted.
NOTE: 'irestart_roots' must all be in 'it' *)
let restart_dependent_subtrees
    (it:             instruction_tree 'i)
    (irestart_roots: set (instruction_instance 'i))
    : instruction_tree 'i * set ioid
  =
  (* calculate the instructions to restart *)
  let irestarts = dependent_suffix_to_restart {i.instance_ioid | forall (i IN irestart_roots) | true} it in
  (* restart them *)
  let it' =
    instruction_tree_map
      (fun _ i _ -> if i.instance_ioid IN irestarts then restart_instruction i else i)
      []
      it
  in
  (it', irestarts)


(** POP restart machinery *)

(* remove read_requests of restarted instructions from pop's read_issuing_order *)
let pop_remove_restarted_reads_from_order
    (pop_thread:      pop_thread_substate)
    (restarted_ioids: set ioid)
    : pop_thread_substate
  =
  <| read_issuing_order = relonFilterSet (fun rr -> rr.r_ioid NIN restarted_ioids) pop_thread.read_issuing_order |>


let pop_did_reads_issue_in_order
    (state:      thread_state 'i)
    (po_old_rr:  read_request)
    (po_new_rr:  read_request)
    : bool
  =
  let read_issuing_order = (get_pop_thread_substate state.thread_substate).read_issuing_order in
  relonInRel po_old_rr po_new_rr read_issuing_order


(* determines the set of instructions that need to be restarted (not
including their dependencies) due to 'read_request' being satisfied.
'it' is the subtree under the instruction that issued  'read_request'.
If we know the writes 'wss' that satisfied the read request, we can be
more precise (fewer restarts). *)

(* now also used for PLDI11 *)
let pop_memory_read_action_restart_roots params
    (state:        thread_state 'i)
    (it:           instruction_tree 'i)
    (read_request: read_request)
    (wss:          maybe (set (write * slices)))
    : set (instruction_instance 'i)
  =
  (* predicate to determine if a po-after satisfied read should be restarted *)

  let restart_satisfied_read ioids inst : bool =
    match wss with
    | Just wss ->
        (* we know the writes that satisfied the read, we will restart
        po-after loads that overlap and read from different writes *)
        exists ((rr, rr_wss) MEM inst.subreads.sr_writes_read_from).
          ((not (pop_did_reads_issue_in_order state read_request rr)) || is_flat_model params) &&
          overlapping_slices_from_different_writes wss (Set.fromList rr_wss) ioids

    | Nothing ->
        (* we don't know the writes that satisfied the read, we will
        restart all po-after reads that overlap. *)
        exists ((rr, rr_wss) MEM inst.subreads.sr_writes_read_from).
            ((not (pop_did_reads_issue_in_order state read_request rr)) || is_flat_model params)
            &&
            exists ((rr_w, rr_sls) MEM rr_wss).
              overlapping_slices 
                (read_request.r_addr, [complete_slice read_request.r_addr])
                (rr_w.w_addr, rr_sls) &&
              rr_w.w_ioid NIN ioids
    end
  in

  let folded =
    instruction_tree_fold_root
      (fun (ioids, restarts) _ i _ ->
          let restarts' =
            if restart_satisfied_read ioids i then {i} union restarts
            else restarts
          in
          ({i.instance_ioid} union ioids, restarts'))
      ({}, {})
      []
      it
  in
  Set.bigunion {restarts | forall ((_, restarts) IN folded) | true}



(* determines the set of instructions that need to be restarted (not
including their dependencies) due to 'writes' being propagated.
'it' is the subtree under the instruction that is propagating 'writes'. *)
let propagate_write_action_restart_roots
    (it:     instruction_tree 'i)
    (writes: list write)
    : set (instruction_instance 'i)
  =

  (* restart reads that have been satisfied by writes that might be
  co-before 'write_slices' *)

  (* we'll walk over each path in the tree from the propagating store,
  starting with its 'writes' and adding new writes when we come to
  them.  This is the write_slices that's used in restart_sat_read,
  which returns true if 'inst' reads from a write that overlaps with
  write_slices (but is not one of them) *)

  let restart_sat_read write_slices ioids inst : bool =
    overlapping_slices_from_different_writes
        (Set.fromList write_slices)
        (Set.fromList (writes_read_from inst))
        ioids
  in

  (* restart reads with unsatisfied slices that overlap write_slices where
  the read requests have already been passed to the storage subsystem
  (i.e. reads that will be satisfied by writes that are co-before
  write_slices). *)

  let restart_unsat_read write_slices inst =
    let write_fps = Set.bigunion
      {slice_footprints write.w_addr slices
       | forall ((write, slices) MEM write_slices)
       | true}
    in
    exists ((rr, unsat_slices) MEM inst.subreads.sr_unsat_slices).
        read_request_issued inst rr && (* i.e. rr was issued *)
        non_empty_intersection_set (slice_footprints rr.r_addr unsat_slices) write_fps
  in

  let folded =
    instruction_tree_fold_root
      (fun (write_slices, ioids, accum) _ i _ ->
        let ioids' = {i.instance_ioid} union ioids in

        let write_slices' =
          let propagated_slices = complete_writes i.subwrites.sw_propagated_writes in
          let not_propagated (write, slices) =
            let (_, match_write_slices) =
              match_writes write.w_addr slices
                           (propagated_slices ++ [(write, slices)]) [] in
            match List.lookup write match_write_slices with
            | Nothing -> Nothing
            | Just slices -> Just (write, slices)
            end
          in
          List.mapMaybe not_propagated write_slices
        in

        if restart_sat_read write_slices ioids i || restart_unsat_read write_slices i
        then (write_slices', ioids', { i } union accum)
        else (write_slices', ioids', accum))
      (complete_writes writes, {}, {})
      []
      it
      in
  Set.bigunion {insts | forall ((_, _, insts) IN folded) | true}


let pop_memory_write_exclusive_commit_fail_action_restart_roots
    (it:          instruction_tree 'i)
    (fail_writes: list write)
    : set (instruction_instance 'i)
  =
  let fail_writes = Set.fromList fail_writes in

  (* restart reads that the writes were forwarded to *)
  {isucc  | forall (isucc IN instructions_of_tree it)
          | exists ((write, _) MEM (writes_read_from isucc)).
                write IN fail_writes}


(* check if 'instruction' might be restarted when a read response from
storage is received for one of the instruction's read requests (see
pop_is_stale_read). *)
let pop_load_sat_might_self_restart params
    (state:               thread_state 'i)
    (might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    : bool
  =
  let prev_ioids =
    {i.instance_ioid
      | forall (i MEM (prefix ++ state.old_instructions))
      | true}
  in
  
  exists ((rr, unsat_slices) MEM instruction.subreads.sr_unsat_slices).
      (* if a po-previous read to the same address is restarted, 'rr' might
      need to be restarted when it is satisfied. *)
      (exists (prev_inst MEM prefix).
        prev_inst.instance_ioid IN might_restart_prefix &&
        exists (rr' MEM (read_requests_of_subreads prev_inst.subreads)).
          overlapping_slices (rr.r_addr, unsat_slices) (rr'.r_addr, [complete_slice rr'.r_addr])
      ) ||

      (* if a po-previous read to the same address has not been issued yet
      'rr' might need to be restarted. *)
      (exists (prev_inst MEM prefix).
       exists ((rr', unsat_slices') MEM prev_inst.subreads.sr_unsat_slices).
          read_request_issued prev_inst rr' &&
          overlapping_slices (rr.r_addr, unsat_slices) (rr'.r_addr, unsat_slices')
      ) ||

      (* if a po-previous read to the same address has been issued after
      'rr' and was already satisfied, 'rr' might need to be restarted. *)
      let issued_after = relonRightOf rr (get_pop_thread_substate state.thread_substate).read_issuing_order in
      exists (rr' IN issued_after).
          rr'.r_ioid IN prev_ioids &&
          overlapping_slices (rr.r_addr, unsat_slices) (rr'.r_addr, [complete_slice rr'.r_addr])


let pop_might_be_restarted_roots params
    (state:                thread_state 'i)
    (might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    (inst_tree:            instruction_tree 'i)
    : set ioid
  =
  let restarts =
    if instruction.finished then {} else

    let store_roots =
      if is_viable_memory_store_ii instruction then
        let potential_footprint =
          instruction.subwrites.sw_potential_writes ++
            instruction.subwrites.sw_potential_write_addresses in
        if is_atomic_store (ik instruction) then
          match instruction.successful_atomic_store with
          | Nothing ->
              (propagate_write_action_restart_roots inst_tree potential_footprint)
              union
              (pop_memory_write_exclusive_commit_fail_action_restart_roots inst_tree
                  potential_footprint)
          | Just true ->
              propagate_write_action_restart_roots inst_tree potential_footprint
          | Just false ->
              pop_memory_write_exclusive_commit_fail_action_restart_roots inst_tree
                  potential_footprint
          end
        else
          propagate_write_action_restart_roots inst_tree potential_footprint
      else {}
    in

    let load_roots =
      if is_memory_load_instruction (ik instruction) then
        Set.bigunionMap
          (fun rr -> pop_memory_read_action_restart_roots params state inst_tree rr Nothing)
          (Set.fromList (read_requests_of_subreads instruction.subreads))

        union
        if instruction.instance_ioid NIN might_restart_prefix && (* for efficiency *)
          pop_load_sat_might_self_restart params state might_restart_prefix prefix instruction
        then {instruction}
        else {}
      else {}
    in

    store_roots union load_roots
  in
  Set.map (fun i -> i.instance_ioid) restarts


(* Return the set of instructions in 'prefix' that might be
restarted in the future.
ASSUME: all memory access instructions in 'prefix' have calculated
their memory address and all the instructions feeding these
calculations are propagated (i.e. addresses are known and cannot change) *)
let pop_might_be_restarted params
    (state:  thread_state 'i)
    (prefix: list (instruction_instance 'i))
    : set ioid
  =
  let fold prev prefix instruction inst_tree =
    prev
    union
    let roots = pop_might_be_restarted_roots params state prev prefix instruction inst_tree in
    (* because 'roots' might include 'instruction' we have to push it into
    the instructions tree before calling 'dependent_suffix_to_restart' *)
    dependent_suffix_to_restart roots (T [(instruction, inst_tree)])
  in

  List.foldl (fun it i -> T [(i, it)]) (T []) prefix
  $> instruction_tree_fold_root fold {} []
  $> Set.bigunion


(* returns true iff a po-previous read request was issued after
'read_request' (i.e. out of order) and was satisfied by a write to the
same address different from 'wss' and 'wss' is not a forward from a
write that is po-after that read request.
NOTE: changes in this function need to be reflected in pop_load_sat_might_self_restart *)
let pop_is_stale_read params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i) (* the load instruction *)
    (read_request: read_request)              (* the read request that is about to be sat. *)
    (wss:          set (write * slices))      (* the writes that are about to sat. the read request *)
    : bool
  =
  not (is_flat_model params) &&

  let full_prefix = (inst_context.active_prefix ++ inst_context.old_prefix) in
  let ioids = {i.instance_ioid | forall (i MEM full_prefix) | true} in

  exists (prev_inst MEM full_prefix).
    exists ((prev_rr, prev_writes) MEM prev_inst.subreads.sr_writes_read_from).
      (not (pop_did_reads_issue_in_order state prev_rr read_request))
      &&
      overlapping_slices_from_different_writes wss (Set.fromList prev_writes) ioids


(** Thread Transition Preconditions and Actions *********************)

(** bits of (shared) commit logic *)

(* check if the instructions feeding register reads are finished.
If an instruction is not finished, recursively check the register write's
dependencies *)
let fully_determined_reg_reads
    (active_prefix: list (instruction_instance 'i))
    (reg_reads:     list (reg_name * register_read_sources * register_value))
    : bool
  =
  undetermined_reg_writes_read_from active_prefix reg_reads
  $> Set.null


(* true iff the value read from registers that feed directly into a memory
access address of 'instruction' cannot change, and the pseudocode has made
enough steps to make the address visible *)
let fully_determined_address
    (active_prefix: list (instruction_instance 'i))
    (instruction:   instruction_instance 'i)
    : bool
  (* po: head is new. ASSUME: super set of the po-prefix of 'instruction' *)
  =
  (* for efficiency, first check if 'instruction' is finished or not a memory access *)
  instruction.finished ||
  not (is_viable_memory_access_ii instruction) ||

  (* the value read from registers that feed directly into a memory
  access address of 'instruction' cannot change *)
  [(reg, register_read_sources, v)
    | forall ((reg, register_read_sources, v) MEM instruction.reg_reads)
    | reg IN instruction.regs_in_feeding_address]
  $> fully_determined_reg_reads active_prefix &&

  (* the pseudocode has made enough steps to make the address visible *)
  (is_viable_memory_store_ii instruction -->
    instruction.subwrites.sw_addr <> Nothing) &&
  (is_memory_load_instruction (ik instruction) -->
    read_footprint_of_load instruction <> Nothing)

let commitDataflow (iic: instruction_in_context 'i) : bool =
  fully_determined_reg_reads iic.active_prefix iic.iic_instance.reg_reads


let commitControlflow (iic: instruction_in_context 'i) : bool =
  (forall (iprev MEM iic.active_prefix).
      is_cond_branch_ii iprev --> iprev.finished) &&

  (forall (iprev MEM iic.active_prefix).
      is_indirect_branch_ii iprev --> iprev.finished) &&

  (* Additions for AArch64 transactional memory *)
  (forall (iprev MEM iic.active_prefix).
      (is_tstart (ik iprev) --> iprev.finished) &&
      (is_tcommit (ik iprev) --> iprev.finished))


let finish_action isa state iic =
  let i' = <| iic.iic_instance with finished = true |> in

  let (it_subtree', discarded_ioids) =
    if isa.isa_model = MIPS then
      if is_branch_instruction (ik iic.iic_instance) then
        match iic.subtree with
        | T [(successor, T iiits)] ->
           (* Prune tree of branch delay instruction *)
           let successor_nia = mips_next_next_pc_of_finished_instruction isa i' in
           (* discard all subtrees that didn't fetch from that address, and all but the first of those *)
           let (iiits, discard) = List.partition (fun (i', _) -> i'.program_loc = successor_nia) iiits in
           (T [(successor, T iiits)], ioids_of_instruction_tree (T discard))
        | T [] -> (iic.subtree, {}) (* branch delay not yet fetched *)
        | _ -> failwith "expected linear subtree following mips branch"
        end
      else
        (iic.subtree, {})
    else
      (* discard any subtrees that don't match the chosen branch  *)
      let nia = next_address_of_finished_instruction isa i' in
      (* discard all subtrees that didn't fetch from that address *)
      (* make sure only one subtree starts with address nia *)
      let (T iiits) = iic.subtree in
      let (iiits, discard) = List.partition (fun (i', _) -> i'.program_loc = nia) iiits in
      let () =
        match iiits with
        | []      -> ()
        | _ :: [] -> ()
        | _       -> failwith "fetched more than once from the same location"
        end
      in
      (T iiits, ioids_of_instruction_tree (T discard))
  in

  let instruction_tree' = apply_tree_context iic.context (i',it_subtree') in

  (* POP: remove read requests from untaken branches from read_issuing_order *)
  let thread_substate' =
    if discarded_ioids <> {} then
      match state.thread_substate with
      | POP_thread pop_substate ->
          let read_issuing_order' = relonFilterSet (fun rr -> rr.r_ioid NIN discarded_ioids) pop_substate.read_issuing_order in
          POP_thread  <| read_issuing_order = read_issuing_order' |>
      | PLDI11_thread _ -> state.thread_substate
      | No_substate -> No_substate
      end
    else state.thread_substate
  in

  <|  state with
      instruction_tree = instruction_tree';
      thread_substate = thread_substate';
  |>
  $> make_old_instructions isa
  $> make_thread_cont_res {} discarded_ioids



let address_from_AArch64_dc_ii (instruction: (instruction_instance 'i)) : maybe address =
  match instruction.instruction_kind with
  | IK_cache_op Cache_op_D_CVAU  ->
    match instruction.reg_reads with
    (* DC CVAU only reads 1 register -- it contains the address *)
    | [(_, _, v)] ->
        address_of_register_value v
    | _ -> Nothing
    end
  | _ -> Nothing
  end

(* Update an instruction (sub)tree to restart dcs to some address:
 * TODO: when we get DC; po; (R|W)  ordering then this needs updating *)
let handle_restart_dc fp it =
  instruction_tree_map
    (fun prefix i _ ->
      match address_from_AArch64_dc_ii i with
      | Just addr ->
          (* TODO: dc cache line overlap *)
          if footprints_overlap fp (addr, 4) then
            restart_instruction i
          else
            i
      | Nothing -> i
      end)
  []
  it


(* can "finish" a DC only once it becomes non-restartable (see above) 
 * currently we make this a strong requirement that all po-previous instructions
 * are finished.
 *)
let flat_can_finish_dc iic =
  (forall (iprev MEM iic.active_prefix).
    iprev.finished)

let propagate_write_action
    (params:        thread_params)
    (state:         thread_state 'i)
    (inst_context:  instruction_in_context 'i)
    (write:         write)
    : thread_cont_res (thread_state 'i)
  =
  let it = inst_context.subtree in
  let i = inst_context.iic_instance in

  let () = ensure (i.successful_atomic_store <> Just false) $
    "atomic write (ioid " ^ show i.instance_ioid ^ ") that was determined to fail has succeeded" in

  let i' =
    <| i with
          subwrites = <| i.subwrites with
            sw_potential_writes =  List.delete write i.subwrites.sw_potential_writes;
            sw_propagated_writes = write :: i.subwrites.sw_propagated_writes;
          |>;
    |>
  in

  let (it', restarted_ioids) =
    if params.thread_model = Relaxed_thread_model then
      (it, {})
    else
      propagate_write_action_restart_roots it [write]
      $> restart_dependent_subtrees it
  in

  let it'' = handle_restart_dc write.w_addr it' in

  let state = <| state with instruction_tree = apply_tree_context inst_context.context (i', it'') |> in

  match state.thread_substate with
  | POP_thread thread_substate ->
      let pop_thread' = pop_remove_restarted_reads_from_order thread_substate restarted_ioids in
      <| state with thread_substate = POP_thread pop_thread' |>
  | PLDI11_thread _ -> state
  | No_substate     -> state
  end
  $> make_thread_cont_res restarted_ioids {}

let failed_write_action
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (write:        write)
    (mos:          micro_op_state 'i)
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let it = inst_context.subtree in

  let () = ensure (i.successful_atomic_store <> Just true) $
    "atomic write (ioid " ^ show i.instance_ioid ^ ") that was determined to succeed has failed" in

  let i' =
    <| i with
          subwrites = <| i.subwrites with
            sw_potential_write_addresses = [];
            sw_potential_writes =          [];
            sw_propagated_writes =         [];
          |>;
          micro_op_state = mos;
    |>
  in

  let (it', restarted_ioids) =
    pop_memory_write_exclusive_commit_fail_action_restart_roots it [write]
    $> restart_dependent_subtrees it
  in

  let state = <| state with instruction_tree = apply_tree_context inst_context.context (i', it') |> in

  match state.thread_substate with
  | POP_thread thread_substate ->
      let pop_thread' = pop_remove_restarted_reads_from_order thread_substate restarted_ioids in
      <| state with thread_substate = POP_thread pop_thread' |>
  | PLDI11_thread _ -> state
  | No_substate     -> state
  end
  $> make_thread_cont_res restarted_ioids {}

(** pldi11 commit candidate *****************************************)

let pldi11_commitPrevMightSameAddress active_prefix footprints =
  forall (iprev MEM active_prefix).
    is_viable_memory_access_ii iprev -->
      (iprev.finished ||
          (* all the instructions that write registers feeding directly into
            a memory access address of iprev are committed*)
          ((forall (iprevprev MEM active_prefix).
            (* it would be enough to just check those before iprev, but more complex *)
        iprevprev.instance_ioid IN iprev.ioids_feeding_address -->
          iprevprev.finished) &&
            (* and iprev cannot produce memory reads or writes that access Unknown
                or anything in i_addresses *)
        not (possibly_reads_or_writes_address iprev footprints)
      ))

let pldi11_commitLoadPrevMightSameAddress iic =
  footprints_read_from iic.iic_instance.subreads.sr_writes_read_from
  $> pldi11_commitPrevMightSameAddress iic.active_prefix

let pldi11_propagateWritePrevMightSameAddress iic write =
  pldi11_commitPrevMightSameAddress iic.active_prefix {write.w_addr}

let pldi11_commit_cand
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    : bool =
  let pldi11_substate = get_pldi11_thread_substate state.thread_substate in
  let i = iic.iic_instance in
  (* let program_order_prefix_full = iic.active_prefix ++ iic.old_prefix in *)

  (* NEWTODO: this code depends on equality of register names, but when we have
     register subfields that will need to be fixed *)

  (* commitDataflow *)
  commitDataflow iic &&
  (* commitControlflow *)
  commitControlflow iic &&
  (* commitPrevMightSameAddress *)
  (is_memory_load_instruction (ik i) -->
      pldi11_commitLoadPrevMightSameAddress iic) &&
   (* commitPrevBarrLS *)
   (is_viable_memory_access_ii i -->
      ((forall (iprev MEM iic.active_prefix).
        (is_sync (ik iprev) || is_lwsync (ik iprev) || is_isync (ik iprev)) --> iprev.finished) &&
      Set.null pldi11_substate.unacknowledged_syncs)) &&
   (* commitPrevBarrSEIEIO *)
   (is_memory_store_instruction (ik i) -->
     forall (iprev MEM iic.active_prefix).
         is_eieo (ik iprev) --> iprev.finished) &&
   (* commitPrevBarrB *)
   (is_barrier (ik i) --> (* this includes isync *)
      ((forall (iprev MEM iic.active_prefix).
         is_barrier (ik iprev) --> iprev.finished) &&
      Set.null pldi11_substate.unacknowledged_syncs)) &&
   (* commitMemoryAccessBeforeBarrier *)
   ((is_sync (ik i) || is_lwsync (ik i)) -->
     forall (iprev MEM iic.active_prefix).
       is_viable_memory_access_ii iprev --> iprev.finished) &&
   (* commitMemoryAccessBeforeBarrierEIEIO *)
   (is_eieio (ik i) -->
     forall (iprev MEM iic.active_prefix).
       is_memory_store_instruction (ik iprev) --> iprev.finished) &&
   (* commitAddressesBeforeIsyncDetermined *)
   (is_isync (ik i) -->
      forall_iprev_with_prefix iic.active_prefix $ fun iprev prev_active_prefix ->
          fully_determined_address prev_active_prefix iprev
     (*
     forall (iprev MEM iic.active_prefix).  (* NEWTODO: or iic.active_prefix_full ? *)
        if (is_memory_access_instruction iprev)
        then
            (* determined previous addresses *)
            known_memory_addresses iprev
            &&
            (* *fully* determined previous addresses *)
            forall (r IN regs_feeding_addresses
                        (fst (sem_of_instruction m
                           iprev.instance_instruction initial_id_state))).
            forall (ideps MEM program_order_prefix ...of... iprev).
            if r IN ideps.regs_out &&
               (not (exists (ideps' IN ((strict_program_order_suffix t ideps) inter (strict_program_order_prefix t iprev))).
                 (r IN ideps'.regs_out)))
            then ideps.committed else true
        else true
   else true
   *)) &&
   (* commitPrevLoadAcquire *)
   (is_memory_store_instruction (ik i) -->
     forall (iprev MEM iic.active_prefix).
      is_AArch64_load_acquire (ik iprev) --> finished_load_part iprev) &&
   (* commitStoreRelease *)
   (is_AArch64_store_release (ik i) -->
     forall (iprev MEM iic.active_prefix).
       is_viable_memory_access_ii iprev --> iprev.finished) &&
   (* commitLRSC *)
   ((is_PPC_load_reserve (ik i) || is_PPC_store_conditional (ik i)) -->
     forall (iprev MEM iic.active_prefix).
       (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev)) --> iprev.finished)


(** pldi11 commit actions *******************************************)

let pldi11_memory_write_commit_action_restart_roots
    (i1: (instruction_instance 'i))
    (it: instruction_tree 'i)
    (ws: set write)
    : set (instruction_instance 'i) =
  { isucc | forall (isucc IN instructions_of_tree it) |
    (exists ((w', _) MEM (writes_read_from isucc)). (* TODOREALLY*)
       let ws'' = {w | forall ((w, _) MEM (writes_read_from isucc)) | true} in
       (non_empty_intersection_write_set ws'' ws) && (* TODOREALLY*)
       (not (w' IN ws)) &&
       (not (exists (ioidfeed IN ioids_of_instruction_tree it). (* i.e. successor of i1 *)
               ioidfeed = w'.w_ioid)) (* XXX: do we need to have it in prefix of isucc? believe not *)
    )
  }


let pldi11_commit_barrier_action state b =
  match b.b_barrier_kind with
  | Barrier_Sync ->
      let pldi11_substate = get_pldi11_thread_substate state.thread_substate in
      let pldi11_substate = <| unacknowledged_syncs = pldi11_substate.unacknowledged_syncs union {b} |> in
      <| state with thread_substate = PLDI11_thread pldi11_substate; |>
  | _ -> state
  end


(** POP commit/propagate/finish candidates ********************************************)

(* aarch64 might-access-same-address (for stores) *)
let pop_write_co_check
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (write:  write)
    : bool
  =
  let might_be_restarted = pop_might_be_restarted params state iic.active_prefix in

  (* to guarantee RW-co, all po-previous reads to the same address must be
     issued and unrestartable. *)
  (forall (iprev MEM iic.active_prefix).
   forall ((iprev_rr, iprev_unsat_slices) MEM iprev.subreads.sr_unsat_slices).
        (non_empty_intersection write.w_addr iprev_rr.r_addr -->
            match iprev_unsat_slices with
            | [] -> true (* i.e. iprev_rr was completely satisfied *)
            | _ -> 
               not (is_flat_model params) &&
               List.lookup iprev_rr iprev.subreads.sr_requested <> Nothing (* i.e. iprev_rr was issued *)
            end &&
            (* and iprev can't be restarted *)
            iprev.instance_ioid NIN might_be_restarted)) &&

  (* guarantee WW-co *)
  (forall (iprev MEM iic.active_prefix).
    let prev_unpropagated_writes =
      iprev.subwrites.sw_potential_write_addresses
      ++ iprev.subwrites.sw_potential_writes
    in

    if iprev.successful_atomic_store = Just false then true
    else if params.thread_allow_write_subsumption &&
        not (is_AArch64_store_release (ik iprev)) &&
        not (is_RISCV_store_release (ik iprev)) &&
        not (is_atomic_store (ik iprev))
    then
      (* if write-subsumption is allowed, we make sure the write we are propagating
      covers all po-previous unpropagated writes that intersect with it *)
      forall (prev_write MEM prev_unpropagated_writes).
        non_empty_intersection write.w_addr prev_write.w_addr
        -->
        sub_footprint prev_write.w_addr write.w_addr
    else
      forall (prev_write MEM prev_unpropagated_writes).
        not (non_empty_intersection write.w_addr prev_write.w_addr)
  ) &&

  (* Additions for mixed-size/load-acq/load-exc: (forbid litmus test CO-MIXED-20cc) if there is
  a po-following read that was partially satisfied by the store, it must
  have already issued the unsat slices. This is important for single-copy
  atomicity *)
  let issued _ iafter itafter =
    forall ((read_request, write_slices) MEM iafter.subreads.sr_writes_read_from).
      (((List.elem write (writes_of_write_slices write_slices)) &&
        (unsat_slices_of_read_request iafter read_request <> [] ||
           (not (is_flat_model params) &&
              (is_AArch64_load_acquire (ik iafter) || is_RISCV_load_strong_acquire (ik iafter)
              || is_atomic_load (ik iafter)))))
      -->
        read_request_issued iafter read_request)
  in
  instruction_tree_all issued [] iic.subtree


let rec pop_load_finish_co_check_helper
    (params:              thread_params)
    (state:               thread_state 'i)
    (might_be_restarted:  set ioid)
    (read_request:        read_request)
    (writes_read_from:    list (write * slices))
    (active_prefix:       list (instruction_instance 'i))
    : bool
  =
  match active_prefix with
  | [] -> true
  | inst :: active_prefix ->
      (* memory address of 'inst' is fully determined *)
      fully_determined_address active_prefix inst &&

      (* to simplify the rest of the checks we also require that 'inst' has
         made enough steps to guarantee all the read/write requests are
         recorded in the instruction_instance state. *)
      all_writes_reads_are_calculated inst &&

      (* filter out slices that overlap propagated writes *)
      let propagated_writes = complete_writes inst.subwrites.sw_propagated_writes in
      let (_, writes_read_from) =
        match_writes read_request.r_addr [complete_slice read_request.r_addr]
                     (propagated_writes ++ writes_read_from) [] in
      let writes_read_from = [(w, s) | forall ((w, s) MEM writes_read_from)
                                     | not (List.elem w inst.subwrites.sw_propagated_writes)]
      in

      (* filter out slices that were forwarded from fixed writes *)
      let writes_read_from =
        let is_fixed =
          not inst.finished && (* for efficiency (propagated_writes covers the propagated case) *)
          not (is_PPC_store_conditional (ik inst)) && (* PPC store-conditional can fail spontaneously *)
          not (is_RISCV_store_conditional (ik inst)) && (* RISC-V store-conditional can fail spontaneously *)

          (* all data dependencies (including address) are determined *)
          fully_determined_reg_reads active_prefix inst.reg_reads
        in

        if is_fixed then
          [(w, s) | forall ((w, s) MEM writes_read_from)
                  | not (List.elem w inst.subwrites.sw_potential_writes)]
        else writes_read_from
      in

      if List.null writes_read_from then true
      else

      (* can't overlap unpropagated writes *)
      not (exists (write MEM (inst.subwrites.sw_potential_writes ++ inst.subwrites.sw_potential_write_addresses)).
           exists ((w, s) MEM writes_read_from).
              overlapping_slices (write.w_addr, [complete_slice write.w_addr]) (w.w_addr, s))
      &&

      (* overlapping reads must be finished, or non-restartable and
      issued in order with read_request *)
      (if finished_load_part inst then true
      else
        match inst.subreads.sr_addr with
        | Nothing -> true (* not a load instruction *)

        | Just read_footprint' ->
            (exists ((w, s) MEM writes_read_from).
              overlapping_slices (w.w_addr, s) (read_footprint', [complete_slice read_footprint']))
            -->
            (inst.instance_ioid NIN might_be_restarted &&
            forall ((rr', slices') MEM inst.subreads.sr_unsat_slices).
                match slices' with
                | [] -> true
                | _  ->
                    ((exists ((w, s) MEM writes_read_from).
                          overlapping_slices (w.w_addr, s) (rr'.r_addr, [complete_slice rr'.r_addr]))
                          (* see AArch64/mixed-size/HAND/R+dmb.sy+rfipw-poswp-ctrlisb.litmus as to why
                          we need to use the complete slice of rr' and not just the unsat slices (slices') *)
                    -->
                    not (is_flat_model params) &&
                    List.lookup rr' inst.subreads.sr_requested <> Nothing &&
                    pop_did_reads_issue_in_order state rr' read_request)
                end)
        end)
      &&

      pop_load_finish_co_check_helper
          params
          state
          might_be_restarted
          read_request
          writes_read_from
          active_prefix
  end


(* pop might-access-same-address (for loads) The closest po-previous write
   to the same address must be propagated and all memory accesses in-between must
   have a fully determined addresses. If the closest po-previous write is a
   write that was forwarded to the load it does not have to be
   propagated, just "fixed" (i.e. instructions feeding ALL its registers are
   determined). *)
let pop_load_finish_co_check
    (params:             thread_params)
    (state:              thread_state 'i)
    (inst_context:       instruction_in_context 'i)
    : bool
  =
  (* any observable behaviour that depends on the load being finished
     ([R]; ctrl; [W] or [R]; ctrl+isb; [R] or [Raq]; po; [W] , etc)
     also depends on the po-prefix having fully determined addresses,
     hence it is ok for might_be_restarted to over-approximate if the
     po-prefix does not have fully determined addresses *)
  let might_be_restarted =
    if (* all po-previous memory addresses are fully determined *)
      forall_iprev_with_prefix inst_context.active_prefix $ fun iprev prev_active_prefix ->
        fully_determined_address prev_active_prefix iprev &&
        (* to simplify the rest of the checks we also require that iprev
        has made enough steps to guarantee all the read/write requests
        are recorded in the instruction_instance state. *)
        all_writes_reads_are_calculated iprev
    then
      pop_might_be_restarted params state inst_context.active_prefix
    else
      {inst.instance_ioid | forall (inst MEM inst_context.active_prefix) | not inst.finished}
  in

  forall ((read_request, writes) MEM inst_context.iic_instance.subreads.sr_writes_read_from).
    pop_load_finish_co_check_helper
        params
        state
        might_be_restarted
        read_request
        writes
        inst_context.active_prefix



let pop_commit_barrier_cand
    (params: thread_params)
    (isa: isa 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  let inst = iic.iic_instance in

  commitDataflow iic &&

  (* we allow RISC-V fences to commit and finish on speculated branches;
  This is needed to allow MP+fence.rw.rw+ctrlfence.w.r and
  SB+fence.rw.rw+ctrlfence.r.rxp *)
  (isa.isa_model <> RISCV --> commitControlflow iic) &&

  (* commit order between barriers *)
  match isa.isa_model with
  | AARCH64 _ ->
      if is_flat_model params then
        (is_pop_strong_memory_barrier (ik inst) -->
          (forall (iprev MEM iic.active_prefix).
            (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
              --> iprev.finished)) &&

        (forall (iprev MEM iic.active_prefix).
          is_pop_strong_memory_barrier (ik iprev) --> iprev.finished)
      else
        forall (iprev MEM iic.active_prefix).
          (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
            --> iprev.finished

  | PPC    ->
      forall (iprev MEM iic.active_prefix).
        (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
          --> iprev.finished

  | MIPS      ->
      forall (iprev MEM iic.active_prefix).
        (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
          --> iprev.finished

  | RISCV     -> true
  | X86       -> true
  end &&

  (is_pop_strong_memory_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_viable_memory_access_ii iprev --> iprev.finished) &&

  (is_pop_instruction_barrier (ik inst) -->
      forall_iprev_with_prefix iic.active_prefix $ fun iprev prev_active_prefix ->
          fully_determined_address prev_active_prefix iprev) &&

  (* Additions for barrier.st/ld: *)
  (is_AArch64_ld_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_memory_load_instruction (ik iprev) --> finished_load_part iprev) &&

  (is_AArch64_st_barrier (ik inst) -->
    (forall (iprev MEM iic.active_prefix).
        is_memory_store_instruction (ik iprev) --> iprev.finished)) &&

  (* Additions for lwsync: *)
  (is_lwsync (ik inst) -->
    (forall (iprev MEM iic.active_prefix).
        is_viable_memory_access_ii iprev --> iprev.finished)) &&

  (* Additions for eieio: *)
  (is_eieio (ik inst) -->
    (forall (iprev MEM iic.active_prefix).
        is_memory_store_instruction (ik iprev) --> iprev.finished)) &&

  (* Additions for load-reserve/store-conditional: *)
  (* none *)

  (** Additions for RISC-V *)
  (is_RISCV_fence_pr (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_memory_load_instruction (ik iprev) --> finished_load_part iprev) &&

  (is_RISCV_fence_pw (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_memory_store_instruction (ik iprev) --> iprev.finished) &&

  (* we commit fence.tso only after all po-previous memory accesses are finished;
  po-later stores can be committed only after the fence.tso is finished;
  po-later loads can be satisfied only after all loads preceding the fence.tso are satisfied *)
  (is_RISCV_fence_tso (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_viable_memory_access_ii iprev --> iprev.finished) &&

  (* for IC/DC *)
  (is_AArch64_dc_wait_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_AArch64_dc_instr (ik iprev) --> iprev.finished) &&

  (is_AArch64_ic_wait_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
        is_AArch64_ic_instr (ik iprev) --> iprev.finished)

let pop_commit_store_cand
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  let instruction = iic.iic_instance in

  (* all po-previous memory addresses are fully determined *)
  (forall_iprev_with_prefix iic.active_prefix $ fun iprev prev_active_prefix ->
      fully_determined_address prev_active_prefix iprev &&
      (* to simplify the rest of the checks we also require that iprev
      has made enough steps to guarantee all the read/write requests
      are recorded in the instruction_instance state. *)
      all_writes_reads_are_calculated iprev) &&

  commitDataflow iic &&
  commitControlflow iic &&

  (forall (iprev MEM iic.active_prefix).
      (is_pop_strong_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
      --> iprev.finished) &&

  (* Additions for barrier.st/ld: *)
  (forall (iprev MEM iic.active_prefix).
      (is_AArch64_st_barrier (ik iprev) --> iprev.finished) &&
      (is_AArch64_ld_barrier (ik iprev) --> iprev.finished)) &&

  (* Additions for load.acquire/store.release: *)
  (* TODO: the following might be too strong, a previous read only
  needs to be issued and non-restartable. *)
  (is_AArch64_store_release (ik instruction) -->
    (forall (iprev MEM iic.active_prefix).
        is_viable_memory_access_ii iprev --> iprev.finished)) &&

  (forall (iprev MEM iic.active_prefix).
      is_AArch64_load_acquire (ik iprev) --> finished_load_part iprev) &&

  (* Additions for load/store-exclusive: *)
  (is_AArch64_store_exclusive (ik instruction) -->
      let atomic_load = ensure_just (paired_atomic_load iic)
          "can't find the paired load of a successful atomic store"
          (* failed store-exclusive uses a different _cand function *)
      in
      finished_load_part atomic_load &&
      forall ((_, rf) MEM atomic_load.subreads.sr_writes_read_from) ((w, _) MEM rf).
        w.w_thread = state.thread -->
          forall (iprev MEM iic.active_prefix).
              iprev.instance_ioid = w.w_ioid -->
                  List.elem w iprev.subwrites.sw_propagated_writes) &&

  (* Additions for lwsync: *)
  (forall (iprev MEM iic.active_prefix).
      is_lwsync (ik iprev) --> iprev.finished) &&

  (* Additions for eieio: *)
  (forall (iprev MEM iic.active_prefix).
      is_eieio (ik iprev) --> iprev.finished) &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_store_conditional (ik instruction) -->
      paired_atomic_load iic <> Nothing &&
      (forall (iprev MEM iic.active_prefix).
          (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev))
            --> iprev.finished)) &&

  (*** Additions for RISC-V ***)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_fence_sw (ik iprev) --> iprev.finished) &&

  (forall (iprev MEM iic.active_prefix).
      is_RISCV_fence_tso (ik iprev) --> iprev.finished) &&

  (forall (iprev MEM iic.active_prefix).
      is_RISCV_load_acquire (ik iprev) --> finished_load_part iprev) &&

  (forall (iprev MEM iic.active_prefix).
      is_RISCV_store_acquire (ik iprev) --> iprev.finished) &&

  (is_RISCV_store_release (ik instruction) -->
    (forall (iprev MEM iic.active_prefix).
        is_viable_memory_access_ii iprev --> iprev.finished)) &&

  ((is_RISCV_store_conditional (ik instruction) && not (is_RISCV_AMO (ik instruction))) -->
      let atomic_load = ensure_just (paired_atomic_load iic)
          "can't find the paired load of a successful atomic store"
          (* failed store-conditional uses a different _cand function *)
      in
      finished_load_part atomic_load &&
      (* the following matches the RVWMO Atomicity Axiom assertion "then 's'
      must precede 'w' in the global memory order". When the lr and sc are
      to the same address this has no effect as the co-check will make sure
      's' is done before 'w', but when they are to a different address
      this is observable. See LR-SC-diff-loc4.litmus (forbidden) *)
      forall ((_, rf) MEM atomic_load.subreads.sr_writes_read_from) ((w, _) MEM rf).
        w.w_thread = state.thread -->
          forall (iprev MEM iic.active_prefix).
              iprev.instance_ioid = w.w_ioid -->
                  List.elem w iprev.subwrites.sw_propagated_writes)


let pop_finish_simple_cand
    (_state:  thread_state 'i)
    (iic:     instruction_in_context 'i)
    : bool
  =
  commitDataflow iic &&
  commitControlflow iic


let pop_finish_load_cand_barrier_part
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  (* Additions for load.acquire/store.release: *)
  (forall (iprev MEM iic.active_prefix).
      is_AArch64_load_acquire (ik iprev) --> finished_load_part iprev) &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_load_reserve (ik iic.iic_instance) -->
    (forall (iprev MEM iic.active_prefix).
        (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev))
        --> iprev.finished)) &&

  (*** Additions for RISCV ***)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_load_acquire (ik iprev) --> finished_load_part iprev) &&

  (* this is just to make sure "fence r,r" and "fence r,rw" are finished
  (the other fences will already be finished, see read-req-cand) *)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_fence_sr (ik iprev) --> iprev.finished) &&

  (forall_iprev_with_prefix iic.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_tso (ik prev_inst) -->
        (prev_inst.finished ||
        forall (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
              --> finished_load_part prev_prev_inst))

let pop_finish_load_cand
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  pop_finish_simple_cand state iic &&
  pop_finish_load_cand_barrier_part state iic &&
  pop_load_finish_co_check params state iic


let pop_finish_cand params state (iic: instruction_in_context 'i) : bool =
  if is_memory_load_instruction (ik iic.iic_instance) then
    pop_finish_load_cand params state iic
  else if is_RISCV_fence_pr (ik iic.iic_instance)
          || is_RISCV_fence_pw (ik iic.iic_instance) then
    true
  else
    pop_finish_simple_cand state iic


let pop_propagate_tmstart_cand (iic: instruction_in_context 'i) : bool =
  let instruction = iic.iic_instance in
  let () = ensure (is_tstart (ik instruction)) "not a tstart instruction" in

  commitDataflow iic &&
  commitControlflow iic &&

  forall (i MEM iic.active_prefix). i.finished
  (* TODO: does nested tstart need to wait for the prefix to be finished?
  I don't think it is observable *)


let pop_propagate_tmcommit_cand (iic: instruction_in_context 'i) : bool =
  let instruction = iic.iic_instance in
  let () = ensure (is_tcommit (ik instruction)) "not a tcommit instruction" in

  commitDataflow iic &&
  commitControlflow iic &&

  forall (i MEM iic.active_prefix). i.finished
  (* TODO: does nested tcommit need to wait for the prefix to be finished?
  I don't think it is observable *)


let pop_propagate_tmabort_cand (iic: instruction_in_context 'i) : bool =
  let instruction = iic.iic_instance in
  let () = ensure (is_tabort (ik instruction)) "not a tabort instruction" in

  commitDataflow iic &&
  commitControlflow iic


(** POP commit/propagate/finish actions **********************************************)

(** Transition a load to MOS_pending_mem_read ***********************)

(** candidates *)

let pldi11_memory_read_storage_cand (state: thread_state 'i) (iic: instruction_in_context 'i) : bool =
  let i = iic.iic_instance in
  (*let program_order_prefix_full = iic.active_prefix ++ iic.committed_prefix in*)
  (forall (iprev MEM iic.active_prefix).
    (is_sync (ik iprev) || is_isync (ik iprev) || is_lwsync (ik iprev)) --> iprev.finished) &&
  (Set.null (get_pldi11_thread_substate state.thread_substate).unacknowledged_syncs) &&
  (is_PPC_load_reserve (ik i) -->
      (forall (iprev MEM iic.active_prefix).
        (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev)) --> iprev.finished))



let pop_memory_read_request_cand params (inst_context: instruction_in_context 'i) : bool =
  let instruction = inst_context.iic_instance in

  (* NOTE: we don't check po-previous instructions to the same address.
     See also private comment THREAD1 *)
  (forall (prev_inst MEM inst_context.active_prefix).
      is_pop_strong_memory_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* See private comment THREAD2 *)
  (forall (prev_inst MEM inst_context.active_prefix).
       is_pop_instruction_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* Additions for barrier.st/ld: *)
  (forall (prev_inst MEM inst_context.active_prefix).
      is_AArch64_ld_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* Additions for load.acquire/store.release: *)
  (* A Store-Release followed by a Load-Acquire is observed in program order *)
  (is_AArch64_load_acquire (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix).
          is_AArch64_store_release (ik prev_inst) --> prev_inst.finished) &&
  (* All po-previous Load-acquires must issue their requests before the
  read request. Also see private note THREAD3 *)
  (forall (prev_inst MEM inst_context.active_prefix).
      is_AArch64_load_acquire (ik prev_inst)
      -->
      (finished_load_part prev_inst ||
      is_entirely_satisfied_load prev_inst)) &&

  (* Additions for transactional memory: *)
  (forall (prev_inst MEM inst_context.active_prefix).
      (is_tstart (ik prev_inst)  --> prev_inst.finished) &&
      (is_tcommit (ik prev_inst) --> prev_inst.finished)) &&

  (* Additions for lwsync: *)
  (* all loads that are po-followed by lwsync in active_prefix are finished *)
  List.dropWhile (fun i -> not (is_lwsync (ik i))) inst_context.active_prefix
  $> List.dropWhile (fun i -> is_memory_load_instruction (ik i) --> finished_load_part i)
  $> List.null &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_load_reserve (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix).
          (is_PPC_load_reserve (ik prev_inst) || is_PPC_store_conditional (ik prev_inst))
          --> prev_inst.finished) &&

  (*** Additions for RISCV ***)
  (forall_iprev_with_prefix inst_context.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_sr (ik prev_inst) -->
        (prev_inst.finished ||
        (is_RISCV_fence_pr (ik prev_inst)
          && not (is_RISCV_fence_pw (ik prev_inst))
          && forall (prev_prev_inst MEM prev_active_prefix).
                is_memory_load_instruction (ik prev_prev_inst)
                  --> is_entirely_satisfied_load prev_prev_inst))) &&

  (forall_iprev_with_prefix inst_context.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_tso (ik prev_inst) -->
        (prev_inst.finished ||
        forall (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
              --> is_entirely_satisfied_load prev_prev_inst)) &&

  (is_RISCV_load_strong_acquire (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix).
          is_RISCV_store_strong_release (ik prev_inst) --> prev_inst.finished) &&

  (is_RISCV_load_release (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix). prev_inst.finished) &&

  (forall (prev_inst MEM inst_context.active_prefix).
      is_RISCV_load_acquire (ik prev_inst)
      -->
      (finished_load_part prev_inst ||
      is_entirely_satisfied_load prev_inst)) &&

  (forall (prev_inst MEM inst_context.active_prefix).
      is_RISCV_store_acquire (ik prev_inst) --> prev_inst.finished)

(** Action *)

let pending_memory_read_request_action params
    (isa:          isa 'i)
    (state:        thread_state 'i)
    (iic:          instruction_in_context 'i)
    (read_kind:    read_kind)
    ((addr, size): footprint)
    (inst_cont:    memory_value -> outcome_S)
    : thread_state 'i
  =
  (* generate the read-requests *)
  let (read_requests, id_state') =
    if params.thread_restriction = RestrictionSC then
      Events.make_read_request_events'
        iic.iic_instance.instance_id_state
        state.thread iic.iic_instance.instance_ioid addr size size read_kind
    else
      make_read_request_events_ii isa
        state.thread iic.iic_instance (addr, size) read_kind
  in

  (* initialise subreads' *)
  let subreads =
    <|  sr_addr = Just (addr, size);
        sr_unsat_slices = [(rr, [complete_slice rr.r_addr]) | forall (rr MEM read_requests) | true];
        sr_writes_read_from = [(rr, []) | forall (rr MEM read_requests) | true];
        sr_requested = [];
        sr_assembled_value = Nothing;
    |>
  in

  let mos =
    if is_RISCV_AMO (ik iic.iic_instance) then MOS_AMO_lock inst_cont
    else MOS_pending_mem_read inst_cont
  in

  let instruction' =
    <|  iic.iic_instance with
        micro_op_state    = mos;
        subreads          = subreads;
        instance_id_state = id_state';
    |>
  in

  <| state with instruction_tree = apply_tree_context iic.context (instruction', iic.subtree) |>


(** Satisfy memory read by write received from storage subsystem ****)

let pldi11_memory_read_action_restart_roots params
  (i:instruction_instance 'i)
  (it: instruction_tree 'i)
  (r:read_request)
  (wss: set (write*slices))   (* the write slices read from by the read being satisfied *)
  : set (instruction_instance 'i) =
  (* check if there's a footprint intersection where they've read from different writes *)
       let irestart_roots =
         (* satisfyReadRestarts *)
         if
           (match params.thread_rr with
           | Restart_on_commit -> false
           | Restart_on_read_satisfy -> true
           end) then
           { isucc | forall (isucc IN instructions_of_tree it) |
              (overlapping_slices_from_different_writes
                 wss
                 (Set.fromList (writes_read_from isucc))
                 (ioids_of_instruction_tree it)) (* i.e. successor of i*)
(**
 && (* TODOREALLY  the previous code did this ifeed stuff, which I now deal with with the third argument to non_empty_... above. Correctly? *)
            (not (exists (ifeed IN instructions_of_tree it). (* i.e. successor of i *)
               ifeed.instance_ioid = w'.w_ioid)) (* XXX: do we need to have it in prefix of isucc? believe not *)
*)
(* NEWTODO DONE? handle the write_possibly_done_by stuff - does it need to look at the whole prefix, or the active one, or just after the read?

            (not (exists (i' IN t.in_flight_instructions).
(* correspondence between text (which here doesn't say "(where the read was not forwarded)") and the use of write_possibly_done_by below isn't terribly clear *)
                    write_possibly_done_by t.thread i'.behaviour w'))
*)

           }
   else {} in
        irestart_roots



(*
let memory_read_action m t i r w ist =
       let irestarts =
         (* satisfyReadRestarts *)
         if
           (match m.thread_rr with
           | Restart_on_commit -> false
           | Restart_on_read_satisfy -> true
           end) then
           { isucc | forall (isucc IN strict_program_order_suffix t i) |
           (exists (w' IN isucc.writes_read_from).
              (w'.w_addr = w.w_addr) && not (w' = w) &&
            (not (exists (i' IN t.in_flight_instructions).
(* TODO: again, correspondence between text (which here doesn't say "(where the read was not forwarded)") and the use of write_possibly_done_by below isn't terribly clear *)
                    write_possibly_done_by t.thread i'.behaviour w')))
           }
   else {}
       in
       let (t',ist') = restart_dependent_subtrees m t irestarts ist in
       let isem = i.behaviour in
       let isem' = mem_read_action isem w.w_value in
       let i' = <| i with behaviour = isem'; read_responses = i.read_responses union {<| rr_thread = r.r_thread; rr_ioid = r.r_ioid; rr_eiid = r.reiid; rr_write = w |>}; writes_read_from = i.writes_read_from union {w} ; has_done_computation = true |> in
       let t'' = <| t' with in_flight_instructions = (t'.in_flight_instructions union {i'}) \ {i} |> in
       (t'',ist')
*)

(* this function is used by both PLDI11 and POP *)
let read_unmapped_memory_action state iic rr slices =
  let i' =
    <|  iic.iic_instance with
        micro_op_state = MOS_pending_exception (ET_read_from_unmapped_memory rr slices);
    |>
  in

  <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
  $> make_thread_cont_res {} {}

let write_unmapped_memory_action state iic writes =
  let i' =
    <|  iic.iic_instance with
        micro_op_state = MOS_pending_exception (ET_write_to_unmapped_memory writes);
    |>
  in

  <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
  $> make_thread_cont_res {} {}


let pldi11_satisfy_read_action params state iic rr (mrss: list memory_read_source) =
  let new_writes_read_from = List.concat ( [ mrs.mrs_writes_read_from | forall (mrs MEM mrss)| true] ) in
  let writes_previously_read_from =
    ensure_just (List.lookup rr iic.iic_instance.subreads.sr_writes_read_from)
      $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show iic.iic_instance.instance_ioid
  in
  let subreads' =
    <|  iic.iic_instance.subreads with
                 sr_unsat_slices = updateAssocList rr [] iic.iic_instance.subreads.sr_unsat_slices;
                 sr_writes_read_from = updateAssocList rr (new_writes_read_from ++ writes_previously_read_from) iic.iic_instance.subreads.sr_writes_read_from;
               |>
  in
  let i' = <| iic.iic_instance with subreads = subreads' |> in

  (* we do the memory_read_action restart stuff on the suffix *)
  (* (we could defer the restart stuff to the actually_satisfy part,
  but it's probably clearer in the UI to have it here) *)
  (* TODO: assuming restarts for the writes_previously_read_from (by forwarding) already dealt with elsewhere*)

  let (it', restarted_ioids) =
    let it = iic.subtree in
    pldi11_memory_read_action_restart_roots params iic.iic_instance it rr (Set.fromList new_writes_read_from)
    $> restart_dependent_subtrees it
  in

  <| state with instruction_tree = apply_tree_context iic.context (i', it') |>
  $> make_thread_cont_res restarted_ioids {}


let pop_satisfy_read_from_storage_action params
    (state:         thread_state 'i)
    (inst_context:  instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let subreads = inst_context.iic_instance.subreads in

  (* the reply from storage includes the forward-writes, but they might
  be old (from when the read was issued), so we need to set the value
  for writes that were forwarded without value *)
  let write_slices =
    (* as this is the point where we get the reply from storage, any write
    in sr_writes_read_from must be from write-forwarding *)
    let forward_writes =
      ensure_just (List.lookup request subreads.sr_writes_read_from)
        $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show inst_context.iic_instance.instance_ioid
    in
    let update_write_forwarding_value write =
      match List.find (fun (w', _) -> w'.weiid = write.weiid) forward_writes with
      | Just (w', _)  -> w'
      | Nothing -> write
      end
    in
    [(update_write_forwarding_value w, s) | forall ((w, s) MEM write_slices) | true]
  in

  if pop_is_stale_read params state inst_context request (Set.fromList write_slices) then
    (* NOTE: maybe, instead of restarting the instruction we should
        just allow 'request' to be re-issued? Things to consider:
        - when a write is propagated how do we know an non-finished
          po-previous read to the same address will not be re-issued?
        - when a store is committed and a write from the store was
          forwarded to a po-after read but only partially satisfied the
          read, we must make sure the other half of the read was issued
          and will not be re-issued after the store is committed (since
          po-after instructions don't have a fully determined addresses
          this is extra tricky).
        - a read can be issued only after all po-previous load-acquires
          have been issued. Therefore when a load-acquire is allowed to
          be re-issued we need to do something with po-after loads. *)
    let (it', restarted_ioids) =
      restart_dependent_subtrees
        (T [(inst_context.iic_instance, inst_context.subtree)])
        {inst_context.iic_instance}
    in
    let inst_and_it' =
      match it' with
      | T [inst_and_it'] -> inst_and_it'
      | _ -> failwith "expected rooted tree"
      end
    in

    let pop_substate = get_pop_thread_substate state.thread_substate in
    let pop_substate = pop_remove_restarted_reads_from_order pop_substate restarted_ioids in

    <| state with
        instruction_tree = apply_tree_context inst_context.context inst_and_it';
        thread_substate = POP_thread pop_substate;
    |>
    $> make_thread_cont_res restarted_ioids {}
  else

  let subreads' =
    <|  subreads with
        sr_unsat_slices = updateAssocList request [] subreads.sr_unsat_slices;
        sr_writes_read_from = updateAssocList request write_slices subreads.sr_writes_read_from;
        (* don't remove 'request' from 'sr_requested', see comment in machineDefTypes *)
    |>
  in

  let instruction' = <| inst_context.iic_instance with subreads = subreads' |> in

  (* do restarts *)
  let irestart_roots =
    pop_memory_read_action_restart_roots params
      state
      inst_context.subtree
      request
      (Just (Set.fromList write_slices))
  in

  let (it', restarted_ioids) = restart_dependent_subtrees inst_context.subtree irestart_roots in
  let it'' = handle_restart_dc request.r_addr it' in
  let pop_substate = get_pop_thread_substate state.thread_substate in
  let pop_substate' = pop_remove_restarted_reads_from_order pop_substate restarted_ioids in

  <| state with
      instruction_tree = apply_tree_context inst_context.context (instruction', it'');
      thread_substate = POP_thread pop_substate';
  |>
  $> make_thread_cont_res restarted_ioids {}


let tso_satisfy_read_from_storage_action
    (state:         thread_state 'i)
    (inst_context:  instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let subreads = inst_context.iic_instance.subreads in

  let subreads' =
    <|  inst_context.iic_instance.subreads with
        sr_unsat_slices = updateAssocList request [] subreads.sr_unsat_slices;
        sr_writes_read_from = updateAssocList request write_slices subreads.sr_writes_read_from;
        (* don't remove 'request' from 'sr_requested', see comment in machineDefTypes *)
    |>
  in

  let instruction' = <| inst_context.iic_instance with subreads = subreads' |> in

  <| state with
      instruction_tree = apply_tree_context inst_context.context (instruction', inst_context.subtree);
  |>
  $> make_thread_cont_res {} {}


let relaxed_satisfy_read_from_storage_action
    (state:         thread_state 'i)
    (inst_context:  instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let subreads = inst_context.iic_instance.subreads in

  let subreads' =
    <|  subreads with
        sr_unsat_slices = updateAssocList request [] subreads.sr_unsat_slices;
        sr_writes_read_from = updateAssocList request write_slices subreads.sr_writes_read_from;
    |>
  in

  let instruction' = <| inst_context.iic_instance with subreads = subreads' |> in

  <| state with
      instruction_tree = apply_tree_context inst_context.context (instruction', inst_context.subtree);
  |>
  $> make_thread_cont_res {} {}


let satisfy_read_action params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (read:         read_request)
    : (list memory_read_source) -> thread_cont_res (thread_state 'i)
  =
  fun mrss ->
    match params.thread_model with
    | PLDI11_thread_model -> pldi11_satisfy_read_action params state inst_context read mrss
    | POP_thread_model _ ->
        match mrss with
        | [mrs]  -> pop_satisfy_read_from_storage_action params state inst_context read mrs.mrs_writes_read_from
        | _ -> failwith "expected one mrs"
        end
    | TSO_thread_model ->
        match mrss with
        | [mrs]  -> tso_satisfy_read_from_storage_action state inst_context read mrs.mrs_writes_read_from
        | _ -> failwith "expected one mrs"
        end
    | Promising_thread_model -> fail
    | Relaxed_thread_model ->
        match mrss with
        | [mrs]  -> relaxed_satisfy_read_from_storage_action state inst_context read mrs.mrs_writes_read_from
        | _ -> failwith "expected one mrs"
        end
    end



(** Satisfy memory read by forwarding in-flight write directly to reading instruction *)

(* TODO: this function was written for POP, Susmit should make sure it works for
PLDI11 and if it does remove the pop_ prefix from the name *)
let pop_possible_write_forwarding
    (params:       thread_params)
    (isa:          isa 'i)
    (state:        thread_state 'i)
    (iic:          instruction_in_context 'i)
    (rr:           read_request)
    (unsat_slices: slices)
    : slices * list (write * slices) (* unsat-read-slices, writes-read-from-slices *)
  =
  (* collect all the write slices that can affect the forward (i.e. be
  forwarded or block other write slices from being forwarded) *)
  let write_slices =
    List.concatMap
      (fun i ->
        complete_writes i.subwrites.sw_potential_write_addresses ++
          
        (complete_writes i.subwrites.sw_potential_writes) ++

        (* the rest of the writes are used for blocking other writes: *)
        (* although propagated writes will not be forwarded, we need
           them in the list so they can cover other writes in the
           initial call to match_writes *)
        (complete_writes i.subwrites.sw_propagated_writes) ++
        (* writes that other loads read from block po-earlier writes, but don't
           take writes from this thread, we will get them from the store
           instructions *)
        (List.filter (fun (write, _) -> write.w_thread <> state.thread) (writes_read_from i))
      )
      iic.active_prefix
  in

  (* find out what slices can be read from *)
  let (_, write_slices) = match_writes rr.r_addr unsat_slices write_slices [] in

  let nonforward_writes =
    Set.fromList
      (List.concatMap
          (fun i ->
            if  (is_AArch64_load_acquire (ik iic.iic_instance) && 
                   is_AArch64_store_exclusive (ik i))
                || is_RISCV_store_conditional (ik i)
                || is_PPC_store_conditional (ik i)
            then
              (* AArch64: don't forward store-exclusives to load-acquire.
                    See also private note THREAD6. *)
              (* PPC: don't forward store-conditionals *)
              (* RISC-V: don't forward store-conditionals *)
              i.subwrites.sw_potential_write_addresses
              ++ i.subwrites.sw_potential_writes
              ++ i.subwrites.sw_propagated_writes
            else
              (* we don't want propagated writes *)
              i.subwrites.sw_propagated_writes
              ++
                (* When running any model other than POP for ARM,
                   don't allow forwarding from writes that do not have
                   their value yet. In POP for ARMv8 we will try to
                   forward these writes, see private comments THREAD4
                   and THREAD5 *)
                (match (isa.isa_model, params.thread_model) with
                 | (AARCH64 _, POP_thread_model Standard_POP) -> []
                 | (AARCH64 _, _) -> i.subwrites.sw_potential_write_addresses
                 | (PPC, _)  -> i.subwrites.sw_potential_write_addresses
                 | (MIPS, _)    -> i.subwrites.sw_potential_write_addresses
                 | (RISCV, _)   -> i.subwrites.sw_potential_write_addresses
                 | (X86, _)     -> i.subwrites.sw_potential_write_addresses
                 end)
          )
          iic.active_prefix)
  in

  (* remove slices we should not be forwarding (i.e. propagated or from
  other threads) *)
  let clean_write_slices =
    List.mapMaybe
      (fun (w, s) ->
        if w IN nonforward_writes then Nothing
        else if w.w_thread <> state.thread then Nothing (* we don't want writes from other threads *)
        else Just (w, s))
      write_slices
  in

  (* the second element of the result should be exactly the same as
  clean_write_slices, we need this call to get the correct first element,
  the 'unsat-read-slices' *)
  match_writes rr.r_addr unsat_slices clean_write_slices []


(* TODO: (SF) I copied the pop function and made minor changes to adopt
it to PLDI11, Susmit should check it *)
let pldi11_satisfy_read_by_forwarding_action params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (request:      read_request)
    ((unsat_slices: slices),
     (writes: list (write * slices)))
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let subreads = i.subreads in

  let writes_read_from = ensure_just (List.lookup request subreads.sr_writes_read_from)
    $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show inst_context.iic_instance.instance_ioid
  in
  let subreads' =
    <|  subreads with
        sr_unsat_slices = updateAssocList request unsat_slices subreads.sr_unsat_slices;
        sr_writes_read_from = updateAssocList request (writes ++ writes_read_from) subreads.sr_writes_read_from;
    |>
  in

  let i' = <| i with subreads = subreads' |> in

  (* do restarts *)
  let (it', restarted_ioids) =
    let it = inst_context.subtree in
    Set.fromList writes
    $> pldi11_memory_read_action_restart_roots params i it request
    $> restart_dependent_subtrees it
  in

  <| state with
      instruction_tree = apply_tree_context inst_context.context (i', it');
  |>
  $> make_thread_cont_res restarted_ioids {}


let pop_satisfy_read_by_forwarding_action params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (request:      read_request)
    ((unsat_slices:  slices),
     (writes: list (write * slices)))
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let subreads = i.subreads in

  let writes_read_from = ensure_just (List.lookup request subreads.sr_writes_read_from)
    $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show inst_context.iic_instance.instance_ioid
  in
  let subreads' =
    <|  subreads with
        sr_unsat_slices = updateAssocList request unsat_slices subreads.sr_unsat_slices;
        sr_writes_read_from = updateAssocList request (writes ++ writes_read_from) subreads.sr_writes_read_from;
    |>
  in

  let i' = <| i with subreads = subreads' |> in

  (* do restarts *)
  let (it', restarted_ioids) =
    let it = inst_context.subtree in

    Just (Set.fromList writes)
    $> pop_memory_read_action_restart_roots params state it request
    $> restart_dependent_subtrees it
  in

  let it'' = handle_restart_dc request.r_addr it' in

  let pop_substate = get_pop_thread_substate state.thread_substate in
  let pop_substate' = pop_remove_restarted_reads_from_order pop_substate restarted_ioids in

  <| state with
      instruction_tree = apply_tree_context inst_context.context (i', it'');
      thread_substate  = POP_thread pop_substate';
  |>
  $> make_thread_cont_res restarted_ioids {}

let init_fetch_instruction params
    (state:           thread_state 'i)
    (complete_prefix: list (instruction_instance 'i))
    : address -> FreshIds.id_state thread_id * list (instruction_instance 'i)
  = fun addr ->
      let () = ensure
          (params.thread_fail_on_loop -->
              not (exists (i MEM complete_prefix). i.program_loc = addr))
          $ "found a loop in thread " ^ show state.thread
      in

      let (ioid', id_state') = FreshIds.gen_fresh_id state.id_state in
      let i' = starting_fetch_inst params ioid' addr in

      match (params.thread_loop_unroll_limit, complete_prefix) with
      | (Nothing, _) -> (id_state', [i'])
      | (_, [])      -> (id_state', [i'])
      | (Just limit, iprev :: _) ->
          if addr <= iprev.program_loc
            && (exists (iprev MEM complete_prefix). iprev.program_loc = addr)
            && (_count_pairs complete_prefix iprev.program_loc addr 0) + 1 >= limit
          then
            (* we've hit the unroll limit *)
            let i' = <| i' with micro_op_state = MOS_pending_exception ET_loop_limit_reached |> in
            (id_state', [i'])
          else
            (id_state', [i'])
      end

(* FDO cases for decode ...
  | FDO_address_not_concrete ->
      let (ioid', id_state') = FreshIds.gen_fresh_id state.id_state in
      (id_state', [starting_fetch_exception_inst_instance ioid' FDE_non_concrete_fetch_address_error addr])

  | FDO_illegal_fetch_address ->
      let (ioid', id_state') = FreshIds.gen_fresh_id state.id_state in
      (id_state', [starting_fetch_exception_inst_instance ioid' (FDE_illegal_fetch_address_error addr) addr])

  | FDO_decode_error de ->
      let (ioid', id_state') = FreshIds.gen_fresh_id state.id_state in
      (id_state', [starting_fetch_exception_inst_instance ioid' (FDE_decode_error de addr) addr])
  end
*)


let get_fetch_instruction_continuation
    (isa :         isa 'i)
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (addr:         address)
    : (fetched 'i -> thread_cont_res (thread_state 'i))
  =
  fun f ->
    let i =
        match f with
        | Fetched_FDO FDO_unpredictable_fetch ->
            <| inst_context.iic_instance with
                micro_op_state = MOS_unpredictable |>
        | _ ->
            <| inst_context.iic_instance with
                micro_op_state = MOS_fetch (Just f);
                instruction =
                    match f with
                    | Fetched_FDO (FDO_success _ _ ast) -> Fetched ast
                    | Fetched_Mem _ (FDO_success _ _ ast) -> Fetched ast
                    | _ -> Fetch_error
                    end
            |>
        end
    in
        <|  state with
            instruction_tree = apply_tree_context inst_context.context (i,inst_context.subtree);
        |>
    $> make_old_instructions isa
    $> make_thread_cont_res {} {}


(**: \subsubsection{The Collected Thread Transitions} :*)

(* enumerate all thread-initiated transitions *)

(* is the result of a thread transition uniformly a new thread_state?  No,
   because some of them need data from the storage subsystem, so the
   thread_trans will contain a suitable continuation *)

(* does a thread transition uniformly arise from a particular instruction
   instance?  I guess so, except for the initial fetch, and so we can uniformly
   include an ioid (or the whole instruction_instance?) in the result *)

let po_predecessors_all_finished (iic: instruction_in_context 'i) : bool =
  forall (iprev MEM iic.active_prefix).
    iprev.finished


(** enumerate all instruction transitions of thread *****************)

let handle_read_mem_outcome params
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    ((read_kind: read_kind),(addr_lifted: address_lifted),(size: nat))
    (cont: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let addr = ensure_just (address_of_address_lifted addr_lifted)
                        "Read_mem from a non-concrete address"
    in

    pending_memory_read_request_action params isa state iic read_kind (addr,size) cont
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic T_pending_memory_read_request state')]


let handle_write_ea_outcome
    (params: thread_params)
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    ((write_kind: write_kind),(addr_lifted: address_lifted),(size: nat))
    (is': outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* Are we (1) going to try committing a Write_mem (including
     write-conditionals, remember) as soon as we see it (eagerly doing remaining
     register transitions), or (2) somehow remember the bool continuation and
     progress (depending on some heavy constraints on what write-conditionals do
     'after' the write), or (3) commit the Write_mem as soon as we see it, but
     leave the instruction in a committed-but-not-yet-finished state, with the
     remaining register transitions still to do?  Option (3). *)

  (* THIS IS A BIT OUT OF DATE Our new scheme involves committing an instruction
     at the point it hits a write, but for write forwarding we have to be able
     to see a write that the pseudocode of an instruction has reached even if
     commit_cand is still false.  That suggests we should split the commit-write
     transition into two: one (T_potential_mem_write_plain) to note the write as
     potentially available for forwarding (but subject to restart) and one
     (T_commit_mem_write_plain) to commit that write, with an intermediate
     MOS_potential_mem_write micro-op state *)

  let i = iic.iic_instance in
  let () = ensure (i.subwrites.sw_addr = Nothing) "already handled Write_ea outcome for this instruction" in

  let address = ensure_just (address_of_address_lifted addr_lifted)
                          "Write_mem to a non-concrete address" in

  let (potential_write_addresses, id_state') =
    if params.thread_restriction = RestrictionSC then
      Events.make_empty_write_events'
        i.instance_id_state state.thread i.instance_ioid address size size write_kind
    else
      make_empty_write_events_ii isa state.thread i (address, size) write_kind
  in

  let state' = fun () ->
    let i' =
      <| i with
          micro_op_state = MOS_plain is';
          subwrites = <| i.subwrites with
              sw_addr = Just (address, size);
              sw_potential_write_addresses = potential_write_addresses;
          |>;
          instance_id_state = id_state';
      |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in

  [T_only (make_label state iic (T_mem_write_footprint potential_write_addresses) state')]


let handle_write_memv_outcome
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (value: memory_value)
    (cont: bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = ensure (i.subwrites.sw_potential_write_addresses <> []) "expected to have potential_write_addresses" in

  let potential_writes = Events.set_write_values value i.subwrites.sw_potential_write_addresses [] in

  let update_write_forwarding_value it : instruction_tree 'i =
    let update i =
      let update_writes (writes: list (write * slices)) =
        let update_write write =
          match List.find (fun w' -> w'.weiid = write.weiid) potential_writes with
          | Just w' -> w'
          | Nothing -> write
          end
        in

        [(update_write w, s) | forall ((w, s) MEM writes) | true]
      in

      let sr_writes_read_from' =
        [(rr, update_writes writes) | forall ((rr, writes) MEM i.subreads.sr_writes_read_from) | true]
      in

      let subreads' =
        <| i.subreads with sr_writes_read_from = sr_writes_read_from' |>
      in

      <| i with subreads = subreads'  |>
    in

    instruction_tree_map (fun _ i _ -> update i) [] it
  in

  let state' = fun () ->
    let i' =
      <| i with
        micro_op_state = MOS_potential_mem_write cont;
        subwrites = <| i.subwrites with
            sw_potential_write_addresses = [];
            sw_potential_writes = potential_writes;
        |>
      |>
    in

    let it' = update_write_forwarding_value iic.subtree in
    <| state with instruction_tree = apply_tree_context iic.context (i', it') |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic (T_mem_potential_write potential_writes) state')]

let cache_maintenance_trans_ic
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (addr:   address) 
    (o: outcome_S) =
  guard (
        forall (iprev MEM iic.active_prefix).
          (is_AArch64_ic_wait_barrier (ik iprev) --> iprev.finished)
  ) >>

  let i = iic.iic_instance in
  let state' =
      fun () ->
        let i' = <| i with micro_op_state = MOS_wait_IC o |> in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
  in
  let lbl =
      <| cmr_cmk = CM_IC;
         cmr_ioid = i.instance_ioid;
         cmr_addr = addr;
      |>
  in
  [T_sync (T_propagate_cache_maintenance (make_label state iic lbl state')) ()]

let cache_maintenance_trans_dc
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (addr:   address)
    (o:      outcome_S) =
  (* wait for po-previous DMB/DSB *)
  guard (
        forall (iprev MEM iic.active_prefix).
          (is_AArch64_dc_wait_barrier (ik iprev) --> iprev.finished)
  ) >>

  let i = iic.iic_instance in
  let state' =
      fun () ->
        let i' = <| i with micro_op_state = MOS_plain o |> in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
  in
  let lbl =
      <| cmr_cmk = CM_DC;
         cmr_ioid = i.instance_ioid;
         cmr_addr = addr;
      |>
  in
  [T_sync (T_propagate_cache_maintenance (make_label state iic lbl state')) ()]

let handle_barrier_outcome
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (bk:     barrier_kind)
    (is':    outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* Note: in the new scheme, it's more natural to do the whole barrier commit now *)
  (* NEWTODO: have to do the rest of the barrier action - check what we did in old ppcmem*)

  let i = iic.iic_instance in

  guard match params.thread_model with
        | PLDI11_thread_model    -> pldi11_commit_cand state iic
        | POP_thread_model _     -> pop_commit_barrier_cand params isa iic
        | TSO_thread_model       -> true
        | Promising_thread_model -> fail
        | Relaxed_thread_model   -> true
        end >>

  let (b, id_state') = Events.make_barrier_event i.instance_id_state state.thread i.instance_ioid bk in

  let state' = fun () ->
    let i' =
      <| i with
        instance_id_state  = id_state';
        micro_op_state     = MOS_plain is';
        committed_barriers = b :: i.committed_barriers;
      |>
    in
    let sub' = 
        if is_AArch64_isb_barrier (ik i) then
            instruction_tree_map
              (fun _ i _ ->
                match i.micro_op_state with
                | MOS_fetch _ ->
                    starting_fetch_inst params i.instance_ioid i.program_loc
                | s -> i
                end)
            []
            iic.subtree
        else
            iic.subtree
    in
    let s' = <| state with instruction_tree = apply_tree_context iic.context (i', sub') |> in

    match params.thread_model with
    | PLDI11_thread_model    -> pldi11_commit_barrier_action s' b
    | POP_thread_model _     -> s'
    | TSO_thread_model       -> s'
    | Promising_thread_model -> fail
    | Relaxed_thread_model   -> s'
    end
    $> make_thread_cont_res {} {}
  in

  if is_flat_model params
    || is_pop_instruction_barrier (ik i)
    || is_AArch64_ld_barrier (ik i)
    || (params.thread_model = TSO_thread_model && 
          isa.isa_model = RISCV &&  not (is_RISCV_fence_pw (ik i)))
    || params.thread_model = Relaxed_thread_model
  then
    (* barriers that are not sent to storage *)
    (* see discussion on DMB LD in private notes60 *)
    [T_only (make_label state iic (T_commit_barrier b) state')]
  else
    (* memory barriers are passed to the storage subsystem *)
    [T_sync (T_propagate_barrier (make_label state iic b state')) ()]

  (* for barriers with acks (such as sync), how are the commit and the sync
     related?  Not at all - the test that the sync has been ack'd occurs
     elsewhere in the thread semantics, in the commit-cand and read-satisfy-cand
     checking for po-later instructions *)


let handle_read_reg_outcome
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (r: reg_name)
      (c: register_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i)) =

  let i = iic.iic_instance in

  if is_pseudo_register isa r then
    (* pseudo registers have a predetermined values and the
    transition is T_internal *)
    let v = pseudo_register_value isa i.program_loc r in
    let state' = fun () ->
      let i' = <| i with micro_op_state = MOS_plain (c v);
                        reg_reads = (r,[RRS_pseudoregister],v)::i.reg_reads;  |> in
      <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
      $> make_thread_cont_res {} {}
    in
    [T_only (make_label state iic (T_pseudoreg_read r v) state')]

  else
    (* *don't* allow reading from reg writes by the same instruction,
       otherwise we get self-blocked. But some 2.06B pseudocode does
       read from self-writes; we allow that by patching the pseudocode
       (otherwise we'd need more fine-grained dependency tracking *)
    match find_reg_read (Just (state.register_data, state.initial_register_state)) r (iic.active_prefix ++ iic.old_prefix)  with
    | FRRO_blocked _ -> []
    | FRRO_not_found -> fail
    | FRRO_found (rrs:register_read_sources) (v:register_value) ->
        let state' = fun () ->
          let i' = <| i with (*reg_read_from_ioids =
                             i.reg_read_from_ioids union
                             match rrs with RRS_instruction i'' -> {i''.instance_ioid} | RRS_initial_state -> {} end ;*)
                             micro_op_state = MOS_plain (c v);
                             reg_reads = (r,rrs,v)::i.reg_reads;
                  |>
          in
          <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
          $> make_thread_cont_res {} {}
        in
        [T_only (make_label state iic (T_register_read r rrs v) state')]
    end


let handle_write_reg_outcome
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    ((r: reg_name), (v: register_value))
    (is':    outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let i = iic.iic_instance in
    let i' =
      <| i with micro_op_state = MOS_plain is';
                reg_writes = (r, (current_reg_write_dependencies i, v)) :: i.reg_writes;
      |>
    in
    <| state with
        instruction_tree = apply_tree_context iic.context (i', iic.subtree);
    |>
    $> make_thread_cont_res {} {}
  in

  let tot =
    if is_pseudo_register isa r then
      (* the only pseudo_register we expect a write to is the NIA/PC register *)
      let () = ensure (register_base_name r = register_base_name isa.nia_reg)
        $ "write reg of non-NIA/PC pseudoregister (" ^ show r ^ ")"
      in
      T_pseudoreg_write r v
    else
      T_register_write r v
  in
  [T_only (make_label state iic tot state')]

let handle_internal_outcome
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (_: (maybe string * maybe (unit -> string)))
    (is': outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let i = iic.iic_instance in
    let i' = <| i with micro_op_state = MOS_plain is' |> in
    <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic T_internal_outcome state')]


let handle_footprint_outcome
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (old_outcome : outcome_S)
    (is': outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let i = iic.iic_instance in

    let () = ensure (isa.isa_model = PPC) "expected PPC" in

    let i' = <| i with micro_op_state = MOS_plain is' |> in
    let i'' = recalculate_register_footprint isa i' old_outcome
                                            (iic.active_prefix ++ iic.old_prefix) in
    let it' = recalculate_ioids_feeding_address (i'' :: (iic.active_prefix ++ iic.old_prefix)) iic.subtree in
    <| state with instruction_tree = apply_tree_context iic.context (i'',it') |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic T_footprint_outcome state')]


let thread_start
    (isa: isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  let try_reg_read maybe_reg reads =
    match maybe_reg with
    | Just reg ->
        match
          find_reg_read (Just (state.register_data, state.initial_register_state)) reg
              (iic.active_prefix ++ iic.old_prefix)
        with
        | FRRO_found rrs v -> Just (Just v, (reg, rrs, v) :: reads)
        | _ -> Nothing
        end
    | Nothing -> Just (Nothing, reads)
    end
  in

  let start_info = isa.thread_start_info in
  option_guard (try_reg_read (Just start_info.tsi_addr) []) >>= fun (maybe_addr_v,reads) ->
  let addr_v = ensure_just maybe_addr_v "fail" in
  option_guard (try_reg_read start_info.tsi_toc reads) >>= fun (toc_v, reads) ->
  option_guard (try_reg_read start_info.tsi_extra reads) >>= fun (_, reads) ->

  let thread_continuation = fun new_tid ->
    let new_tid_rv =
      match new_tid with
      | Just new_tid -> integerFromNat new_tid
      | Nothing      -> ~1 (* i.e. -1 *)
      end
      $> register_value_for_reg_of_integer start_info.tsi_return
    in
    let i' =
      <| i with
          reg_reads = reads ++ i.reg_reads;
          reg_writes = (start_info.tsi_return, (current_reg_write_dependencies i, new_tid_rv))
            :: i.reg_writes;
          finished = true;
      |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
    $> make_old_instructions isa
    $> make_thread_cont_res {} {}
  in

  [T_thread_start (make_label state iic (addr_v, toc_v) thread_continuation)]


let handle_done_outcome
      (params: thread_params)
      (isa: isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  guard (not (i.subwrites.sw_committed || i.committed_barriers <> []) -->
         match params.thread_model with
         | PLDI11_thread_model    -> pldi11_commit_cand state iic
         | POP_thread_model _     -> pop_finish_cand params state iic
         | TSO_thread_model       -> true
         | Promising_thread_model -> fail
         | Relaxed_thread_model   -> true
         end) >>

  guard (is_AArch64_dc_instr (ik i) --> flat_can_finish_dc iic) >>

  let instr = ensure_fetched i.instruction in

  if isa.is_thread_start_instruction instr then
    (* special case for thread creation pseudo-instruction *)
    guard (forall (iprev MEM iic.active_prefix). 
           if is_pop_strong_memory_barrier (ik iprev)
           then iprev.finished else true) >>
    thread_start isa state iic
  else
    let state' = fun () -> finish_action isa state iic in
    let addr = i.program_loc in
    [T_only (make_label state iic (T_finish addr instr) state')]


let handle_sail_termination
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (msg: string)
    : list (thread_trans 'i (thread_state 'i))
  =
  guard (po_predecessors_all_finished iic) >>
  let state' = fun () -> make_thread_cont_res {} {} state in
  [T_only (make_label state iic (T_exception (ET_ISA_termination msg)) state')]


let enumerate_write_forward_transitions_pop
    (params: thread_params)
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (unsat_slices <> []) >>
  (* filter out already-requested reads *)
  guard (lookup rr i.subreads.sr_requested = Nothing) >>
  let (unsat_slices,sliced_writes) =
    pop_possible_write_forwarding params isa state iic rr unsat_slices in
  guard (sliced_writes <> []) >>
  let state' = fun () ->
    pop_satisfy_read_by_forwarding_action params state iic rr (unsat_slices, sliced_writes)
  in
  [T_only (make_label state iic (T_mem_forward_write rr sliced_writes) state')]


let enumerate_write_forward_transitions_pldi11
      (params: thread_params)
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i)) =

  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (unsat_slices <> []) >>
  (* filter out already-requested reads *)
  guard (lookup rr i.subreads.sr_requested = Nothing) >>
  (* TODO: (SF) I copied the write forwarding from POP,
     Susmit should make sure this is good for PLDI11 *)
  let (unsat_slices,sliced_writes) =
    pop_possible_write_forwarding params isa state iic rr unsat_slices in
  guard (sliced_writes <> []) >>
  let state' = fun () ->
    pldi11_satisfy_read_by_forwarding_action params state iic rr (unsat_slices, sliced_writes)
  in
  [T_only (make_label state iic (T_mem_forward_write rr sliced_writes) state')]


let enumerate_write_forward_transitions_relaxed
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (unsat_slices <> []) >>
  (* filter out already-requested reads *)
  guard (lookup rr i.subreads.sr_requested = Nothing) >>
  let (unsat_slices,sliced_writes) =
    let write_slices =
      List.concatMap
        (fun i -> complete_writes i.subwrites.sw_potential_writes)
        iic.active_prefix
    in
    match_writes rr.r_addr unsat_slices write_slices []
  in
  guard (sliced_writes <> []) >>
  let state' = fun () ->
    let subreads = i.subreads in

    let writes_read_from = ensure_just (List.lookup rr subreads.sr_writes_read_from)
      $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show iic.iic_instance.instance_ioid
    in
    let subreads' =
      <|  subreads with
          sr_unsat_slices = updateAssocList rr unsat_slices subreads.sr_unsat_slices;
          sr_writes_read_from = updateAssocList rr (sliced_writes ++ writes_read_from) subreads.sr_writes_read_from;
      |>
    in

    let i' = <| i with subreads = subreads' |> in

    <| state with
        instruction_tree = apply_tree_context iic.context (i', iic.subtree);
    |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic (T_mem_forward_write rr sliced_writes) state')]


let enumerate_write_forward_transitions
      (params: thread_params)
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i)) =
  match params.thread_model with
  | PLDI11_thread_model ->
      enumerate_write_forward_transitions_pldi11 params isa state iic c
  | POP_thread_model _ ->
      enumerate_write_forward_transitions_pop params isa state iic c
  | TSO_thread_model -> []
  | Promising_thread_model -> fail
  | Relaxed_thread_model ->
      enumerate_write_forward_transitions_relaxed state iic c
  end

let enumerate_read_request_transitions
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  guard (not (is_flat_model params)) >>
  guard (params.thread_model <> TSO_thread_model) >>
  guard (params.thread_model <> Relaxed_thread_model) >>

  let i = iic.iic_instance in

  let successful_exclusives =
    if is_atomic_load (ik i) then
      let s = paired_atomic_stores i iic.subtree in
      let s = {i.instance_ioid | forall (i MEM s) | i.successful_atomic_store = Just true} in
      if s <> {} then Just s else Nothing
    else Nothing
  in

  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* no need to request satisfied reads, except for load-acquire, where we
     need the satisfied read to act as a token, and for load-exclusive where
     we need storage to know it needs to guarantee atomicity *)
  guard (unsat_slices <> []
        || is_AArch64_load_acquire (ik i)
        || is_RISCV_load_strong_acquire (ik i)
        || is_atomic_load (ik i)) >>
  guard (List.lookup rr i.subreads.sr_requested = Nothing) >>

  let state' = function
    | true ->
        let subreads =
          <| i.subreads with sr_requested = (rr, unsat_slices) :: i.subreads.sr_requested |>
        in
        let i = <| i with subreads = subreads |> in
        let state = <| state with instruction_tree = apply_tree_context iic.context (i, iic.subtree) |> in

        if params.thread_model = POP_thread_model Standard_POP then
          let pop_substate = get_pop_thread_substate state.thread_substate in
          let read_issuing_order =
            relonAddToTheRight
              (fun rr' -> non_empty_intersection rr'.r_addr rr.r_addr)
              rr
              pop_substate.read_issuing_order
          in
          let pop_substate = <| read_issuing_order = read_issuing_order |> in
          <| state with thread_substate = POP_thread pop_substate |>
          $> make_thread_cont_res {} {}
        else
          make_thread_cont_res {} {} state

    | false ->
        read_unmapped_memory_action state iic rr unsat_slices
    end
  in

  (* to guarantee single-copy atomicity, storage needs to know which
      writes the read has already read from. *)
  let writes_read_from = ensure_just (List.lookup rr i.subreads.sr_writes_read_from)
    $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show i.instance_ioid
  in
  [(T_sync (T_mem_read_request (make_label state iic (rr, unsat_slices, writes_read_from, successful_exclusives) state')) ())]

      

let enumerate_pldi11_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* for each read_request and its unsat_slices .. *)
  guard ((List.lookup rr i.subreads.sr_requested) <> Nothing) >>
  guard (unsat_slices <> []) >>
  let state' = satisfy_read_action params state iic rr in
  [T_sync (T_PLDI11_mem_satisfy_read (make_label state iic (rr, unsat_slices) state')) ()]


let enumerate_flat_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  let successful_atomic_stores =
    if is_AArch64_load_exclusive (ik i) then
      let s = paired_atomic_stores i iic.subtree in
      let s = {i.instance_ioid | forall (i MEM s) | i.successful_atomic_store = Just true} in
      if s <> {} then Just s else Nothing
    else Nothing
  in

  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (List.lookup rr i.subreads.sr_requested = Nothing && unsat_slices <> []) >>

  let state' = function
    | Just mrss ->
      let subreads' =
        <| i.subreads with sr_requested = (rr, unsat_slices) :: i.subreads.sr_requested |>
      in
      let i' = <| i with subreads = subreads' |> in
      let iic' = <| iic with iic_instance = i' |> in
      satisfy_read_action params state iic' rr mrss
    | Nothing ->
      read_unmapped_memory_action state iic rr unsat_slices
    end
  in

  let writes_read_from =
    ensure_just (List.lookup rr i.subreads.sr_writes_read_from)
      $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show i.instance_ioid
  in
  let label = make_label state iic (rr, unsat_slices, writes_read_from, successful_atomic_stores) state' in
  [(T_sync (T_Flat_mem_satisfy_read label) ())]

  (* TODO SUBREADS: should forwarding be for sr_not_yet_requested or
     sr_requested?  If the latter, by requesting a rr we exclude the
     possibility of forwarding? *)
(*
   List.map
     (fun (rr,rrs) ->
       (* add the forwarded one *)
       match params.thread_model with
       | PLDI11_thread_model ->
           match pldi11_possible_memory_read_source iic rr with
           | Just mrs ->
               let read_from_forwarded_t = pldi11_satisfy_read_action params state iic rr (c mrs.mrs_value) mrs in
                 [(i.instance_ioid, (T_only (T_mem_forward_write rr mrs read_from_forwarded_t), ist'))] in
           | Nothing -> []
           end

       | POP_thread_model ->
           match pop_possible_memory_read_source iic rr with
           | Just mrs ->
               (* get the updated iic from pending_memory_read_t *)
               let in_flights_context =
                 in_flight_instructions pending_memory_read_t.instruction_tree [] [] pending_memory_read_t.old_instructions in
               let (Just iic') = List.find (fun iic -> iic.iic_instance.instance_ioid = i.instance_ioid) in_flights_context in

               let read_from_forwarded_t = pop_satisfy_read_action params pending_memory_read_t iic' rr c mrs.mrs_sliced_writes in

               let read_from_forwarded_transition =
                 (i.instance_ioid, (T_only (T_mem_forward_write rr mrs read_from_forwarded_t), ist')) in
               [pending_memory_read_transition; read_from_forwarded_transition]

           | Nothing -> [pending_memory_read_transition]
           end
       end
     )
     singleton_extracts sr.sr_requested
*)


let enumerate_tso_read_satisfy_from_memory_transitions 
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* for each read request and unsat_slices .. *)
  guard (List.lookup rr i.subreads.sr_requested = Nothing && unsat_slices <> []) >>
  let state' = function
    | Just mrss ->
      let subreads' =
        <| i.subreads with sr_requested = (rr, unsat_slices) :: i.subreads.sr_requested |>
      in
      let i' = <| i with subreads = subreads' |> in
      let iic' = <| iic with iic_instance = i' |> in
      satisfy_read_action params state iic' rr mrss
    | Nothing ->
      read_unmapped_memory_action state iic rr unsat_slices
    end
  in
  [T_sync (T_TSO_mem_satisfy_read (make_label state iic rr state')) ()]


let enumerate_relaxed_read_satisfy_from_memory_transitions
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (List.lookup rr i.subreads.sr_requested = Nothing && unsat_slices <> []) >>

  let state' = function
    | Just mrss ->
      let subreads' =
        <| i.subreads with sr_requested = (rr, unsat_slices) :: i.subreads.sr_requested |>
      in
      let i' = <| i with subreads = subreads' |> in
      let iic' = <| iic with iic_instance = i' |> in
      satisfy_read_action params state iic' rr mrss
    | Nothing ->
      read_unmapped_memory_action state iic rr unsat_slices
    end
  in

  let writes_read_from =
    ensure_just (List.lookup rr i.subreads.sr_writes_read_from)
      $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show i.instance_ioid
  in
  let label = make_label state iic (rr, unsat_slices, writes_read_from, Nothing) state' in
  [(T_sync (T_Flat_mem_satisfy_read label) ())]


let enumerate_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  match params.thread_model with
  | PLDI11_thread_model ->
      enumerate_pldi11_read_satisfy_from_memory_transitions params state iic c
  | POP_thread_model Standard_POP -> []
  | POP_thread_model Flat_POP ->
      enumerate_flat_read_satisfy_from_memory_transitions params state iic c
  | TSO_thread_model ->
      enumerate_tso_read_satisfy_from_memory_transitions params state iic c
  | Promising_thread_model -> fail
  | Relaxed_thread_model ->
      enumerate_flat_read_satisfy_from_memory_transitions params state iic c
  end

let enumerate_actually_satisfy_transitions
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
    (* All the writes have their values (in case they were propagated without it) *)
  guard (forall ((_, wss) MEM i.subreads.sr_writes_read_from) ((w,_) MEM wss). w.w_value <> Nothing) >>
    (* and for load-acquire, all the read-requests were issued (for the token) *)
  guard (((is_AArch64_load_acquire (ik i) || is_RISCV_load_strong_acquire (ik i))
              && not (is_flat_model params))
          -->
          (* by the following I mean the domains of the lists are identical *)
          List.length i.subreads.sr_requested = List.length i.subreads.sr_unsat_slices) >>
    (* and for load-exclusive, all the read-requests were issued (for atomicity) *)
  guard ((is_atomic_load (ik i) && not (is_flat_model params)) -->
          (* by the following I mean the domains of the lists are identical *)
          List.length i.subreads.sr_requested = List.length i.subreads.sr_unsat_slices) >>

  let sorted_writes_read_from =
    Sorting.sortByOrd
      (fun (lhs, _) (rhs, _) -> compare lhs.r_addr rhs.r_addr)
      i.subreads.sr_writes_read_from
  in
  let value = (sorted_writes_read_from >>= (comb value_of_write_slices snd)) in

  let state' = fun () ->
    let is' = c value in
    let i' =  <| i with
                micro_op_state = MOS_plain is';
                subreads =
                  <| i.subreads with sr_assembled_value = Just value; |>;
              |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  return (T_only (make_label state iic (T_actually_satisfy value) state'))


let read_request_cand params state iic = 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_memory_read_storage_cand state iic
  | POP_thread_model _     -> pop_memory_read_request_cand params iic
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end


let handle_AMO_lock
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  let () = ensure (is_RISCV_AMO (ik i)) $
    "atomic_begin in a non-RISC-V-AMO instruction (ioid " ^ show i.instance_ioid ^ ")" in
  let _ = ensure_singleton i.subreads.sr_writes_read_from $
    "AMO (ioid " ^ show i.instance_ioid ^ ") should have exactly one read-request" in
  let write = ensure_singleton i.subwrites.sw_potential_write_addresses $
    "AMO (ioid " ^ show i.instance_ioid ^ ") should have exactly one potential write with no value" in
  let () = ensure (i.subwrites.sw_potential_writes = []) $
    "AMO (ioid " ^ show i.instance_ioid ^ ") should have no potential writes (with value)" in

  (* check that the load can be satisfied *)
  guard (read_request_cand params state iic) >>

  (* check that the load part could be finished, except for the
     co-check. The co-check only works for satisfied loads, but
     should always hold due to the write commit/write propagate
     requirements below (an 'ensure' later checks that) *)
  guard (pop_finish_simple_cand state iic &&
         pop_finish_load_cand_barrier_part state iic) >>

  (* check that the store part can be committed and propagated *)
  guard (match params.thread_model with
          | POP_thread_model _     ->
              pop_commit_store_cand state iic
              && pop_write_co_check params state iic write
          | TSO_thread_model       -> true
          | PLDI11_thread_model    -> fail
          | Promising_thread_model -> fail
          | Relaxed_thread_model   -> true
          end) >>

  let state' = fun () ->
      let i' = <| i with micro_op_state = MOS_pending_mem_read c |> in
      <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
      $> make_thread_cont_res {} {}
  in
  return (T_only (make_label state iic T_RISCV_atomic_begin state'))


let handle_AMO_unlock
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (o:      outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let i' = <| iic.iic_instance with micro_op_state = MOS_plain o |> in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  return (T_only (make_label state iic T_RISCV_atomic_end state'))


let handle_memory_read
    (params: thread_params)
    (isa : isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  if (exists ((_, slices) MEM iic.iic_instance.subreads.sr_unsat_slices). slices <> []) then
    (* there are unsatisfied slices *)
    guard (read_request_cand params state iic) >>

    enumerate_write_forward_transitions params isa state iic c ++
    enumerate_read_request_transitions params state iic c ++
    enumerate_read_satisfy_from_memory_transitions params state iic c
  else 
    (* all slices are satisfied *)
    enumerate_actually_satisfy_transitions params state iic c


let enumerate_commit_store_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = ensure (not (is_RISCV_store_conditional (ik i)))
      "must not be a RISC-V store-conditional" in
      (* RISC-V store-conditional is handled elsewhere as it needs to
      commit and propagate at the same time *)

  guard (match params.thread_model with
         | PLDI11_thread_model    -> pldi11_commit_cand state iic
         | POP_thread_model _     -> pop_commit_store_cand state iic
         | TSO_thread_model       -> true
         | Promising_thread_model -> fail
         | Relaxed_thread_model   -> true
         end) >>

  let state' = fun () ->
    let i' = <| i with subwrites = <| i.subwrites with sw_committed = true |> |> in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in

  [T_only (make_label state iic T_commit_store state')]


let enumerate_propagate_write_transitions
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = ensure (not (is_RISCV_store_conditional (ik i)))
      "must not be a RISC-V store-conditional" in
      (* RISC-V store-conditional is handled elsewhere as it needs to
      commit and propagate at the same time *)

  let () = ensure (i.subwrites.sw_potential_write_addresses = []) 
    "the store has writes with no values" in

  i.subwrites.sw_potential_writes >>= fun (write: write) ->
  (* for each potential write .. *)
  guard (match params.thread_model with
         | PLDI11_thread_model    -> pldi11_propagateWritePrevMightSameAddress iic write
         | POP_thread_model _     -> pop_write_co_check params state iic write
         | TSO_thread_model       -> true
         | Promising_thread_model -> fail
         | Relaxed_thread_model   -> true
         end) >>

  let rf =
    match isa.isa_model with
    | AARCH64 _ ->
        guard (is_flat_model params) >>
        let successful_atomic_pairings =
          instruction_tree_fold_root (fun found _prefix ii it ->
            if is_atomic_load (ik ii) then
              let s = paired_atomic_stores ii it in
              let s = {i.instance_ioid | forall (i MEM s) | i.successful_atomic_store = Just true} in
              if s <> {} then Set.insert (ii, s) found else found
            else found
          ) {} [] iic.subtree
          $> Set.bigunion
          $> Set_extra.toList
        in
        (* for each load exclusive "loadx" successfully paired with "storexs" *)
        successful_atomic_pairings >>= fun (loadx,storexs) ->
        (* check all the writes loadx read from *)
        loadx.subreads.sr_writes_read_from >>= fun (read_request,writes_and_slices) ->
        (* and collect the parts (write',slices) reading from the write we're about to commit *)
        let rf = [(write',slices) | forall ((write',slices) MEM writes_and_slices) | write' = write] in
        (* unless this list is empty *)
        guard (rf <> []) >>
        (* and return the load exclusive's read_request, this list, and the store exclusive ioid *)
        return (read_request,rf,storexs)
    | RISCV     -> []
    | PPC       -> []
    | MIPS      -> []
    | X86       -> []
    end
  in

  let state' = function
    | MWO_successful ->
        propagate_write_action params state iic write
    | MWO_unmapped_address ws ->
        write_unmapped_memory_action state iic ws
    | MWO_exclusive_failed ->
        fail
    end
  in

  let plain_write_transition =
    if params.thread_allow_write_subsumption &&
        (let propagated_writes = find_propagated_writes iic.subtree [] in
        exists (w MEM propagated_writes). non_empty_intersection write.w_addr w.w_addr)
    then
      (* the write was subsumed *)
      let state' = fun () -> state' MWO_successful in
      T_only (make_label state iic (T_POP_subsumed_write write) state')
    else
      T_sync (T_propagate_write (make_label state iic (write, Nothing, rf) state')) ()
  in

  if is_atomic_store (ik i) then
    let paired_load =
      ensure_just (paired_atomic_load iic)
      "trying to propagate the writes of atomic store that is not paired with atomic load"
    in
    (* FIXME: handle cases where fp is not equal *)
    if paired_load.subreads.sr_addr = (Just write.w_addr) then
      let rs = read_requests_of_subreads paired_load.subreads in
      guard (rs <> []) >>
      let r = ensure_singleton rs
        $ "can't handle atomic load (ioid " ^ show paired_load.instance_ioid ^ ") with multiple/pair reads (yet)"
      in
      return (T_sync (T_propagate_write (make_label state iic (write, Just r, rf) state')) ())
    else [plain_write_transition]
  else [plain_write_transition]


let enumerate_commit_and_prop_RISCV_store_cond_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = ensure (is_RISCV_store_conditional (ik i)) $
      "expected a RISC-V store-conditional (ioid " ^ show i.instance_ioid ^ ")" in

  let () = ensure (i.subwrites.sw_potential_write_addresses = []) $
      "the store (ioid " ^ show i.instance_ioid ^ ") has writes with no values" in

  let write = ensure_singleton i.subwrites.sw_potential_writes $
      "store-conditional (ioid " ^ show i.instance_ioid ^ ") should have exactly one write" in

  guard (match params.thread_model with
          | POP_thread_model _     ->
              pop_commit_store_cand state iic
              && pop_write_co_check params state iic write
          | TSO_thread_model       -> true
          | PLDI11_thread_model    -> fail
          | Promising_thread_model -> fail
          | Relaxed_thread_model   -> true
          end) >>

  let load = ensure_just (paired_atomic_load iic) $
      "about to commit a store-conditional (ioid " ^ show i.instance_ioid ^ ") that is not paired" in
  (* the commit_cand above guarantees the paired load-reserved is finished *)
  let () = ensure (is_entirely_satisfied_load load) $
      "expected the load-reserved (ioid " ^ show load.instance_ioid ^ ") to have already been satisfied" in
  let (_, prev_writes) = ensure_singleton load.subreads.sr_writes_read_from
      $ "can't handle atomic load (ioid " ^ show load.instance_ioid ^ ") with multiple reads" in

  let state' = function
    | MWO_successful ->
        let i' =
          <| i with
              subwrites = <| i.subwrites with sw_committed = true |>;
              successful_atomic_store = Just true;
          |>
        in
        let iic' = <| iic with iic_instance = i' |> in
        propagate_write_action params state iic' write
    | MWO_unmapped_address ws ->
        write_unmapped_memory_action state iic ws
    | MWO_exclusive_failed ->
        let i' = <| i with successful_atomic_store = Just false |> in
        let iic' = <| iic with iic_instance = i' |> in
        failed_write_action state iic' write (MOS_plain (c false))
    end
  in
  [T_sync (T_Flat_try_commit_store_cond (make_label state iic (write, prev_writes) state')) ()]


let enumerate_complete_store_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in

  let () = ensure (i.subwrites.sw_potential_write_addresses = [])
             "the store has writes with no values" in

  let state' = fun () ->
    let i' =
      if is_RISCV_AMO (ik i) then
        let () = ensure (pop_finish_load_cand params state iic)
                   "completed AMO cannot finish load part" in
        <| i with micro_op_state = MOS_AMO_unlock (c true) |>
      else
        <| i with micro_op_state = MOS_plain (c true) |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in

  [T_only (make_label state iic T_complete_store state')]


let handle_memory_write
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  if (not iic.iic_instance.subwrites.sw_committed) then
    if is_RISCV_store_conditional (ik iic.iic_instance) then
      enumerate_commit_and_prop_RISCV_store_cond_transition params state iic c
    else
      enumerate_commit_store_transition params state iic c
  else if iic.iic_instance.subwrites.sw_potential_writes <> [] then
    enumerate_propagate_write_transitions params isa state iic c
  else
    enumerate_complete_store_transition params state iic c 

let handle_exception
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (e: exception_type 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  match iic.iic_instance.micro_op_state with
  | MOS_pending_exception ET_loop_limit_reached ->
      guard (match iic.active_prefix with iprev :: _ -> iprev.finished | [] -> true end) >>
      let state' = fun () -> make_thread_cont_res {} {} state in
      [T_only (make_label state iic (T_exception e) state')]
  | _ ->
      guard (po_predecessors_all_finished iic) >>
      let state' = fun () -> make_thread_cont_res {} {} state in
      [T_only (make_label state iic (T_exception e) state')]
  end

let enumerate_previous_excl_res_outcome_transition
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  let i = iic.iic_instance in
  option_guard (i.successful_atomic_store) >>= fun s ->
  let state' = fun () ->
    let i' = <| i with micro_op_state = MOS_plain (isa_cont s) |> in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic (T_prev_excl_result s) state')]


let enumerate_excl_res_fail_outcome_transition
    (params:   thread_params)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  guard (params.thread_model <> TSO_thread_model) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>

  let state' = fun () ->
    let i' =
      <| i with
          successful_atomic_store = Just false;
          reg_reads = [];
            (* as the store-conditional/exclusive will not be using
            these we want to dissever the dependency; this prevents
            restarts and allows the instruction to be finished.
            this test should be allowed:
            a:R x=1             d:R y=1
              <addr>              <addr>
            b:W-exclusive z=1   e:W x=1
              <addr>
            c:W y=1
            *)
          micro_op_state = MOS_plain (isa_cont false);
      |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic T_failed_store_excl state')]

let enumerate_excl_res_success_outcome_transition_pop
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  guard (params.thread_model = POP_thread_model Standard_POP) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>

  option_guard (paired_atomic_load iic) >>= fun load ->

  match isa.isa_model with
  | AARCH64 _ ->
      let state' = fun () ->
        let i' =
          <| i with
              successful_atomic_store = Just true;
              micro_op_state = MOS_plain (isa_cont true);
          |>
        in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in

      if load.subreads.sr_requested <> [] then
        let (r, rf) = ensure_singleton load.subreads.sr_unsat_slices
            $ "can't handle atomic load (ioid " ^ show load.instance_ioid ^ ") with multiple/pair reads (yet)"
        in
        let rf =
          (* the read request was requested but not satisfied yet, i.e., it's in
              storage, no need to include the 'rf' in the transition *)
          if rf <> [] then Nothing else
          (* the read request is completely satisfied, we need to include the 'rf'
              in the transition *)
            let rf = ensure_just (List.lookup r load.subreads.sr_writes_read_from)
              $ "missing a read-request in 'sr_writes_read_from' of ioid " ^ show load.instance_ioid
            in
            Just rf
        in
        [(T_sync (T_try_store_excl (make_label state iic (r, rf, i.instance_ioid) state')) ())]
      else
        [(T_only (make_label state iic T_successful_store_excl state'))]
  | RISCV     ->
      let state' = fun () ->
        let i' = <| i with micro_op_state = MOS_plain (isa_cont true) |> in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in
      [(T_only (make_label state iic T_potential_store_cond state'))]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end


let enumerate_excl_res_success_outcome_transition_flat
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  guard (is_flat_model params) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>

  option_guard (paired_atomic_load iic) >>= fun load ->

  match isa.isa_model with
  | AARCH64 _ ->
      let state' = fun () ->
        let i' =
          <| i with
              successful_atomic_store = Just true;
              micro_op_state = MOS_plain (isa_cont true);
          |>
        in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in

      if load.subreads.sr_writes_read_from <> [] then
        let (r,rf) = ensure_singleton load.subreads.sr_writes_read_from
          $ "can't handle atomic load (ioid " ^ show load.instance_ioid ^ ") with multiple/pair reads (yet)"
        in

        let rf = [(w, slice) | forall ((w,slice) MEM rf)
                            | w.w_thread = state.thread -->
                              forall (iprev MEM iic.active_prefix (* ++ iic.old_prefix *)).
                              iprev.instance_ioid = w.w_ioid -->
                              List.elem w iprev.subwrites.sw_propagated_writes]
        in

        [T_sync (T_try_store_excl (make_label state iic (r, Just rf, i.instance_ioid) state')) ()]
      else
        [T_only (make_label state iic T_successful_store_excl state')]
  | RISCV     ->
      let state' = fun () ->
        let i' = <| i with micro_op_state = MOS_plain (isa_cont true) |> in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in
      [T_only (make_label state iic T_potential_store_cond state')]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end



let enumerate_excl_res_success_outcome_transition_tso
    (params:   thread_params)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  guard (params.thread_model = TSO_thread_model) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  let state' = fun () ->
    let i' =
      <| i with successful_atomic_store = Just true;
                micro_op_state = MOS_plain (isa_cont true) |>
    in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  option_guard (paired_atomic_load iic) >>= fun load ->

  let (r,rf) =
    ensure_singleton load.subreads.sr_writes_read_from
      $ "can't handle atomic load (ioid " ^ show load.instance_ioid ^ ") with multiple/pair reads (yet)"
  in

  let rf = [(w, slice) | forall ((w,slice) MEM rf)
                      | w.w_thread = state.thread -->
                        forall (iprev MEM iic.active_prefix (* ++ iic.old_prefix *)).
                        iprev.instance_ioid = w.w_ioid -->
                        List.elem w iprev.subwrites.sw_propagated_writes]
  in

  [T_sync (T_try_store_excl (make_label state iic (r, Just rf, i.instance_ioid) state')) ()]


let enumerate_excl_res_success_outcome_transition_relaxed
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  guard (params.thread_model = Relaxed_thread_model) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>

  match isa.isa_model with
  | AARCH64 _ ->
      let state' = fun () ->
        let i' =
          <| i with
              successful_atomic_store = Just true;
              micro_op_state = MOS_plain (isa_cont true);
          |>
        in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in
      [T_only (make_label state iic T_successful_store_excl state')]
  | RISCV     ->
      let state' = fun () ->
        let i' = <| i with micro_op_state = MOS_plain (isa_cont true) |> in
        <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
        $> make_thread_cont_res {} {}
      in
      [T_only (make_label state iic T_potential_store_cond state')]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end


let handle_excl_res_outcome
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome_S)
  =
  enumerate_previous_excl_res_outcome_transition state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_pop params isa state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_flat params isa state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_tso params state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_relaxed params isa state iic isa_cont ++
  enumerate_excl_res_fail_outcome_transition params state iic isa_cont

let enumerate_finish_load_part_of_rmw
    (params: thread_params)
    (state:      thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  guard (is_memory_rmw (ik iic.iic_instance) && 
         not (is_RISCV_AMO (ik iic.iic_instance)) &&
         iic.iic_instance.rmw_finished_load_snapshot = Nothing &&
         is_entirely_satisfied_load iic.iic_instance &&
         pop_finish_load_cand params state iic) >>

  let state' = fun () ->
    let snapshot =
      <|  rfls_instance_id_state = iic.iic_instance.instance_id_state;
          rfls_reg_reads         = iic.iic_instance.reg_reads;
          rfls_reg_writes        = iic.iic_instance.reg_writes;
          rfls_micro_op_state    = iic.iic_instance.micro_op_state;
      |>
    in
    let i' = <| iic.iic_instance with rmw_finished_load_snapshot = Just snapshot |> in
    <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
    $> make_thread_cont_res {} {}
  in
  return (T_only (make_label state iic T_finish_load_of_rmw state'))

(* handle_thread_start is a hack. It handles the fake instruction that
signals a fork in rmem. We expect the Sail code for this instruction
to do nothing. Here we generate register read transitions as needed,
and then do the fork and write the result register at the same time.
Maybe it would be nicer to have Sail do the register reads and writes,
but then we will need to add a fork outcome/effect to Sail and I'm not
up to it right now. Also, it is not clear we want such effect in Sail
as "fork" is not a real thing. *)
let handle_thread_start
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (is:     outcome_S)
    : list (thread_trans 'i (thread_state 'i))
  =
  let c = fun _ -> is in
  let start_info = isa.thread_start_info in
  let i = iic.iic_instance in

  if forall ((r, _, _) MEM i.reg_reads). r <> start_info.tsi_addr then
    handle_read_reg_outcome isa state iic start_info.tsi_addr c
  else if
    match start_info.tsi_toc with
    | Nothing -> false
    | Just tsi_toc ->
        forall ((r, _, _) MEM i.reg_reads). r <> tsi_toc
    end
  then
    let tsi_toc = ensure_just start_info.tsi_toc "fail" in
    handle_read_reg_outcome isa state iic tsi_toc c
  else if
    match start_info.tsi_extra with
    | Nothing -> false
    | Just tsi_extra ->
        forall ((r, _, _) MEM i.reg_reads). r <> tsi_extra
    end
  then
    let tsi_extra = ensure_just start_info.tsi_extra "fail" in
    handle_read_reg_outcome isa state iic tsi_extra c
  else
    guard
      match params.thread_model with
      | PLDI11_thread_model    -> pldi11_commit_cand state iic
      | POP_thread_model _     -> pop_finish_cand params state iic
      | TSO_thread_model       -> true
      | Promising_thread_model -> fail
      | Relaxed_thread_model   -> true
      end >>

    guard (forall (iprev MEM iic.active_prefix). 
           if is_pop_strong_memory_barrier (ik iprev)
           then iprev.finished else true) >>

    let addr_v =
      List.find (fun (r, _, _) -> r = start_info.tsi_addr) i.reg_reads
    in
    let (_, _, addr_v) = ensure_just addr_v "fail" in
    let toc_v =
      match start_info.tsi_toc with
      | Nothing -> Nothing
      | Just tsi_toc ->
          let v = List.find (fun (r, _, _) -> r = tsi_toc) i.reg_reads in
          let (_, _, v) = ensure_just v "fail" in
          Just v
      end
    in

    let thread_continuation = fun new_tid ->
      let new_tid_rv =
        match new_tid with
        | Just new_tid -> integerFromNat new_tid
        | Nothing      -> ~1 (* i.e. -1 *)
        end
        $> register_value_for_reg_of_integer start_info.tsi_return
      in
      let i' =
        <| i with
            reg_writes = (start_info.tsi_return, (current_reg_write_dependencies i, new_tid_rv))
              :: i.reg_writes;
            finished = true;
        |>
      in
      <| state with instruction_tree = apply_tree_context iic.context (i',iic.subtree) |>
      $> make_old_instructions isa
      $> make_thread_cont_res {} {}
    in

    [T_thread_start (make_label state iic (addr_v, toc_v) thread_continuation)]

let handle_ic_ivau
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (value:    register_value)
    (outcome:  outcome_S)
  =
      match address_of_register_value value with
      | Nothing -> failwith "TODO: handle_ic_ivau fail invalid addr"
      | Just addr ->
            cache_maintenance_trans_ic state iic addr outcome
      end

let handle_dc_cvau
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (value:    register_value)
    (outcome:  outcome_S)
  =
      match address_of_register_value value with
      | Nothing -> failwith "TODO: handle_dc_cvau fail invalid addr"
      | Just addr ->
            cache_maintenance_trans_dc state iic addr outcome
      end

let create_opcode =
    fun mrs ->
        match maybe_all (List.map byte_of_byte_lifted (mrs.mrs_value)) with
        | Nothing -> failwith ("create_opcode lifted byte: " ^ (show mrs.mrs_value))
        | Just [b0; b1; b2; b3] ->
            let endianness = E_little_endian in (* TODO: hook this into the arch? *)
            match endianness with
            | E_big_endian -> opcode_of_bytes b0 b1 b2 b3
            | E_little_endian -> opcode_of_bytes b3 b2 b1 b0
            end
        | Just _ -> failwith "create_fdo unexpected number of bytes"
        end


let create_fdo isa (a : address)
    : memory_read_source -> fetch_and_decode_outcome 'i =
    fun mrs ->
        let opcode = create_opcode mrs in
        let fdo = isa.instruction_semantics.decode_to_instruction a opcode in
        fdo


let enumerate_fetch_transitions_of_instruction
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =
  let i = iic.iic_instance in
  guard (i.micro_op_state = MOS_fetch Nothing) >>

  (* let fetch_kind =
    if not prev_i.finished
        && exists (nia IN prev_iic.iic_instance.nias). nia = NIA_indirect_address
    then FK_unfixed
    else if Set.size all_fetch_addrs > 1 then FK_multiple_fixed
    else FK_normal
  in *)
  let fetch_kind = FK_normal in
  let addr = i.program_loc in
  let thread_cont = get_fetch_instruction_continuation isa state iic addr in
  let make_fr addr fk =
    <| fr_addr = addr;
       fr_kind = fk;
       fr_tid = state.thread;
       fr_decode = create_fdo isa;
    |>
  in
  [T_sync (T_fetch (make_label state iic (make_fr addr fetch_kind) thread_cont)) ()]

let enumerate_decode_transitions_of_instruction params
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =
  let i = iic.iic_instance in
  (* Can only decode after fetched *)
  guard (match i.micro_op_state with
         | MOS_fetch (Just _) -> true
         | _ -> false
         end) >>

  (* only decode if program-order previous decoded ISBs are finished *)
  guard (
        forall (iprev MEM iic.active_prefix).
          (is_AArch64_isb_barrier (ik iprev) --> iprev.finished)
  ) >>

  (* Can only decode after parent has decoded or initial fetch *)
  let prefix = iic.active_prefix ++ iic.old_prefix in
  guard (match prefix with
         | hd::_ ->
            match hd.micro_op_state with
            | MOS_fetch _ -> false
            | _ -> true
            end
         | [] -> true
         end) >>

  let f =
    match i.micro_op_state with
    | MOS_fetch (Just f) -> f
    | _ -> failwith "unreachable"
    end
  in
  let cont () =
    let fdo = fdo_from_fetched f in
    let prefix = (i :: iic.active_prefix ++ iic.old_prefix) in
    match fdo with
    | FDO_success addr opcode inst ->
        let i' = starting_inst_instance params i.instance_ioid opcode inst addr prefix in
            <|  state with
                instruction_tree = apply_tree_context iic.context (i',iic.subtree);
            |>
    | err ->
      let fde =
        match err with
        | FDO_address_not_concrete -> FDE_non_concrete_fetch_address_error
        | FDO_illegal_fetch_address -> FDE_illegal_fetch_address_error i.program_loc
        | FDO_decode_error de -> FDE_decode_error de i.program_loc
        | _ -> failwith "impossible"
        end
      in
        let i' = <| i with micro_op_state = MOS_pending_exception (ET_fetch_and_decode fde) |> in
            <|  state with
                instruction_tree = apply_tree_context iic.context (i',iic.subtree);
            |>
    end
    $> make_old_instructions params
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic (T_decode i.program_loc f) cont)]


let enumerate_transitions_of_instruction
    (params: thread_params)
    (isa:    isa 'i)
    (s:      thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let is_restricted = params.thread_restriction <> RestrictionNone in
  guard (is_restricted --> forall (p MEM iic.active_prefix). p.finished) >>

  match iic.iic_instance.micro_op_state with
  | MOS_unpredictable -> []
  | MOS_fetch Nothing  -> enumerate_fetch_transitions_of_instruction isa s iic
  | MOS_fetch (Just _) -> enumerate_decode_transitions_of_instruction isa s iic
  | MOS_wait_IC _ -> []
  | MOS_plain is ->
    match fst is with

    (* IC *)
    | Write_reg (Reg "instruction_cache_operation_IVAU" 63 64 D_decreasing, v) o ->
      handle_ic_ivau s iic v o

    (* DC *)
    | Write_reg (Reg "data_cache_operation_CVAU" 63 64 D_decreasing, v) o ->
      handle_dc_cvau s iic v o

    (* normal outcomes *)
    | Read_mem descr c     -> handle_read_mem_outcome     params isa s iic descr c
    | Write_ea descr o     -> handle_write_ea_outcome     params isa s iic descr o
    | Write_memv descr c   -> handle_write_memv_outcome   s iic descr c
    | Excl_res c           -> handle_excl_res_outcome     params isa s iic c
    | Barrier descr o      -> handle_barrier_outcome      params isa s iic descr o
    | Read_reg descr c     -> handle_read_reg_outcome     isa s iic descr c
    | Write_reg descr o    -> handle_write_reg_outcome    isa s iic descr o
    | Internal descr o     -> handle_internal_outcome     s iic descr o
    | Footprint o          -> handle_footprint_outcome    isa s iic is o
    | Done ()              ->
       let instr = ensure_fetched iic.iic_instance.instruction in
       if isa.is_thread_start_instruction instr
       then handle_thread_start params isa s iic is
       else handle_done_outcome params isa s iic

    | Escape (Just msg)    -> handle_sail_termination     s iic $ "Escape: " ^ msg
    | Escape Nothing       -> handle_sail_termination     s iic $ "Escape"
    | Error msg            -> handle_sail_termination     s iic $ "Error: " ^ msg
    | Fail (Just msg)      -> handle_sail_termination     s iic $ "Fail: " ^ msg
    | Fail Nothing         -> handle_sail_termination     s iic $ "Fail"
    end

  | MOS_pending_mem_read c    -> handle_memory_read  params isa s iic c
  | MOS_potential_mem_write c -> handle_memory_write params isa s iic c
  | MOS_AMO_lock c            -> handle_AMO_lock     params s iic c
  | MOS_AMO_unlock o          -> handle_AMO_unlock   s iic o
  | MOS_pending_exception e   -> handle_exception    s iic e
  end ++
  enumerate_finish_load_part_of_rmw params s iic



(** enumerate all fetch transitions of thread *)

(* are instruction fetches going to be done with satisfy_read transitions?  Not
   in the first instance, as that's confusing wrt the (lack of) icache
   synchronisation.  Are they going to be done from the same memory?  No, they
   come from distinct parts of the ELF file to the other mapped memory.  *)


(* NEWTODO when instructions feeding into LR/CR register values get restarted,
   and when new prediction addresses become available, how are we going to do
   the newly enabled fetches after branches? *)

(* val debug_print : string -> unit *)
(* declare ocaml target_rep function debug_print s = `Printf.eprintf` "%s%!" s *)

(* TODO: proper fixed-point or enumerate all addrs *)
let potential_next_addresses_of_instruction_relaxed
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : set address
  =
    match iic.iic_instance.micro_op_state with
    | MOS_fetch _ ->
        let branch_targets = Map.findWithDefault state.thread Map.empty params.branch_targets in
        let addrs = Map.findWithDefault iic.iic_instance.program_loc Set.empty branch_targets in
        let succ = successor_fetch_address iic.iic_instance in
        if Set.null addrs then {succ}
        else addrs
    | _ ->
        potential_next_addresses_of_instruction params isa state iic
    end

let enumerate_init_fetch_transitions_of_instruction
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =
  let is_restricted = match params.thread_restriction with
    | RestrictionNone    -> false
    | RestrictionSC      -> true
    | RestrictionSCANASC -> true
  end in

  let i = iic.iic_instance in
  let prefix = (i :: iic.active_prefix ++ iic.old_prefix) in

  guard (is_restricted --> i.finished) >>
  guard (params.thread_model = TSO_thread_model --> i.finished) >>

  guard (i.micro_op_state <> MOS_pending_exception ET_loop_limit_reached) >>

  guard (
    match params.thread_fetch_limit with
    | Just lim ->
      let is_not_decoded inst =
            (match inst.micro_op_state with
            | MOS_fetch _ -> true
            | _ -> false
            end) in
      let decode_depth = List.length (List.filter is_not_decoded iic.active_prefix) in
        lim > decode_depth
    | Nothing -> true
    end) >>

  (* init only after previous have been decoded *)
  guard (params.thread_fetch_order = Fetch_Sequential -->
      match i.micro_op_state with
         | MOS_fetch _ -> false
         | _ -> true
         end) >>

  let (T iits) = iic.subtree in
  let already_fetched_addrs = { i.program_loc | forall ((i,_) MEM iits) | true } in

  guard (params.thread_allow_tree_speculation || already_fetched_addrs = {}) >>

  (* TODO: make potential_next_addresses of init fetch be unconstrained *)
  let all_fetch_addrs =
      match params.thread_fetch_order with
      | Fetch_Sequential -> potential_next_addresses_of_instruction params isa state iic
      | Fetch_Unrestricted -> potential_next_addresses_of_instruction_relaxed params isa state iic
      end
  in
  let multiple = Set.size all_fetch_addrs > 1 in

  (* remove addresses we have already fetched from, and remove the return address *)
  Set_extra.toList all_fetch_addrs >>= fun addr -> (* for each addr .. *)
  guard (addr NIN already_fetched_addrs) >>
  guard (addr <> state.return_address) >>

  guard (
    match (params.thread_loop_unroll_limit, prefix) with
    | (Nothing, _) -> true
    | (_, [])      -> true
    | (Just limit, iprev :: _) ->
        not (addr <= iprev.program_loc
             && (exists (iprev MEM prefix). iprev.program_loc = addr)
             && (_count_pairs prefix iprev.program_loc addr 0) + 1 >= limit)
    end) >>


  let state' addr = fun () ->
    let (id_state', is') = init_fetch_instruction params state [] addr in
    let (T iits) = iic.subtree in
    let it' = T (iits ++ [(i', T[]) | forall (i' MEM is') | true]) in
    <| state with
       instruction_tree = apply_tree_context iic.context (i, it');
       id_state = id_state';
    |>
    $> make_thread_cont_res {} {}
  in
  [T_only (make_label state iic (T_init_fetch addr multiple) (state' addr))]


let initial_fetch_transition_of_thread
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (maybe_addr:  maybe address)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* if we haven't done anything yet, fetch initial instruction *)
  guard (state.instruction_tree = T [] && state.old_instructions = []) >>
  option_guard maybe_addr >>= fun addr ->
  (* if the thread has no instruction the initial address will also be the return address *)
  guard (addr <> state.return_address) >>

  (* this is a dummy ioid - morally the ioid of the (nonexistent) preceding instruction *)
  let (ioid, state) =
    let (ioid, id_state') = FreshIds.gen_fresh_id state.id_state in
    (ioid, <| state with id_state = id_state' |>)
  in

  let thread_cont = fun a ->
    let (id_state', is') = init_fetch_instruction params state [] addr in

    <| state with
        instruction_tree = T [(i',T []) | forall (i' MEM is') | true];
        id_state = id_state'
    |>
    $> make_thread_cont_res {} {}
  in

  let tl =
    <|  tl_label = T_init_fetch addr false;
        tl_suppl = Nothing;
        tl_cont  =
          <|  tc_tid  = state.thread;
              tc_ioid = ioid;
              tc_cont = thread_cont |>;
    |>
  in
  [T_only tl]



let enumerate_transitions_of_thread
    (params: thread_params)
    (isa : isa 'i)
    (state: thread_state 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* initial fetch transition *)
  initial_fetch_transition_of_thread params isa state state.initial_fetch_address ++

  (* possible transitions of inflight instructions *)
  (in_flight_instructions state >>= fun iic ->
    catch_thread_errors state.thread iic.iic_instance.instance_ioid $ fun () ->
      enumerate_transitions_of_instruction params isa state iic) ++

  (* transitions for initialising the fetch of successor instructions *)
  (un_old_instructions state >>= fun iic ->
    catch_thread_errors state.thread iic.iic_instance.instance_ioid $ fun () ->
      enumerate_init_fetch_transitions_of_instruction params isa state iic)


let pop_receive_satisfy_read_transition params isa state rr mrs = 
  let iic =
    ensure_just
      (find_ioid_instruction_in_context state rr.r_ioid)
      ("cannot find the ioid " ^ show rr.r_ioid ^ " in the instruction tree")
  in
  let state' = fun () -> satisfy_read_action params state iic rr [mrs] in
  Just (make_cont state.thread iic.iic_instance.instance_ioid state')


let pldi11_receive_acknowledge_sync_barrier_transition params isa state b = 
  let state' = fun () ->
    let pldi11_substate =
      let substate = get_pldi11_thread_substate state.thread_substate in
      <| unacknowledged_syncs = { b' | forall (b' IN substate.unacknowledged_syncs) 
                                  | b'.b_ioid <> b.b_ioid } |>
    in
    <| state with thread_substate = PLDI11_thread pldi11_substate |>
    $> make_old_instructions isa
    $> make_thread_cont_res {} {}
  in
  Just <| tc_tid = state.thread; tc_ioid = b.b_ioid; tc_cont = state' |>

let flat_receive_finish_ic_transition params isa state (cmr : cache_maintenance_request) = 
  let state' = fun () ->
    let iic =
      ensure_just (find_ioid_instruction_in_context state cmr.cmr_ioid)
      $ "cannot find the ioid " ^ show cmr.cmr_ioid ^ " in the instruction tree"
    in
    let i = iic.iic_instance in
    match i.micro_op_state with
    | MOS_wait_IC o ->
       let i' = <| i with micro_op_state = MOS_plain o |> in
       <| state with instruction_tree = apply_tree_context iic.context (i', iic.subtree) |>
       $> make_thread_cont_res {} {}
    | _ -> failwith "flat finish IC:  wasn't MOS_wait_IC"
    end
  in
  Just <| tc_tid = state.thread; tc_ioid = cmr.cmr_ioid; tc_cont = state' |>

let flat_receive_ic_clear_transition params isa state (cmr : cache_maintenance_request) = 
  let state' = fun () ->
    let it = state.instruction_tree in
    let it' =
      instruction_tree_map
        (fun _ i _ ->
          if i.program_loc <> cmr.cmr_addr then i
          else
            match i.micro_op_state with
            | MOS_fetch _ ->
               starting_fetch_inst params i.instance_ioid i.program_loc
            | s -> i
            end
        )
        []
        it
    in
    <| state with instruction_tree=it' |>
    $> make_thread_cont_res {} {}
  in
  Just <| tc_tid = state.thread; tc_ioid = cmr.cmr_ioid; tc_cont = state' |>

let thread_receive_transition
      (params: thread_params)
      (isa:    isa 'i)
      (state:  thread_state 'i)
      label =

  match label with
  (* PLDI transitions: *)
  | SS_PLDI11_acknowledge_sync_barrier b ->
     pldi11_receive_acknowledge_sync_barrier_transition params isa state b
  (* POP transitions: *)
  | SS_POP_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  (* Flowing transitions: *)
  | SS_Flowing_seg_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  | SS_Flowing_mem_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  (* Flat Transitions *)
  | SS_Flat_ic_finish cmr ->
     flat_receive_finish_ic_transition params isa state cmr
  | SS_Flat_thread_ic cmr _ ->
     flat_receive_ic_clear_transition params isa state cmr
  end

(* based on CandidateExecution.footprints_of_cex_instruction_instance *)
let footprints_of_instruction_instance (i:instruction_instance 'i) : set footprint =
  Set.fromList
    ([w.w_addr | forall ((w,sls) MEM (List.concat (snd (List.unzip i.subreads.sr_writes_read_from)))) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_potential_write_addresses) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_potential_writes) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_propagated_writes) | true]
     ++ [r.r_addr | forall ((r,_) MEM i.subreads.sr_writes_read_from) | true]
     ++ [r.r_addr | forall ((r,_) MEM i.subreads.sr_requested) | true])


val machine_thread : forall 'i. threadSubsystem 'i (thread_state 'i)
let machine_thread = 
  <| ts_tid = fun ts -> ts.thread;
     ts_initial_fetch_address = fun ts -> ts.initial_fetch_address;
     ts_initial_reg_state = fun ts -> ts.initial_register_state;
     ts_initial_thread_state = initial_thread_state;
     ts_final_reg_state = registers_final_state;
     ts_instruction_tree = fun ts -> (ts.old_instructions,ts.instruction_tree);
     ts_update_initial_register_state = machine_update_initial_register_state;
     ts_update_initial_fetch_address = machine_update_initial_fetch_address;
     ts_is_final_state = thread_is_final_state;
     ts_return_address = fun ts -> ts.return_address;
     (* ts_make_ui_thread_state = make_ui_machine_thread_state; *)
     ts_enumerate_transitions_of_thread = enumerate_transitions_of_thread;
     ts_receive_transition = thread_receive_transition;
 |>

