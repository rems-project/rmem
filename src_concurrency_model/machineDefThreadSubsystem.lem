(*========================================================================================*)
(*                                                                                        *)
(*                rmem executable model                                                   *)
(*                =====================                                                   *)
(*                                                                                        *)
(*  This file is:                                                                         *)
(*                                                                                        *)
(*  Copyright Shaked Flur, University of Cambridge                            2014-2018   *)
(*  Copyright Peter Sewell, University of Cambridge                           2014-2017   *)
(*  Copyright Christopher Pulte, University of Cambridge                      2015-2018   *)
(*  Copyright Robert Norton-Wright, University of Cambridge                   2016-2017   *)
(*  Copyright Susmit Sarkar, University of St Andrews                              2014   *)
(*  Copyright Kathy Gray, University of Cambridge (when this work was done)   2014-2017   *)
(*  Copyright Jon French, University of Cambridge                             2016-2017   *)
(*  Copyright Linden Ralph, University of Cambridge (when this work was done)      2017   *)
(*  Copyright Ohad Kammar, University of Cambridge (when this work was done)  2013-2014   *)
(*                                                                                        *)
(*  All rights reserved.                                                                  *)
(*                                                                                        *)
(*  It is part of the rmem tool, distributed under the 2-clause BSD licence in            *)
(*  LICENCE.txt.                                                                          *)
(*                                                                                        *)
(*========================================================================================*)

(* emacs fontification -*-caml-*- *)

open import Pervasives_extra
open import Sail_impl_base
open import Utils
open import Fragments
open import FreshIds
open import ExceptionTypes
open import Events
open import Debug
open import Params
open import InstructionSemantics
open import Isa
open import RegUtils
open import InstructionKindPredicates
open import MachineDefThreadSubsystemUtils
open import MachineDefTypes
open ListMonad

(* SF: ???? *)
(* NEWTODO: the old machineDefInstructionSemantics.write_possibly_done_by
checks that "w (a write-read-from by some read) is by thread tid and
has the same address and value as some write in the behaviour s".  Why
do we do that instead of checking identity of writes?  Here I do that,
and also note that I'm only looking at the pending events - is that
right?  Shaked says that it has to be the former way*)


(** Initial thread state ********************************************)

let init_pldi11_thread_substate = <| unacknowledged_syncs = {}; |>
let init_pop_thread_substate = <| read_issuing_order = relonEmpty; |>

let initial_thread_state
    (params:         thread_params)
    (tid :           thread_id)
    (return_address: address)
    (rd:             registerdata)
    (irv:            reg_base_name -> register_value)
    (initial_fetch:  maybe address)
  =
  <| thread                     = tid;
     id_state                   = FreshIds.initial_id_state tid;
     return_address             = return_address;
     register_data              = rd;
     initial_register_state     = irv;
     initial_fetch_address      = initial_fetch;
     old_instructions           = [];
     instruction_tree           = T [];

     thread_substate =
        match params.thread_model with
        | PLDI11_thread_model    -> PLDI11_thread init_pldi11_thread_substate
        | POP_thread_model _     -> POP_thread init_pop_thread_substate
        | TSO_thread_model       -> No_substate
        | Promising_thread_model -> fail
        | Relaxed_thread_model   -> No_substate
        end;
  |>

(********************************************************************)
(* record things that might affect (over-approximate) the value being
written to the register *)
let current_reg_write_dependencies
    (instruction: instruction_instance 'i)
    : list register_write_dependency
  =
  let reg_deps =
    instruction.reg_reads >>= fun (reg_name, register_read_sources, _) ->
    register_read_sources >>= function
    (* for each reg_name and each of its register_read_sources .. *)
    | RRS_instruction ioid reg_names _ -> [(RWD_reg_write ioid reg_names)]
    | RRS_initial_state _              -> []
    | RRS_pseudoregister               -> []
    end
  in
  if read_completed instruction then RWD_mem_read :: reg_deps else reg_deps

(* iic_prefix is active_prefix ++ old_prefix *)
let paired_atomic_load_aux
      (iic_instance : instruction_instance 'i)
      prefix 
    : maybe (instruction_instance 'i) =
  if is_memory_rmw (ik iic_instance) then Just iic_instance 
  else
    let atomic i = (is_atomic_load i || is_atomic_store i) && not (is_memory_rmw i) in
    Maybe.bind (List.find (fun i -> atomic (ik i)) prefix) $ fun inst ->
    if is_atomic_load (ik inst) then Just inst else Nothing

let paired_atomic_load (iic: instruction_in_context 'i) : maybe (instruction_instance 'i) =
  paired_atomic_load_aux
    iic.iic_instance
    (iic.active_prefix ++ iic.old_prefix)


let rec paired_atomic_stores_helper (T its: instruction_tree 'i) : list (instruction_instance 'i) =
  its >>= fun (i, it) ->
  if is_atomic_load (ik i) && not (is_memory_rmw (ik i)) then []
  else if is_atomic_store (ik i) && not (is_memory_rmw (ik i)) then [i]
  else paired_atomic_stores_helper it

let rec paired_atomic_stores (i: instruction_instance 'i) (it: instruction_tree 'i)
        : list (instruction_instance 'i) =
  if is_memory_rmw (ik i) then [i]
  else paired_atomic_stores_helper it

(* registers_final_state: find the registers state when thread has reached its
   final state.
   NOTE: 'state' might be a deadlock state, hence we find a registers snapshot
   for each path in the tree and join them together (register with multiple
   values is mapped to Nothing) *)

let registers_final_states_per_path (state: thread_state 'i)
    : set (list (reg_base_name * maybe register_value)) = 
  let paths = instruction_tree_fold_root (fun acc _ i _ -> i :: acc)
                state.old_instructions [] state.instruction_tree in
  Set.map (find_register_snapshot state.register_data state.initial_register_state) paths

let merge_registers_final_states
      (reg_states : set (list (reg_base_name * maybe register_value))) 
    : list (reg_base_name * maybe register_value) = 
  let s = Set_extra.choose reg_states in
  let reg_states' = reg_states \ {s} in
  List.map
    (fun (rbn, v) ->
      if forall (s' IN reg_states'). List.lookup rbn s' = Just v
      (* rbn is mapped to the same value in all snapshots *)
      then (rbn, v)
      else (rbn, Nothing))
    s

let registers_final_state (state: thread_state 'i) 
    : list (reg_base_name * maybe register_value) =
  (* get a register snapshot for each path in the instructions tree *)
  let reg_states = registers_final_states_per_path state in
  let () = ensure (not (Set.null reg_states))
             "there must be at least one path in the tree" in
  if Set.size reg_states = 1 then Set_extra.choose reg_states
  else merge_registers_final_states reg_states

(** Instruction instance predicates *)

(* A failed store-conditional/exclusive is not considered a memory access after it is finished *)

let atomic_store_determined_to_fail (i : instruction_instance 'i) : bool = 
  i.successful_atomic_store = Just false 

let atomic_store_determined_to_succeed (i : instruction_instance 'i) : bool = 
  i.successful_atomic_store = Just true

let is_viable_memory_store_ii (i: instruction_instance 'i) : bool =
  is_memory_store_instruction (ik i) &&
  not (atomic_store_determined_to_fail i && i.finished)

let is_viable_memory_access_ii (i: instruction_instance 'i) : bool =
  is_memory_load_instruction (ik i) || is_viable_memory_store_ii i

let is_cond_branch_ii (i: instruction_instance 'i) : bool =
  Set.size i.nias > 1

let is_indirect_branch_ii (i: instruction_instance 'i) : bool =
  exists (nia IN i.nias). nia = NIA_indirect_address



(** Possible Reads and Writes of Instruction ************************)

(* Return Nothing if the read footprint is not determined yet, or Just
   applied to the set of read addresses otherwise. If the memory read
   has already been initiated then this information is in the
   instruction instance state; if not, the footprint is only
   determined if the instruction has a Mem_read outcome in the next
   state. (This depends on the fact that the only register in the Sail
   code for loads is for determining the data, after that the read can
   go ahead. *)
let read_footprint_of_load instruction : maybe footprint =
  match instruction.subreads.sr_addr with
  | Just fp -> Just fp
  | Nothing ->
      match instruction.micro_op_state with
      | MOS_plain (O_Read_mem (read_kind,addr_lifted,size) _) ->
         let addr = ensure_just (address_of_address_lifted addr_lifted)
                      "read_footprint_of_load: bad address" in
         Just (addr, size)
      | _ ->  Nothing
      end
  end


let possibly_reads_address
    (instruction: instruction_instance 'i)
    (fps:         set footprint)
    : bool
  =
  is_memory_load_instruction (ik instruction) &&
  match read_footprint_of_load instruction with
  | Just fp -> non_empty_intersection_set fps {fp}
  | Nothing -> exists ((_, s) IN fps). s <> 0
  end


let possibly_writes_address
    (instruction: instruction_instance 'i)
    (fps:         set footprint)
    : bool
  =
  is_viable_memory_store_ii instruction &&
  match instruction.subwrites.sw_addr with
  | Just fp -> non_empty_intersection_set fps {fp}
  | Nothing -> exists ((_, s) IN fps). s <> 0
  end


(* Return 'true' iff 'instruction' might read or write from/to a footprint
intersecting with 'fps'. In particular, return 'true' if the footprint of
'instruction' can't be determined.
NOTE: we check the instruction in its current state, i.e., if the
pseudocode has not made enough steps yet to make the reads/writes avilable
the function returns 'true' for any (non-empty) 'fps', and we don't consider
what can happen if the instruction is restarted. *)
let possibly_reads_or_writes_address
    (inst: instruction_instance 'i)
    (fps:  set footprint)
    : bool
  =
  possibly_reads_address inst fps || possibly_writes_address inst fps

(* return true iff the sail code has already generated its memory-read event for
   the instruction. This guarantees that the instruction's memory read is
   recorded in the instruction_instance state. *)
let all_reads_are_calculated inst : bool =
  is_memory_load_instruction (ik inst) --> read_initiated inst

let all_writes_are_calculated inst : bool =
  is_viable_memory_store_ii inst --> write_initiated inst

(* return true iff the sail code has already generated all the memory-read/write
   events (except AArch64 write-mem-value, i.e., E_write_memv) for the
   instruction. This guarantees that any memory read/write footprint of the
   instruction is recorded in the instruction_instance state. *)
let all_writes_reads_are_calculated inst : bool =
  (* for efficiency, first check if 'inst' is unfinished *)
  inst.finished ||
  (all_reads_are_calculated inst && all_writes_are_calculated inst)

let is_entirely_satisfied_load (i: instruction_instance 'i) : bool =
  all_reads_are_calculated i && read_completed i

let finished_load_part inst : bool =
  inst.finished || inst.rmw_finished_load_snapshot <> Nothing





(** Instruction restart machinery ***********************************)

(* When a store is finished, POP needs to know if po-previous reads
to the same address might be restarted. We try to share as much code
as possible between the functions that do restarts and the function
that determines if a po-previous read might be restarted. *)


(* calculate the set of instructions in the tree 'it' that should be
restarted if 'roots' (presumed within 'it') are restarted *)

(* predicates to determin whether inst needs to be restarted if the
   instructions in 'restarts' are restarted *)

let also_restart_register_dependent_instr restarts inst prefix = 
  let undetermined_reg_deps =
    undetermined_reg_writes_read_from prefix inst.reg_reads in
  not (Set.null (Set.intersection restarts undetermined_reg_deps))

let also_restart_forward_dependent_instr restarts inst = 
  exists ((write, _) MEM (writes_read_from inst)).
  write.w_ioid IN restarts

let also_restart_instr_after_load_acquire restarts inst prefix =
  is_memory_load_instruction (ik inst) &&
  exists (prev_inst MEM prefix).
    (is_AArch64_load_acquire (ik prev_inst) || is_RISCV_load_acquire (ik prev_inst))
    && not (finished_load_part prev_inst)
    && prev_inst.instance_ioid IN restarts

let also_restart_instr_after_RISCV_fence_sr restarts inst prefix = 
  is_memory_load_instruction (ik inst) &&
  exists_iprev_with_prefix prefix $ fun prev_inst prev_active_prefix ->
    is_RISCV_fence_sr (ik prev_inst)
    && is_RISCV_fence_pr (ik prev_inst)
    && not (is_RISCV_fence_pw (ik prev_inst))
    && not prev_inst.finished
    && exists (prev_prev_inst MEM prev_active_prefix).
        is_memory_load_instruction (ik prev_prev_inst)
        && not (finished_load_part prev_prev_inst)
        && prev_prev_inst.instance_ioid IN restarts

let also_restart_instr_after_RISCV_fence_tso restarts inst prefix = 
  is_memory_load_instruction (ik inst) &&
  exists_iprev_with_prefix prefix $ fun prev_inst prev_active_prefix ->
    is_RISCV_fence_tso (ik prev_inst)
    && not prev_inst.finished
    && exists (prev_prev_inst MEM prev_active_prefix).
        is_memory_load_instruction (ik prev_prev_inst)
        && not (finished_load_part prev_prev_inst)
        && prev_prev_inst.instance_ioid IN restarts

let also_restart_instr restarts inst prefix = 
  also_restart_register_dependent_instr restarts inst prefix
  || also_restart_forward_dependent_instr restarts inst
  || also_restart_instr_after_load_acquire restarts inst prefix
  || also_restart_instr_after_RISCV_fence_sr restarts inst prefix
  || also_restart_instr_after_RISCV_fence_tso restarts inst prefix

let dependent_suffix_to_restart
    (roots: set ioid)
    (it:    instruction_tree 'i)
    : set ioid
  =
  let restart_fold
      (restarts: set ioid)
      (prefix:   list (instruction_instance 'i))
      (inst:     instruction_instance 'i)
      (_:        instruction_tree 'i)
      : set ioid
    =
    if inst.instance_ioid IN roots || also_restart_instr restarts inst prefix
    then Set.insert inst.instance_ioid restarts
    else restarts
  in
  bigunion (instruction_tree_fold_root restart_fold {} [] it)


(* return a pair, the instruction tree after restarting 'irestart_roots' and
their dependants, and the set of instructions that were restarted.
NOTE: 'irestart_roots' must all be in 'it' *)
let restart_dependent_subtrees
    (it:             instruction_tree 'i)
    (restart_roots: set (instruction_instance 'i))
    : instruction_tree 'i * set ioid
  =
  (* calculate the instructions to restart *)
  let root_ioids = {i.instance_ioid | forall (i IN restart_roots) | true} in
  let restarts = dependent_suffix_to_restart root_ioids it in
  (* restart them *)
  let it' =
    instruction_tree_map
      (fun _ i _ -> if i.instance_ioid IN restarts
                    then restart_instruction i else i)
      [] it
  in
  (it', restarts)


(** POP restart machinery *)

(* see if there is a pair of distinct writes in wss1 and wss2 whose
   slices footprint-intersect and where the second does not come from
   an instruction in ifeed_ioids *)
let overlapping_slices_from_different_writes_not_in_set
    (wss1: set (write*slices))
    (wss2: set (write*slices))
    (ifeed_ioids: set ioid)
    : bool
  =
  let wss2 = {(w, sls) | forall ((w, sls) IN wss2) | w.w_ioid NIN ifeed_ioids} in
  exists ((w1, sls1) IN wss1). exists ((w2, sls2) IN wss2).
    (w1 <> w2) &&
    overlapping_slices (w1.w_addr, sls1) (w2.w_addr, sls2)

let overlapping_slices_not_in_set
    ((rr, rs): (read_request*slices))
    (wss: set (write*slices))
    (ifeed_ioids: set ioid)
    : bool
  =
  let wss = {(w, ws) | forall ((w, ws) IN wss) | w.w_ioid NIN ifeed_ioids} in
  exists ((w, ws) IN wss).
    overlapping_slices (rr.r_addr, rs) (w.w_addr, ws)


(* remove read_requests of restarted instructions from pop's read_issuing_order *)
let pop_remove_reads_from_order
    (pop_thread:      pop_thread_substate)
    (to_remove: set ioid)
    : pop_thread_substate
  =
  let read_issuing_order' = 
    relonFilterSet (fun rr -> rr.r_ioid NIN to_remove)
      pop_thread.read_issuing_order
  in
  <| read_issuing_order = read_issuing_order' |>


let remove_reads_from_pop_order 
    (state : thread_state 'i)
    (to_remove: set ioid)
    : thread_state 'i = 
  match state.thread_substate with
  | POP_thread thread_substate ->
     let pop_thread' = pop_remove_reads_from_order thread_substate to_remove in
     <| state with thread_substate = POP_thread pop_thread' |>
  | PLDI11_thread _ -> state
  | No_substate     -> state
  end

let pop_add_read_to_order
    (pop_thread:      pop_thread_substate)
    (to_add: read_request)
    : pop_thread_substate
  =
  let read_issuing_order =
    relonAddToTheRight
      (fun rr' -> non_empty_intersection rr'.r_addr to_add.r_addr)
      to_add
      pop_thread.read_issuing_order
  in
  <| read_issuing_order = read_issuing_order |>

let add_read_to_pop_order 
    (state : thread_state 'i)
    (to_add: read_request)
    : thread_state 'i = 
  match state.thread_substate with
  | POP_thread thread_substate ->
     let pop_thread' = pop_add_read_to_order thread_substate to_add in
     <| state with thread_substate = POP_thread pop_thread' |>
  | PLDI11_thread _ -> state
  | No_substate     -> state
  end


let pop_reads_issued_in_order
    (state:      thread_state 'i)
    (po_old_rr:  read_request)
    (po_new_rr:  read_request)
    : bool
  =
  let read_issuing_order =
    (get_pop_thread_substate state.thread_substate).read_issuing_order in
  relonInRel po_old_rr po_new_rr read_issuing_order


type write_slices_or_slices =
  | WSS of set (write * slices)
  | SS  of slices

(* determines the set of instructions that need to be restarted (not
including their dependencies) due to 'read_request' being satisfied.
'it' is the subtree under the instruction that issued  'read_request'.
If we know the writes 'wss' that satisfied the read request, we can be
more precise (fewer restarts). *)

(* now also used for PLDI11 *)
let pop_memory_read_action_restart_roots params
    (state:        thread_state 'i)
    (it:           instruction_tree 'i)
    (read_request: read_request)
    (ss:           write_slices_or_slices)
    : set (instruction_instance 'i)
  =
  (* predicate to determine if a po-after satisfied read should be restarted *)
  let restart_satisfied_read prefix_ioids inst : bool =
      match ss with
      | WSS wss ->
          exists ((rr, rr_wss) MEM inst.subreads.sr_writes_read_from).
            ((not (pop_reads_issued_in_order state read_request rr)) || is_flat_model params) &&
            overlapping_slices_from_different_writes_not_in_set
              wss (Set.fromList rr_wss) prefix_ioids
      | SS rss ->
          exists (rr MEM (read_requests_of_subreads inst.subreads)).
            ((not (pop_reads_issued_in_order state read_request rr)) || is_flat_model params) &&
            overlapping_slices (read_request.r_addr, rss)
                (rr.r_addr, [complete_slice rr.r_addr])
      end
  in

  {i | forall ((i,prefix_ioids) IN instructions_with_prefix_ioids it)
     | restart_satisfied_read prefix_ioids i}



(* determines the set of instructions that need to be restarted (not
including their dependencies) due to 'writes' being propagated.
'it' is the subtree under the instruction that is propagating 'writes'. *)
let propagate_write_action_restart_roots
    (it:     instruction_tree 'i)
    (writes: list write)
    : set (instruction_instance 'i)
  =

  (* restart reads that have been satisfied by writes that might be
  co-before 'write_slices' *)

  (* we'll walk over each path in the tree from the propagating store,
  starting with its 'writes' and adding new writes when we come to
  them.  This is the write_slices that's used in restart_sat_read,
  which returns true if 'inst' reads from a write that overlaps with
  write_slices (but is not one of them) *)

  let read_satisfied_not_from_write_slices_not_from_po_predecessor
        write_slices prefix_ioids inst : bool =
    overlapping_slices_from_different_writes_not_in_set
      (Set.fromList write_slices)
      (Set.fromList (writes_read_from inst))
      prefix_ioids
  in

  (* restart reads with unsatisfied slices that overlap write_slices where
  the read requests have already been passed to the storage subsystem
  (i.e. reads that will be satisfied by writes that are co-before
  write_slices). *)

  let unsatisfied_issued_read_overlapping_write_slices ws inst : bool =
    let write_fps = write_fps_of_write_slices ws in
    exists ((rr, unsat_slices) MEM inst.subreads.sr_unsat_slices).
        read_requested inst rr &&
        non_empty_intersection_set (slice_footprints rr.r_addr unsat_slices) write_fps
  in

  let folded =
    instruction_tree_fold_root
      (fun (write_slices, prefix_ioids, restarts) _ i _ ->
        let prefix_ioids' = Set.insert i.instance_ioid prefix_ioids in
        let propagated = propagated_write_slices_of_instruction i in
        let write_slices' =
          List.mapMaybe (parts_of_write_not_overwritten_by_write_slices propagated)
            write_slices in
        let restarts' = 
          if read_satisfied_not_from_write_slices_not_from_po_predecessor
               write_slices prefix_ioids i || 
             unsatisfied_issued_read_overlapping_write_slices write_slices i
          then Set.insert i restarts else restarts 
        in
        (write_slices', prefix_ioids', restarts')
      )
      (complete_writes writes, {}, {})
      [] it
      in
  Set.bigunion {insts | forall ((_, _, insts) IN folded) | true}


let pop_memory_write_exclusive_commit_fail_action_restart_roots
    (it:          instruction_tree 'i)
    (failed_writes: list write)
    : set (instruction_instance 'i)
  =
  (* restart reads that the writes were forwarded to *)
  {isucc  | forall (isucc IN instructions_of_tree it)
          | exists ((write, _) MEM (writes_read_from isucc)).
                List.elem write failed_writes}


(* check if 'instruction' might be restarted when a read response from
storage is received for one of the instruction's read requests (see
pop_is_stale_read). *)
let pop_load_sat_might_self_restart params
    (state:                thread_state 'i)
    (might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    : bool
  =
  not (is_flat_model params) &&

  let prev_ioids =
    {i.instance_ioid | forall (i MEM (prefix ++ state.old_instructions)) | true}
  in
  
  exists ((rr, unsat_slices) MEM instruction.subreads.sr_unsat_slices).
      (* if a po-previous read to the same address is restarted, 'rr' might
      need to be restarted when it is satisfied. *)
      (exists (prev_inst MEM prefix).
        prev_inst.instance_ioid IN might_restart_prefix &&
        exists (rr' MEM (read_requests_of_subreads prev_inst.subreads)).
          overlapping_slices (rr.r_addr, unsat_slices) 
                             (rr'.r_addr, [complete_slice rr'.r_addr])
      )

      ||

      (* if a po-previous read to the same address has not been issued yet
      'rr' might need to be restarted. *)
      (exists (prev_inst MEM prefix).
       exists ((rr', unsat_slices') MEM prev_inst.subreads.sr_unsat_slices).
          not (read_requested prev_inst rr') &&
          overlapping_slices (rr.r_addr, unsat_slices) 
                             (rr'.r_addr, unsat_slices')
      )

      ||

      (* if a po-previous read to the same address has been issued after
      'rr' and was already satisfied, 'rr' might need to be restarted. *)
      let pop_ts = get_pop_thread_substate state.thread_substate in
      let issued_after = relonRightOf rr pop_ts.read_issuing_order in
      exists (rr' IN issued_after).
          rr'.r_ioid IN prev_ioids &&
          overlapping_slices (rr.r_addr, unsat_slices) 
                             (rr'.r_addr, [complete_slice rr'.r_addr])


let pop_store_might_restart_roots params
    (state:                thread_state 'i)
    (_might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    (inst_tree:            instruction_tree 'i)
    : set (instruction_instance 'i)
  =
  if not (is_viable_memory_store_ii instruction) then {}
  else
    let potential_footprint =
      instruction.subwrites.sw_potential_writes ++
        instruction.subwrites.sw_potential_write_addresses in
    let write_restarts (success : bool) = 
      if success
      then propagate_write_action_restart_roots inst_tree potential_footprint
      else pop_memory_write_exclusive_commit_fail_action_restart_roots
             inst_tree potential_footprint
    in
    if is_atomic_store (ik instruction) then
      (* Nothing means success undetermined, Just true means determined to succeed*)
      match instruction.successful_atomic_store with
      | Nothing -> (write_restarts true) union (write_restarts false)
      | Just b -> write_restarts b
      end
    else
      write_restarts true

let pop_load_might_restart_roots params
    (state:                thread_state 'i)
    (might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    (inst_tree:            instruction_tree 'i)
    : set (instruction_instance 'i)
  =
  if not (is_memory_load_instruction (ik instruction)) then {} else

  if instruction.instance_ioid IN might_restart_prefix ||
       pop_load_sat_might_self_restart params state might_restart_prefix prefix instruction
  then
    (* because the load migh be restarted, we have to assume it will be, and then
       resatisfied, hence the complete slice below. *)
    Set.bigunionMap
      (fun rr -> pop_memory_read_action_restart_roots params state inst_tree rr (SS [complete_slice rr.r_addr]))
      (Set.fromList (read_requests_of_subreads instruction.subreads))
    union {instruction}
  else
    Set.bigunionMap
      (fun (rr, unsat_slices) -> pop_memory_read_action_restart_roots params state inst_tree rr (SS unsat_slices))
      (Set.fromList instruction.subreads.sr_unsat_slices)

let pop_instruction_might_restart_roots params
    (state:                thread_state 'i)
    (might_restart_prefix: set ioid)
    (prefix:               list (instruction_instance 'i))
    (instruction:          instruction_instance 'i)
    (inst_tree:            instruction_tree 'i)
    : set ioid
  =
  if instruction.finished then {} else
    let store_roots =
      pop_store_might_restart_roots 
        params state might_restart_prefix prefix instruction inst_tree
    in
    let load_roots =
      pop_load_might_restart_roots 
        params state might_restart_prefix prefix instruction inst_tree
    in
    Set.map (fun i -> i.instance_ioid) (store_roots union load_roots)


(* Return the set of instructions in 'prefix' that might be
restarted in the future.
ASSUME: all memory access instructions in 'prefix' have calculated
their memory address and all the instructions feeding these
calculations are propagated (i.e. addresses are known and cannot change) *)
let pop_might_be_restarted params
    (state:  thread_state 'i)
    (prefix: list (instruction_instance 'i))
    : set ioid
  =
  let fold prev prefix instruction inst_tree =
    let roots = pop_instruction_might_restart_roots 
                  params state prev prefix instruction inst_tree in
    (* because 'roots' might include 'instruction' we have to push it into
    the instructions tree before calling 'dependent_suffix_to_restart' *)
    let roots_and_dependents =
      dependent_suffix_to_restart roots (T [(instruction, inst_tree)]) in
    prev union roots_and_dependents
  in
  let trees = List.foldl (fun it i -> T [(i, it)]) (T []) prefix in
  Set.bigunion (instruction_tree_fold_root fold {} [] trees)


(* returns true iff a po-previous read request was issued after
'read_request' (i.e. out of order) and was satisfied by a write to the
same address different from 'wss', and 'wss' is not a forward from a
write that is po-after that read request.
NOTE: changes in this function need to be reflected in pop_load_sat_might_self_restart *)
let pop_is_stale_read params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i) (* the load instruction *)
    (read_request: read_request)              (* the read request that is about to be sat. *)
    (wss:          set (write * slices))      (* the writes that are about to sat. the read request *)
    : bool
  =
  not (is_flat_model params) &&

  let full_prefix = (inst_context.active_prefix ++ inst_context.old_prefix) in
  let ioids = {i.instance_ioid | forall (i MEM full_prefix) | true} in

  exists (prev_inst MEM full_prefix).
    exists ((prev_rr, prev_writes) MEM prev_inst.subreads.sr_writes_read_from).
      (not (pop_reads_issued_in_order state prev_rr read_request))
      &&
        overlapping_slices_from_different_writes_not_in_set
          wss (Set.fromList prev_writes) ioids


(** Thread Transition Preconditions and Actions *********************)

(** bits of (shared) commit logic *)

(* check if the instructions feeding register reads are finished.
If an instruction is not finished, recursively check the register write's
dependencies *)
let fully_determined_reg_reads
    (active_prefix: list (instruction_instance 'i))
    (reg_reads:     list (reg_name * register_read_sources * register_value))
    : bool
  =
  Set.null (undetermined_reg_writes_read_from active_prefix reg_reads)


(* true iff the value read from registers that feed directly into a memory
access address of 'instruction' cannot change, and the pseudocode has made
enough steps to make the address visible *)
let fully_determined_address
    (active_prefix: list (instruction_instance 'i))
    (instruction:   instruction_instance 'i)
    : bool
  (* po: head is new. ASSUME: super set of the po-prefix of 'instruction' *)
  =
  (* for efficiency, first check if 'instruction' is finished or not a memory access *)
  instruction.finished ||
  not (is_viable_memory_access_ii instruction) ||

  (* the value read from registers that feed directly into a memory
  access address of 'instruction' cannot change *)
  let addr_reg_reads = 
    [(reg, register_read_sources, v)
       | forall ((reg, register_read_sources, v) MEM instruction.reg_reads)
       | reg IN instruction.regs_in_feeding_address] in
  fully_determined_reg_reads active_prefix addr_reg_reads &&

  (* the pseudocode has made enough steps to make the address visible *)
  (is_viable_memory_store_ii instruction -->
    instruction.subwrites.sw_addr <> Nothing) &&
  (is_memory_load_instruction (ik instruction) -->
    read_footprint_of_load instruction <> Nothing)



let preceding_memory_accesses_have_fully_determined_address iic = 
  forall_iprev_with_prefix iic.active_prefix
    (fun iprev prev_active_prefix ->
     fully_determined_address prev_active_prefix iprev)

let preceding_reads_writes_are_calculated iic = 
  forall (iprev MEM iic.active_prefix).
  all_writes_reads_are_calculated iprev

let dataflow_committed (iic: instruction_in_context 'i) : bool =
  fully_determined_reg_reads iic.active_prefix iic.iic_instance.reg_reads


let controlflow_committed (iic: instruction_in_context 'i) : bool =
  (forall (iprev MEM iic.active_prefix).
      is_cond_branch_ii iprev --> iprev.finished) &&
  (forall (iprev MEM iic.active_prefix).
      is_indirect_branch_ii iprev --> iprev.finished)


let finish_action_prune_instruction_tree_mips isa subtree i'
    : instruction_tree 'i * set ioid = 
  if is_branch_instruction (ik i') then
    match subtree with
    | T [(successor, T iiits)] ->
       (* Prune tree of branch delay instruction *)
       let successor_nia = mips_next_next_pc_of_finished_instruction isa i' in
       (* discard all subtrees that didn't fetch from that address, and all but the first of those *)
       let (iiits, discard) = List.partition (fun (i', _) -> i'.program_loc = successor_nia) iiits in
       (T [(successor, T iiits)], ioids_of_instruction_tree (T discard))
    | T [] -> (subtree, {}) (* branch delay not yet fetched *)
    | _ -> failwith "expected linear subtree following mips branch"
    end
  else
    (subtree, {})

(* also returns the ioids of discarded instructions*)
let finish_action_prune_instruction_tree isa subtree i'
    : instruction_tree 'i * set ioid
  = 
  if isa.isa_model = MIPS then
    finish_action_prune_instruction_tree_mips isa subtree i'
  else
    (* discard any subtrees that don't match the chosen branch  *)
    let nia = next_address_of_finished_instruction isa i' in
    (* discard all subtrees that didn't fetch from that address *)
    (* make sure only one subtree starts with address nia *)
    let (T iiits) = subtree in
    let (iiits, discard) = List.partition (fun (i', _) -> i'.program_loc = nia) iiits in
    let () =
      match iiits with
      | []      -> ()
      | _ :: [] -> ()
      | _       -> failwith "fetched more than once from the same location"
      end
    in
    (T iiits, ioids_of_instruction_tree (T discard))

let finish_action isa state iic =
  let i' = <| iic.iic_instance with finished = true |> in
  let (it_subtree', discarded_ioids) =
    finish_action_prune_instruction_tree isa iic.subtree i' in
  let instruction_tree' = apply_tree_context iic.context (i',it_subtree') in
  let state' = <| state with instruction_tree = instruction_tree' |> in
  (* POP: remove read requests from untaken branches from read_issuing_order *)
  let state'' = remove_reads_from_pop_order state' discarded_ioids in
  let state''' = make_old_instructions isa state'' in
  make_thread_cont_res {} discarded_ioids state'''



let address_from_AArch64_dc_ii (instruction: (instruction_instance 'i)) : maybe address =
  match instruction.instruction_kind with
  | IK_cache_op Cache_op_D_CVAU  ->
    match instruction.reg_reads with
    (* DC CVAU only reads 1 register -- it contains the address *)
    | [(_, _, v)] -> address_of_register_value v
    | _ -> Nothing
    end
  | _ -> Nothing
  end

(* Update an instruction (sub)tree to restart dcs to some address:
 * TODO: when we get DC; po; (R|W)  ordering then this needs updating *)
let handle_restart_dc fp it =
  instruction_tree_map
    (fun prefix i _ ->
      match address_from_AArch64_dc_ii i with
      | Just addr ->
          (* TODO: dc cache line overlap *)
         if footprints_overlap fp (addr, 4)
         then restart_instruction i
         else i
      | Nothing -> i
      end)
  [] it


(* can "finish" a DC only once it becomes non-restartable (see above) 
 * currently we make this a strong requirement that all po-previous instructions
 * are finished.
 *)
let flat_can_finish_dc iic =
  forall (iprev MEM iic.active_prefix). iprev.finished

let propagate_write_action
    (params:        thread_params)
    (state:         thread_state 'i)
    (inst_context:  instruction_in_context 'i)
    (write:         write)
    : thread_cont_res (thread_state 'i)
  =
  let it = inst_context.subtree in
  let i = inst_context.iic_instance in
  let () = ensure (not (atomic_store_determined_to_fail i))
             ("atomic write (ioid " ^ show i.instance_ioid ^ ") "^
                "that was determined to fail has succeeded") in
  let i' = mark_write_as_propagated i write in
  let (it', restarted_ioids) =
    if params.thread_model = Relaxed_thread_model then (it, {})
    else
      let restart_roots = propagate_write_action_restart_roots it [write] in
      restart_dependent_subtrees it restart_roots
  in
  let it'' = handle_restart_dc write.w_addr it' in
  let it''' = apply_tree_context inst_context.context (i', it'') in
  let state' = <| state with instruction_tree = it''' |> in
  let state'' = remove_reads_from_pop_order state' restarted_ioids in
  make_thread_cont_res restarted_ioids {} state''

let failed_write_action
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (write:        write)
    (mos:          micro_op_state 'i)
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let it = inst_context.subtree in
  let () = ensure (not (atomic_store_determined_to_succeed i)) $
    "atomic write (ioid " ^ show i.instance_ioid ^ ") that was determined to succeed has failed" in
  let i' = <| i with subwrites = empty_subwrites i.subwrites;
                     micro_op_state = mos |> in
  let (it', restarted_ioids) =
    let roots = pop_memory_write_exclusive_commit_fail_action_restart_roots it [write] in
    restart_dependent_subtrees it roots
  in
  let state = <| state with instruction_tree = apply_tree_context inst_context.context (i', it') |> in
  let state' = remove_reads_from_pop_order state restarted_ioids in
  make_thread_cont_res restarted_ioids {} state'

(** pldi11 commit candidate *****************************************)

let pldi11_commitPrevMightSameAddress active_prefix footprints =
  forall (iprev MEM active_prefix).
    is_viable_memory_access_ii iprev -->
      (iprev.finished ||
          (* all the instructions that write registers feeding directly into
            a memory access address of iprev are committed*)
          ((forall (iprevprev MEM active_prefix).
            (* it would be enough to just check those before iprev, but more complex *)
        iprevprev.instance_ioid IN iprev.ioids_feeding_address -->
          iprevprev.finished) &&
            (* and iprev cannot produce memory reads or writes that access Unknown
                or anything in i_addresses *)
        not (possibly_reads_or_writes_address iprev footprints)
      ))

let pldi11_commitLoadPrevMightSameAddress iic =
  let fps = footprints_read_from iic.iic_instance.subreads.sr_writes_read_from in
  pldi11_commitPrevMightSameAddress iic.active_prefix fps

let pldi11_propagateWritePrevMightSameAddress iic write =
  pldi11_commitPrevMightSameAddress iic.active_prefix {write.w_addr}

let pldi11_commit_cand
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    : bool =
  let pldi11_substate = get_pldi11_thread_substate state.thread_substate in
  let i = iic.iic_instance in
  (* let program_order_prefix_full = iic.active_prefix ++ iic.old_prefix in *)

  (* NEWTODO: this code depends on equality of register names, but when we have
     register subfields that will need to be fixed *)

  (* dataflow_committed *)
  dataflow_committed iic &&
  (* controlflow_committed *)
  controlflow_committed iic &&
  (* commitPrevMightSameAddress *)
  (is_memory_load_instruction (ik i) -->
      pldi11_commitLoadPrevMightSameAddress iic) &&
   (* commitPrevBarrLS *)
   (is_viable_memory_access_ii i -->
      ((forall (iprev MEM iic.active_prefix).
        (is_sync (ik iprev) || is_lwsync (ik iprev) || is_isync (ik iprev)) --> iprev.finished) &&
      Set.null pldi11_substate.unacknowledged_syncs)) &&
   (* commitPrevBarrSEIEIO *)
   (is_memory_store_instruction (ik i) -->
     forall (iprev MEM iic.active_prefix).
         is_eieo (ik iprev) --> iprev.finished) &&
   (* commitPrevBarrB *)
   (is_barrier (ik i) --> (* this includes isync *)
      ((forall (iprev MEM iic.active_prefix).
         is_barrier (ik iprev) --> iprev.finished) &&
      Set.null pldi11_substate.unacknowledged_syncs)) &&
   (* commitMemoryAccessBeforeBarrier *)
   ((is_sync (ik i) || is_lwsync (ik i)) -->
     forall (iprev MEM iic.active_prefix).
       is_viable_memory_access_ii iprev --> iprev.finished) &&
   (* commitMemoryAccessBeforeBarrierEIEIO *)
   (is_eieio (ik i) -->
     forall (iprev MEM iic.active_prefix).
       is_memory_store_instruction (ik iprev) --> iprev.finished) &&
   (* commitAddressesBeforeIsyncDetermined *)
   (is_isync (ik i) -->
      preceding_memory_accesses_have_fully_determined_address iic) &&
   (* commitPrevLoadAcquire *)
   (is_memory_store_instruction (ik i) -->
     forall (iprev MEM iic.active_prefix).
      is_AArch64_load_acquire (ik iprev) --> finished_load_part iprev) &&
   (* commitStoreRelease *)
   (is_AArch64_store_release (ik i) -->
     forall (iprev MEM iic.active_prefix).
       is_viable_memory_access_ii iprev --> iprev.finished) &&
   (* commitLRSC *)
   ((is_PPC_load_reserve (ik i) || is_PPC_store_conditional (ik i)) -->
     forall (iprev MEM iic.active_prefix).
       (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev)) --> iprev.finished)

let pldi11_finish_cand state iic = 
  iic.iic_instance.subwrites.sw_committed || 
  iic.iic_instance.committed_barriers <> [] || 
  pldi11_commit_cand state iic



(** pldi11 commit actions *******************************************)

let pldi11_memory_write_commit_action_restart_roots
    (i1: (instruction_instance 'i))
    (it: instruction_tree 'i)
    (ws: set write)
    : set (instruction_instance 'i) =
  { isucc | forall (isucc IN instructions_of_tree it) |
    (exists ((w', _) MEM (writes_read_from isucc)). (* TODOREALLY*)
       let ws'' = {w | forall ((w, _) MEM (writes_read_from isucc)) | true} in
       (non_empty_intersection_write_set ws'' ws) && (* TODOREALLY*)
       (not (w' IN ws)) &&
       (not (exists (ioidfeed IN ioids_of_instruction_tree it). (* i.e. successor of i1 *)
               ioidfeed = w'.w_ioid)) (* XXX: do we need to have it in prefix of isucc? believe not *)
    )
  }


let pldi11_mark_barrier_as_unacknowledged state b = 
  let pldi11_substate = get_pldi11_thread_substate state.thread_substate in
  let unacknowledged_syncs =
    Set.insert b pldi11_substate.unacknowledged_syncs in
  let pldi11_substate = <| unacknowledged_syncs = unacknowledged_syncs |> in
  <| state with thread_substate = PLDI11_thread pldi11_substate; |>

let pldi11_mark_barrier_as_acknowledged state b = 
  let pldi11_substate = get_pldi11_thread_substate state.thread_substate in
  let unacknowledged_syncs =
    Set.delete b pldi11_substate.unacknowledged_syncs in
  let pldi11_substate = <| unacknowledged_syncs = unacknowledged_syncs |> in
  <| state with thread_substate = PLDI11_thread pldi11_substate; |>

let pldi11_commit_barrier_action state b =
  match b.b_barrier_kind with
  | Barrier_Sync -> pldi11_mark_barrier_as_unacknowledged state b
  | _ -> state
  end


(** POP commit/propagate/finish candidates ********************************************)

let pop_all_po_preceding_overlapping_reads_issued_and_non_restartable
      params iic write might_be_restarted = 
  (forall (iprev MEM iic.active_prefix).
   forall ((iprev_rr, iprev_unsat_slices) MEM iprev.subreads.sr_unsat_slices).
        (non_empty_intersection write.w_addr iprev_rr.r_addr -->
            (List.null iprev_unsat_slices ||
               (not (is_flat_model params) && read_requested iprev iprev_rr)) &&
            (* and iprev can't be restarted *)
            iprev.instance_ioid NIN might_be_restarted))

let pop_all_po_preceding_overlapping_unpropagated_writes_covered
      prev_unpropagated_writes write = 
  forall (prev_write MEM prev_unpropagated_writes).
  non_empty_intersection write.w_addr prev_write.w_addr -->
    sub_footprint prev_write.w_addr write.w_addr

let pop_no_po_preceding_overlapping_unpropagated_writes
  prev_unpropagated_writes write = 
      forall (prev_write MEM prev_unpropagated_writes).
        not (non_empty_intersection write.w_addr prev_write.w_addr)

(* TODO: SF: I think we should make it so that transitions are only held back by
   po-preceding instructions. In this case, instead of checking the
   po-succeeding loads, we should restart them if the transition is taken. *)
let pop_all_reads_partially_satisfied_by_forwarding_issued_unsat_slices
      params iic write = 
  let issued _ iafter itafter =
    forall ((read_request, write_slices) MEM iafter.subreads.sr_writes_read_from).
      (((List.elem write (writes_of_write_slices write_slices)) &&
        (unsat_slices_of_read_request iafter read_request <> [] ||
           (not (is_flat_model params) &&
              (is_AArch64_load_acquire (ik iafter) || is_RISCV_load_strong_acquire (ik iafter)
              || is_atomic_load (ik iafter)))))
      -->
        read_requested iafter read_request)
  in
  instruction_tree_all issued [] iic.subtree

let pop_write_allowed_to_be_subsumed params inst = 
  params.thread_allow_write_subsumption &&
    not (is_AArch64_store_release (ik inst)) &&
    not (is_RISCV_store_release (ik inst)) &&
    not (is_atomic_store (ik inst))
  
(* aarch64 might-access-same-address (for stores) *)
let pop_write_co_check
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (write:  write)
    : bool
  =
  let might_be_restarted =
    pop_might_be_restarted params state iic.active_prefix in

  (* to guarantee RW-coherence *)
  pop_all_po_preceding_overlapping_reads_issued_and_non_restartable
    params iic write might_be_restarted &&

  (* guarantee WW-co *)
  (forall (iprev MEM iic.active_prefix).
    let prev_unpropagated_writes = unpropagated_writes_of_inst iprev in
    if atomic_store_determined_to_fail iprev then 
      true
    else if pop_write_allowed_to_be_subsumed params iprev then
      pop_all_po_preceding_overlapping_unpropagated_writes_covered
        prev_unpropagated_writes write
    else
      pop_no_po_preceding_overlapping_unpropagated_writes
        prev_unpropagated_writes write
  ) &&

    (* Additions for mixed-size/load-acq/load-exc: (forbid litmus test
       CO-MIXED-20cc) if there is a po-following read that was
       partially satisfied by the store, it must have already issued
       the unsat slices. This is important for single-copy atomicity
       *)
    pop_all_reads_partially_satisfied_by_forwarding_issued_unsat_slices
      params iic write 


let pop_fixed_write write_instr active_prefix : bool = 
  (* PPC store-conditional can fail spontaneously *)
  not (is_PPC_store_conditional (ik write_instr)) && 
  (* RISC-V store-conditional can fail spontaneously *)
  not (is_RISCV_store_conditional (ik write_instr)) && 
  (* all data dependencies (including address) are determined *)
  fully_determined_reg_reads active_prefix write_instr.reg_reads


let rec pop_load_finish_co_check_helper
    (params:              thread_params)
    (state:               thread_state 'i)
    (might_be_restarted:  set ioid)
    (read_request:        read_request)
    (writes_read_from:    list (write * slices))
    (active_prefix:       list (instruction_instance 'i))
    : bool
  =
  match active_prefix with
  | [] -> true
  | inst :: active_prefix ->
      (* memory address of 'inst' is fully determined *)
      fully_determined_address active_prefix inst &&

      (* to simplify the rest of the checks we also require that 'inst' has
         made enough steps to guarantee all the read/write requests are
         recorded in the instruction_instance state. *)
      all_writes_reads_are_calculated inst &&

      (* filter out slices that overlap propagated writes *)
      let writes_read_from = parts_of_read_rf_not_overwritten_by_write
                               writes_read_from read_request inst in

      (* filter out slices that were forwarded from fixed writes *)
      let writes_read_from =
        (* for efficiency check inst.finished (propagated_writes
           covers the propagated case) *)
        if not inst.finished && pop_fixed_write inst active_prefix then
          parts_of_read_rf_not_forwarded_from_write
            writes_read_from read_request inst
        else writes_read_from
      in

      if List.null writes_read_from then true
      else

      (* can't overlap unpropagated writes *)
        not (exists (write MEM (unpropagated_writes_of_inst inst)).
             exists ((w, s) MEM writes_read_from).
             overlapping_slices (write.w_addr, [complete_slice write.w_addr]) (w.w_addr, s))
      &&

      (* overlapping reads must be finished, or non-restartable and
      issued in order with read_request *)
      (finished_load_part inst ||
        match inst.subreads.sr_addr with
        (* not a load instruction (because all_writes_reads_are_calculated) *)
        | Nothing -> true 

        | Just read_footprint' ->
            (exists ((w, s) MEM writes_read_from).
              write_slices_overlaps_with_addr read_footprint' (w, s) )
            -->
            (inst.instance_ioid NIN might_be_restarted &&
            forall ((rr', slices') MEM inst.subreads.sr_unsat_slices).
            (((overlapping_slices_not_in_set (rr', slices') (Set.fromList writes_read_from) {})
            (*(List.null slices' ||
               ((exists ((w, s) MEM writes_read_from).
                 overlapping_slices
                 write_slices_overlaps_with_addr rr'.r_addr (w, s) )*)
                (* see
                   AArch64/mixed-size/HAND/R+dmb.sy+rfipw-poswp-ctrlisb.litmus
                   for why we need to use the complete slice of rr'
                   and not just the unsat slices (slices') *)  
                -->
                not (is_flat_model params) &&
                read_requested inst rr' &&
                pop_reads_issued_in_order state rr' read_request)
            ))
        end)
      &&

      pop_load_finish_co_check_helper
        params state might_be_restarted read_request writes_read_from active_prefix
  end


(* pop might-access-same-address (for loads) The closest po-previous write
   to the same address must be propagated and all memory accesses in-between must
   have a fully determined addresses, except if the closest po-previous write is a
   write that was forwarded to the load, then it does not have to be
   propagated, just "fixed" (i.e. instructions feeding ALL its registers are
   determined). *)
let pop_load_finish_co_check
    (params:             thread_params)
    (state:              thread_state 'i)
    (iic:       instruction_in_context 'i)
    : bool
  =
  (* any observable behaviour that depends on the load being finished
     ([R]; ctrl; [W] or [R]; ctrl+isb; [R] or [Raq]; po; [W] , etc)
     also depends on the po-prefix having fully determined addresses,
     hence it is ok for might_be_restarted to over-approximate if the
     po-prefix does not have fully determined addresses *)

  let might_be_restarted =
    (* to simplify the rest of the checks we also require that iprev
       has made enough steps to guarantee all the read/write requests
       are recorded in the instruction_instance state. *)
    if preceding_memory_accesses_have_fully_determined_address iic &&
         preceding_reads_writes_are_calculated iic
    then pop_might_be_restarted params state iic.active_prefix
    else {inst.instance_ioid | forall (inst MEM iic.active_prefix)
                             | not inst.finished}
  in
  let writes_read_from =
    iic.iic_instance.subreads.sr_writes_read_from in

  forall ((read_request, ws) MEM writes_read_from).
    pop_load_finish_co_check_helper
      params state might_be_restarted read_request ws iic.active_prefix



let pop_commit_barrier_cand
    (params: thread_params)
    (isa: isa 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  let inst = iic.iic_instance in

  dataflow_committed iic &&

  (* we allow RISC-V fences to commit and finish on speculated branches;
  This is needed to allow MP+fence.rw.rw+ctrlfence.w.r and
  SB+fence.rw.rw+ctrlfence.r.rxp *)
  (isa.isa_model <> RISCV --> controlflow_committed iic) &&

  (* commit order between barriers *)
  match (isa.isa_model, is_flat_model params) with
  | (AARCH64 _, true) ->
     (is_pop_strong_memory_barrier (ik inst) -->
      forall (iprev MEM iic.active_prefix).
      (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
      --> iprev.finished) &&
       
     (forall (iprev MEM iic.active_prefix).
      is_pop_strong_memory_barrier (ik iprev) --> iprev.finished)

  | (AARCH64 _, false) ->
     forall (iprev MEM iic.active_prefix).
     (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
     --> iprev.finished

  | (PPC, _) ->
    forall (iprev MEM iic.active_prefix).
    (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
    --> iprev.finished

  | (MIPS, _) ->
     forall (iprev MEM iic.active_prefix).
     (is_pop_memory_barrier (ik iprev) || is_pop_instruction_barrier (ik iprev))
     --> iprev.finished

  | (RISCV, _) -> true
  | (X86, _) -> true
  end &&

  (is_pop_strong_memory_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
    is_viable_memory_access_ii iprev --> iprev.finished) &&

  (is_pop_instruction_barrier (ik inst) -->
      preceding_memory_accesses_have_fully_determined_address iic) &&

  (* Additions for barrier.ld / Fence_r_xx: *)
  ((is_AArch64_ld_barrier (ik inst) || is_RISCV_fence_pr (ik inst)) -->
    forall (iprev MEM iic.active_prefix).
    is_memory_load_instruction (ik iprev) --> finished_load_part iprev) &&

  (* Additions for barrier.st / Fence_w_xx: *)
  ((is_AArch64_st_barrier (ik inst) || is_RISCV_fence_pw (ik inst)) -->
    (forall (iprev MEM iic.active_prefix).
     is_memory_store_instruction (ik iprev) --> iprev.finished)) &&

  (* Additions for lwsync: *)
  (is_lwsync (ik inst) -->
    (forall (iprev MEM iic.active_prefix).
     is_viable_memory_access_ii iprev --> iprev.finished)) &&

  (* Additions for eieio: *)
  (is_eieio (ik inst) -->
    (forall (iprev MEM iic.active_prefix).
     is_memory_store_instruction (ik iprev) --> iprev.finished)) &&

  (* we commit fence.tso only after all po-previous memory accesses
     are finished; po-later stores can be committed only after the
     fence.tso is finished; po-later loads can be satisfied only
     after all loads preceding the fence.tso are satisfied *)
  (is_RISCV_fence_tso (ik inst) -->
    forall (iprev MEM iic.active_prefix).
    is_viable_memory_access_ii iprev --> iprev.finished) &&

  (* for IC/DC *)
  (is_AArch64_dc_wait_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
    is_AArch64_dc_instr (ik iprev) --> iprev.finished) &&

  (is_AArch64_ic_wait_barrier (ik inst) -->
    forall (iprev MEM iic.active_prefix).
    is_AArch64_ic_instr (ik iprev) --> iprev.finished)


let pop_commit_store_cand
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  let instr = iic.iic_instance in

  (* all po-previous memory addresses are fully determined *)
  preceding_memory_accesses_have_fully_determined_address iic &&
  (* to simplify the rest of the checks we also require that iprev
     has made enough steps to guarantee all the read/write requests
     are recorded in the instruction_instance state. *)
  preceding_reads_writes_are_calculated iic &&


  dataflow_committed iic &&
  controlflow_committed iic &&

  (forall (iprev MEM iic.active_prefix).
    (is_pop_strong_memory_barrier (ik iprev) || 
       is_pop_instruction_barrier (ik iprev))
    --> iprev.finished) &&

  (* Additions for barrier.st/ld / fence_xx_w: *)
  (forall (iprev MEM iic.active_prefix).
      (is_AArch64_st_barrier (ik iprev) --> iprev.finished) &&
      (is_AArch64_ld_barrier (ik iprev) --> iprev.finished) &&
      (is_RISCV_fence_sw (ik iprev) --> iprev.finished)) &&

  (* Additions for load.acquire/store.release: *)
  (* TODO: the following might be too strong, a previous read only
  needs to be issued and non-restartable. *)
  ((is_AArch64_store_release (ik instr) || is_RISCV_store_release (ik instr)) -->
    (forall (iprev MEM iic.active_prefix).
     is_viable_memory_access_ii iprev --> iprev.finished)) &&

  (forall (iprev MEM iic.active_prefix).
   (is_AArch64_load_acquire (ik iprev) || is_RISCV_load_acquire (ik iprev)) --> 
   finished_load_part iprev) &&

  (* Additions for ARM load/store-exclusive, RISC-V
     load-reserve/store-conditional: *)
  ((is_AArch64_store_exclusive (ik instr)  || 
      (is_RISCV_store_conditional (ik instr) && not (is_RISCV_AMO (ik instr))))
   -->
      let atomic_load = ensure_just (paired_atomic_load iic)
          "can't find the paired load of a successful atomic store"
          (* failed store-exclusive uses a different _cand function *)
      in
      finished_load_part atomic_load &&
      (* RISC-V note: the following matches the RVWMO Atomicity
         Axiom assertion "then 's' must precede 'w' in the global
         memory order". When the lr and sc are to the same address
         this has no effect as the co-check will make sure 's' is
         done before 'w', but when they are to a different address
         this is observable. See LR-SC-diff-loc4.litmus (forbidden)
         *)
      forall ((_, rf) MEM atomic_load.subreads.sr_writes_read_from) ((w, _) MEM rf).
      w.w_thread = state.thread -->
      forall (iprev MEM iic.active_prefix).
      iprev.instance_ioid = w.w_ioid -->
      List.elem w iprev.subwrites.sw_propagated_writes) &&

  (* Additions for lwsync: *)
  (forall (iprev MEM iic.active_prefix).
      is_lwsync (ik iprev) --> iprev.finished) &&

  (* Additions for eieio: *)
  (forall (iprev MEM iic.active_prefix).
      is_eieio (ik iprev) --> iprev.finished) &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_store_conditional (ik instr) -->
      paired_atomic_load iic <> Nothing &&
      (forall (iprev MEM iic.active_prefix).
          (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev))
            --> iprev.finished)) &&

  (*** Additions for RISC-V fence.tso ***)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_fence_tso (ik iprev) --> iprev.finished) &&

  (*** Additions for RISC-V store acquire ***)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_store_acquire (ik iprev) --> iprev.finished)


let pop_finish_simple_cand
    (_state:  thread_state 'i)
    (iic:     instruction_in_context 'i)
    : bool
  =
  dataflow_committed iic &&
  controlflow_committed iic


let pop_finish_load_cand_barrier_part
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  (* Additions for load.acquire/store.release: *)
  (forall (iprev MEM iic.active_prefix).
   (is_AArch64_load_acquire (ik iprev) || is_RISCV_load_acquire (ik iprev))
    --> finished_load_part iprev) &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_load_reserve (ik iic.iic_instance) -->
    (forall (iprev MEM iic.active_prefix).
        (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev))
        --> iprev.finished)) &&

  (*** Additions for RISCV fences ***)
  (* this is just to make sure "fence r,r" and "fence r,rw" are finished
  (the other fences will already be finished, see read-req-cand) *)
  (forall (iprev MEM iic.active_prefix).
      is_RISCV_fence_sr (ik iprev) --> iprev.finished) &&

  (forall_iprev_with_prefix iic.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_tso (ik prev_inst) -->
        (prev_inst.finished ||
        forall (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
              --> finished_load_part prev_prev_inst))

let pop_finish_load_cand
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : bool
  =
  pop_finish_simple_cand state iic &&
  pop_finish_load_cand_barrier_part state iic &&
  pop_load_finish_co_check params state iic


let pop_finish_cand params state (iic: instruction_in_context 'i) : bool =
  if is_AArch64_dc_instr (ik iic.iic_instance) then
    flat_can_finish_dc iic
  else if iic.iic_instance.subwrites.sw_committed then
    true
  else if iic.iic_instance.committed_barriers <> [] then
    true
  else if is_memory_load_instruction (ik iic.iic_instance) then
    pop_finish_load_cand params state iic
  (* The following two cases seem like some leftovers from something. The above
     committed_barriers <> [] case already covers these, so I don't know why
     they are here. *)
  else if is_RISCV_fence_pr (ik iic.iic_instance) then
    true
  else if is_RISCV_fence_pw (ik iic.iic_instance) then
    true
  else
    pop_finish_simple_cand state iic


(** Transition a load to MOS_pending_mem_read ***********************)

let pldi11_memory_read_storage_cand (state: thread_state 'i) (iic: instruction_in_context 'i) : bool =
  let i = iic.iic_instance in
  (*let program_order_prefix_full = iic.active_prefix ++ iic.committed_prefix in*)
  (forall (iprev MEM iic.active_prefix).
    (is_sync (ik iprev) || is_isync (ik iprev) || is_lwsync (ik iprev)) --> iprev.finished) &&
  (Set.null (get_pldi11_thread_substate state.thread_substate).unacknowledged_syncs) &&
  (is_PPC_load_reserve (ik i) -->
      (forall (iprev MEM iic.active_prefix).
        (is_PPC_load_reserve (ik iprev) || is_PPC_store_conditional (ik iprev)) --> iprev.finished))



let pop_memory_read_request_cand params (inst_context: instruction_in_context 'i) : bool =
  let instruction = inst_context.iic_instance in

  (* NOTE: we don't check po-previous instructions to the same address.
     See also private comment THREAD1 *)
  (forall (prev_inst MEM inst_context.active_prefix).
      is_pop_strong_memory_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* See private comment THREAD2 *)
  (forall (prev_inst MEM inst_context.active_prefix).
       is_pop_instruction_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* Additions for barrier.st/ld: *)
  (forall (prev_inst MEM inst_context.active_prefix).
      is_AArch64_ld_barrier (ik prev_inst) --> prev_inst.finished) &&

  (* Additions for load.acquire/store.release: *)
  (* A Store-Release followed by a Load-Acquire is observed in program order *)
  ((is_AArch64_load_acquire (ik instruction) || 
    is_RISCV_load_strong_acquire (ik instruction)) -->
      forall (prev_inst MEM inst_context.active_prefix).
          (is_AArch64_store_release (ik prev_inst) || 
           is_RISCV_store_strong_release (ik prev_inst))
          --> prev_inst.finished) &&

  (* All po-previous Load-acquires must issue their requests before the
  read request. Also see private note THREAD3 *)
  (forall (prev_inst MEM inst_context.active_prefix).
      (is_AArch64_load_acquire (ik prev_inst) || 
         is_RISCV_load_acquire (ik prev_inst))
      -->
      (finished_load_part prev_inst ||
      is_entirely_satisfied_load prev_inst)) &&

  (* Additions for lwsync: *)
  (* all loads that are po-followed by lwsync in active_prefix are finished *)
  List.dropWhile (fun i -> not (is_lwsync (ik i))) inst_context.active_prefix
  $> List.dropWhile (fun i -> is_memory_load_instruction (ik i) --> finished_load_part i)
  $> List.null &&

  (* Additions for load-reserve/store-conditional: *)
  (is_PPC_load_reserve (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix).
          (is_PPC_load_reserve (ik prev_inst) || is_PPC_store_conditional (ik prev_inst))
          --> prev_inst.finished) &&

  (*** Additions for RISCV fences ***)
  (forall_iprev_with_prefix inst_context.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_sr (ik prev_inst) -->
        (prev_inst.finished ||
        (is_RISCV_fence_pr (ik prev_inst)
          && not (is_RISCV_fence_pw (ik prev_inst))
          && forall (prev_prev_inst MEM prev_active_prefix).
                is_memory_load_instruction (ik prev_prev_inst)
                  --> is_entirely_satisfied_load prev_prev_inst))) &&

  (forall_iprev_with_prefix inst_context.active_prefix $ fun prev_inst prev_active_prefix ->
      is_RISCV_fence_tso (ik prev_inst) -->
        (prev_inst.finished ||
        forall (prev_prev_inst MEM prev_active_prefix).
            is_memory_load_instruction (ik prev_prev_inst)
              --> is_entirely_satisfied_load prev_prev_inst)) &&

  (*** Additions for RISCV load-release/store-acquire ***)
  (is_RISCV_load_release (ik instruction) -->
      forall (prev_inst MEM inst_context.active_prefix). prev_inst.finished) &&
  (forall (prev_inst MEM inst_context.active_prefix).
      is_RISCV_store_acquire (ik prev_inst) --> prev_inst.finished)

(** Action *)

let initiate_subreads (addr,size) read_requests = 
  <|  sr_addr = Just (addr, size);
      sr_unsat_slices = [(rr, [complete_slice rr.r_addr]) | forall (rr MEM read_requests) | true];
      sr_writes_read_from = [(rr, []) | forall (rr MEM read_requests) | true];
      sr_requested = [];
      sr_assembled_value = Nothing;
  |>

let initiate_reads i (addr,size) read_requests = 
  let subreads = initiate_subreads (addr,size) read_requests in
  <| i with subreads = subreads |>



let initiate_subwrites subwrites (addr,size) potential_write_addresses = 
  <| subwrites with sw_addr = Just (addr, size);
                    sw_potential_write_addresses = potential_write_addresses |>

let initiate_writes i (addr,size) potential_write_addresses = 
  let subwrites' =
    initiate_subwrites i.subwrites (addr,size) potential_write_addresses in
  <| i with subwrites = subwrites' |>



let instantiate_subwrites subwrites writes = 
  <| subwrites with sw_potential_write_addresses = [];
                    sw_potential_writes = writes |>

let instantiate_writes i writes = 
  let subwrites' = instantiate_subwrites i.subwrites writes in
  <| i with subwrites = subwrites' |>


let initiate_read_action params
    (isa:          isa 'i)
    (state:        thread_state 'i)
    (iic:          instruction_in_context 'i)
    (read_kind:    read_kind)
    ((addr, size): footprint)
    (inst_cont:    memory_value -> outcome unit)
  =
  let (read_requests, i') =
    (if params.thread_restriction = RestrictionSC
     then make_single_atomic_read_request_event_ii
     else make_read_request_events_ii)
      isa state.thread iic.iic_instance (addr, size) read_kind
  in
  let c () = 
    let i' = initiate_reads i' (addr,size) read_requests in
    let mos = if is_RISCV_AMO (ik iic.iic_instance) 
              then MOS_AMO_lock inst_cont
              else MOS_pending_mem_read inst_cont in
    let i' = <|  i' with micro_op_state = mos |> in
    let it = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it |> in
    make_thread_cont_res {} {} state'
  in
  (read_requests,c)


(** Satisfy memory read by write received from storage subsystem ****)

let pldi11_memory_read_action_restart_roots params
  (i:instruction_instance 'i)
  (it: instruction_tree 'i)
  (r:read_request)
  (wss: set (write*slices))   (* the write slices read from by the
                                 read being satisfied *)
  : set (instruction_instance 'i) =
  (* check if there's a footprint intersection where they've read from
     different writes *)
  (* satisfyReadRestarts *)
  { isucc | forall (isucc IN instructions_of_tree it) |
    (overlapping_slices_from_different_writes_not_in_set
       wss
       (Set.fromList (writes_read_from isucc))
       (ioids_of_instruction_tree it)) (* i.e. successor of i*)
    (** && (* TODOREALLY the previous code did this ifeed stuff, which
       I now deal with with the third argument to
       non_empty_... above. Correctly? *) (not (exists (ifeed IN
       instructions_of_tree it). (* i.e. successor of i *)
       ifeed.instance_ioid = w'.w_ioid)) (* XXX: do we need to have it
       in prefix of isucc? believe not *) *)
    (* NEWTODO DONE? handle the write_possibly_done_by stuff - does it
       need to look at the whole prefix, or the active one, or just
       after the read?

     (not (exists (i' IN t.in_flight_instructions).

    (* correspondence between text (which here doesn't say "(where the
       read was not forwarded)") and the use of write_possibly_done_by
       below isn't terribly clear *) write_possibly_done_by t.thread
       i'.behaviour w')) *)

  }



(* this function is used by both PLDI11 and POP *)
let read_unmapped_memory_action state iic rr slices =
  let mos = MOS_pending_exception (ET_read_from_unmapped_memory rr slices) in
  let i' = <| iic.iic_instance with micro_op_state = mos |> in
  let it = apply_tree_context iic.context (i', iic.subtree) in
  let s = <| state with instruction_tree = it |> in
  make_thread_cont_res {} {} s

let write_unmapped_memory_action state iic writes =
  let mos = MOS_pending_exception (ET_write_to_unmapped_memory writes) in
  let i' = <| iic.iic_instance with micro_op_state = mos |> in
  let it = apply_tree_context iic.context (i', iic.subtree) in
  let s = <| state with instruction_tree = it |> in
  make_thread_cont_res {} {} s



let pldi11_satisfy_read_action params state iic rr (mrss: list memory_read_source) =
  let i = iic.iic_instance in
  let new_writes_read_from = List.concatMap (fun mrs -> mrs.mrs_writes_read_from) mrss in
  let writes_previously_read_from = sat_slices_of_read_request i rr in
  let writes_read_from = new_writes_read_from ++ writes_previously_read_from in
  let i' = mark_read_as_satisfied i rr [] writes_read_from in
  (* we do the memory_read_action restart stuff on the suffix *)
  (* (we could defer the restart stuff to the actually_satisfy part,
     but it's probably clearer in the UI to have it here) *)
  (* TODO: assuming restarts for the writes_previously_read_from (by forwarding) already dealt with elsewhere*)
  let (it', restarted_ioids) =
    let it = iic.subtree in
    let roots = pldi11_memory_read_action_restart_roots
                  params i it rr (Set.fromList new_writes_read_from) in
    restart_dependent_subtrees it roots
  in
  let it'' = apply_tree_context iic.context (i', it') in
  let state' = <| state with instruction_tree = it'' |> in
  make_thread_cont_res restarted_ioids {} state'




let pop_satisfy_stale_read_from_memory_action
    (state:         thread_state 'i)
    (iic:           instruction_in_context 'i)
    (_request:      read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  (* NOTE: maybe, instead of restarting the instruction we should just
     allow 'request' to be re-issued? Things to consider: - when a
     write is propagated how do we know an non-finished po-previous
     read to the same address will not be re-issued?  - when a store
     is committed and a write from the store was forwarded to a
     po-after read but only partially satisfied the read, we must make
     sure the other half of the read was issued and will not be
     re-issued after the store is committed (since po-after
     instructions don't have a fully determined addresses this is
     extra tricky).  - a read can be issued only after all po-previous
     load-acquires have been issued. Therefore when a load-acquire is
     allowed to be re-issued we need to do something with po-after
     loads. *)
    let (it', restarted_ioids) =
      restart_dependent_subtrees
        (T [(iic.iic_instance, iic.subtree)]) {iic.iic_instance}
    in
    let inst_and_it' =
      match it' with
      | T [inst_and_it'] -> inst_and_it'
      | _ -> failwith "expected rooted tree"
      end
    in
    let it' = apply_tree_context iic.context inst_and_it' in
    let state' = <| state with instruction_tree = it' |> in
    let state'' = remove_reads_from_pop_order state' restarted_ioids in
    make_thread_cont_res restarted_ioids {} state''


(* the reply from storage includes the forward-writes, but they might
   be old (from when the read was issued), so we need to set the value
   for writes that were forwarded without value. This only does
   anything if there is symbolic forwarding. *)
let pop_read_from_memory_update_forward_writes iic request write_slices =
  (* as this is the point where we get the reply from storage, any
     write in sr_writes_read_from must be from write-forwarding *)
  let forward_writes = sat_slices_of_read_request iic.iic_instance request in
  let update_write_forwarding_value write =
    match List.find (fun (w', _) -> w'.weiid = write.weiid) forward_writes with
    | Just (w', _)  -> w'
    | Nothing -> write
    end
  in
  let write_slices = [(update_write_forwarding_value w, s) 
                        | forall ((w, s) MEM write_slices) | true] in
  write_slices

  

let pop_satisfy_read_from_memory_action params
    (state:         thread_state 'i)
    (iic:           instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let write_slices = pop_read_from_memory_update_forward_writes
                       iic request write_slices in
  (* In Flat is_stale_read never holds *)
  if pop_is_stale_read params state iic request (Set.fromList write_slices)
  then pop_satisfy_stale_read_from_memory_action state iic request write_slices
  else
    let instruction' =
      mark_read_as_satisfied iic.iic_instance request [] write_slices in
    (* do restarts *)
    let (it', restarted_ioids) =
      let roots = pop_memory_read_action_restart_roots
                    params state iic.subtree request
                    (WSS (Set.fromList write_slices)) in
      restart_dependent_subtrees iic.subtree roots
    in
    let it'' = handle_restart_dc request.r_addr it' in
    let it''' = apply_tree_context iic.context (instruction', it'') in
    let state' = <| state with instruction_tree = it''' |> in
    let state'' = remove_reads_from_pop_order state' restarted_ioids in
    make_thread_cont_res restarted_ioids {} state''


let tso_satisfy_read_from_memory_action
    (state:         thread_state 'i)
    (iic:           instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let i' = mark_read_as_satisfied iic.iic_instance request [] write_slices in
  let it' = apply_tree_context iic.context (i', iic.subtree) in
  let state' = <| state with instruction_tree = it' |> in
  make_thread_cont_res {} {} state'


let relaxed_satisfy_read_from_memory_action
    (state:         thread_state 'i)
    (iic:           instruction_in_context 'i)
    (request:       read_request)
    (write_slices:  list (write * slices))
    : thread_cont_res (thread_state 'i)
  =
  let i' = mark_read_as_satisfied iic.iic_instance request [] write_slices in
  let it' = apply_tree_context iic.context (i', iic.subtree) in
  let state' = <| state with instruction_tree = it' |> in
  make_thread_cont_res {} {} state'


let satisfy_read_action params
    (state:        thread_state 'i)
    (iic:          instruction_in_context 'i)
    (read:         read_request)
    (mrss : list memory_read_source)
    : thread_cont_res (thread_state 'i)
  =
  match params.thread_model with
  | PLDI11_thread_model -> pldi11_satisfy_read_action params state iic read mrss
  | POP_thread_model _ ->
     let mrs = ensure_singleton mrss "expected one mrs" in
     pop_satisfy_read_from_memory_action params state iic read mrs.mrs_writes_read_from
  | TSO_thread_model ->
     let mrs = ensure_singleton mrss "expected one mrs" in
     tso_satisfy_read_from_memory_action state iic read mrs.mrs_writes_read_from
  | Promising_thread_model -> fail
  | Relaxed_thread_model ->
     let mrs = ensure_singleton mrss "expected one mrs" in
     relaxed_satisfy_read_from_memory_action state iic read mrs.mrs_writes_read_from
  end



(** Satisfy memory read by forwarding in-flight write directly to reading instruction *)



let pop_nonforward_writes_of_instr params
  (from: instruction_instance 'i)
  (to: instruction_instance 'i)
   = 
  if (is_AArch64_load_acquire (ik to) && 
        is_AArch64_store_exclusive (ik from))
       || is_RISCV_store_conditional (ik from)
       || is_PPC_store_conditional (ik from)
  then
    all_writes_of_inst from
  else if is_pop_not_flat_model params then
    from.subwrites.sw_propagated_writes
  else
    from.subwrites.sw_propagated_writes ++
      from.subwrites.sw_potential_write_addresses


(* TODO: this function was written for POP, Susmit should make sure it works for
PLDI11 and if it does remove the pop_ prefix from the name *)
let pop_possible_write_forward_slices
      (params:       thread_params)
      (isa:          isa 'i)
      (state:        thread_state 'i)
      (iic:          instruction_in_context 'i)
      (rr:           read_request)
      (unsat_slices: slices)
    : slices * list (write * slices) (* unsat-read-slices, writes-read-from-slices *)
  =
  let i = iic.iic_instance in

  (* Collect all the write slices that can affect the forward (i.e. be
     forwarded or block forwarding). The propagated writes are used
     for blocking other writes: although propagated writes are not
     forwarded, we record them so they can cover other writes in the
     initial call to match_writes. We also record writes that other
     loads read from, to block po-earlier writes; but here we don't
     take writes from this thread, we will get them from the store
     instructions *)
  let relevant_write_slices =
    let relevant iprev = 
      complete_writes (unpropagated_writes_of_inst iprev ++
                       propagated_writes_of_inst iprev) ++
        [(w,s) | forall ((w,s) MEM (writes_read_from iprev)) 
               | w.w_thread <> state.thread]
    in
    List.concatMap relevant iic.active_prefix in

  (* find out what slices can be read from *)
  let (_, write_slices) =
    match_writes rr.r_addr unsat_slices relevant_write_slices [] in

  (* Exclude propagated writes from being forwarded. When running any
     model other than POP for ARM, also forbid forwarding from writes
     that do not have their value yet. In POP for ARMv8 we will try to
     forward these writes, see private comments THREAD4 and THREAD5.
     Moreover, forbid certain write forwarding: In AArch64, don't
     forward store-exclusives to load-acquire -- also see private note
     THREAD6. In PPC, don't forward store-conditionals. In RISC-V,
     don't forward store-conditionals *)
  let nonforward_writes =
    List.concatMap (fun iprev -> pop_nonforward_writes_of_instr params iprev i)
      iic.active_prefix in

  (* remove slices we should not be forwarding (i.e. propagated or from
  other threads) *)
  let clean_write_slices =
    [(w,s) | forall ((w,s) MEM write_slices)
           | not (List.elem w (nonforward_writes)) &&
             w.w_thread = state.thread]
  in

  (* the second element of the result should be exactly the same as
  clean_write_slices, we need this call to get the correct first element,
  the 'unsat-read-slices' *)
  match_writes rr.r_addr unsat_slices clean_write_slices []


(* TODO: (SF) I copied the pop function and made minor changes to adopt
it to PLDI11, Susmit should check it *)
let pop_and_pldi11_satisfy_read_by_forwarding_action params
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (request:      read_request)
    ((unsat_slices:  slices),
     (writes: list (write * slices)))
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let write_slices = writes ++ (sat_slices_of_read_request i request) in
  let i' = mark_read_as_satisfied i request unsat_slices write_slices in
  (* do restarts *)
  let (it', restarted_ioids) =
    let it = inst_context.subtree in
    let roots = match params.thread_model with
      | POP_thread_model _ ->
         pop_memory_read_action_restart_roots
           params state it request (WSS (Set.fromList writes))
      | PLDI11_thread_model ->
         pldi11_memory_read_action_restart_roots
           params i it request (Set.fromList writes)
      | _ -> fail
      end
    in
    restart_dependent_subtrees it roots
  in
  let it'' = match params.thread_model with
    | POP_thread_model _ -> handle_restart_dc request.r_addr it'
    | _ -> it'
  end in
  let it''' = apply_tree_context inst_context.context (i', it'') in
  let state' = <| state with instruction_tree = it''' |> in
  let state'' = remove_reads_from_pop_order state' restarted_ioids in
  make_thread_cont_res restarted_ioids {} state''

let ensure_no_loop_if_forbidden params tid prefix addr : unit = 
  if params.thread_fail_on_loop then
    ensure (not (exists (i MEM prefix). i.program_loc = addr))
      ("found a loop in thread " ^ show tid)
  else ()

let reached_loop_limit params complete_prefix addr = 
  match (params.thread_loop_unroll_limit, complete_prefix) with
  | (Nothing, _) -> false
  | (_, [])      -> false
  | (Just limit, iprev :: _) ->
     addr <= iprev.program_loc
     && exists (i MEM complete_prefix). i.program_loc = addr
     && (_count_pairs complete_prefix iprev.program_loc addr 0) + 1 >= limit
  end

let init_fetch_instruction params
    (state:           thread_state 'i)
    (complete_prefix: list (instruction_instance 'i))
    (addr : address)
    : FreshIds.id_state thread_id * instruction_instance 'i
  =
  let () = ensure_no_loop_if_forbidden
             params state.thread complete_prefix addr in
  let (ioid', id_state') = FreshIds.gen_fresh_id state.id_state in
  let i' = starting_fetch_inst params ioid' addr in
  if reached_loop_limit params complete_prefix addr then
    let mos = MOS_pending_exception ET_loop_limit_reached in
    let i' = <| i' with micro_op_state = mos |> in
    (id_state', i')
  else
    (id_state', i')

let get_fetch_instruction_continuation
    (isa :         isa 'i)
    (state:        thread_state 'i)
    (inst_context: instruction_in_context 'i)
    (addr:         address)
    (f : fetch_result 'i)
    : thread_cont_res (thread_state 'i)
  =
  let i = inst_context.iic_instance in
  let i =
    match f with
    | Fetched_FDO FDO_unpredictable_fetch ->
       <| i with micro_op_state = MOS_unpredictable |>
    | _ ->
       let fdo = fdo_from_fetch_result f in
       let instr = match fdo with
         | FDO_success _ _ ast -> Fetched ast
         | _ -> Fetch_error
       end in
       <| i with micro_op_state = MOS_fetched f;
                 instruction = instr
       |>
    end
  in
  let it' = apply_tree_context inst_context.context (i,inst_context.subtree) in
  let state' = <| state with instruction_tree = it' |> in
  let state'' = make_old_instructions isa state' in
  make_thread_cont_res {} {} state''


(**: \subsubsection{The Collected Thread Transitions} :*)

(* enumerate all thread-initiated transitions *)

(* is the result of a thread transition uniformly a new thread_state?  No,
   because some of them need data from the storage subsystem, so the
   thread_trans will contain a suitable continuation *)

(* does a thread transition uniformly arise from a particular instruction
   instance?  I guess so, except for the initial fetch, and so we can uniformly
   include an ioid (or the whole instruction_instance?) in the result *)

let po_predecessors_all_finished (iic: instruction_in_context 'i) : bool =
  forall (iprev MEM iic.active_prefix).
    iprev.finished


(** enumerate all instruction transitions of thread *****************)

let handle_read_mem_outcome params
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    ((read_kind: read_kind),(addr_lifted: address_lifted),(size: nat))
    (cont: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let addr = ensure_just (address_of_address_lifted addr_lifted)
               "Read_mem from a non-concrete address" in
  let (_read_requests,c) = 
    initiate_read_action params isa state iic read_kind (addr,size) cont in
  [T_only (make_label state iic T_pending_memory_read_request c)]


let initiate_write_action
    (params: thread_params)
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    ((write_kind: write_kind),(addr: address),(size: nat))
    (is': outcome unit)
  = 
  let i = iic.iic_instance in
  let (potential_write_addrs, i') =
    (if params.thread_restriction = RestrictionSC
     then make_single_atomic_empty_write_event_ii 
     else make_empty_write_events_ii)
      isa state.thread i (addr, size) write_kind
  in
  let c = fun () ->
    let i' = initiate_writes i (addr,size) potential_write_addrs in
    let i' = <| i' with micro_op_state = MOS_plain is' |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  (potential_write_addrs, c)


let handle_write_ea_outcome
    (params: thread_params)
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    ((write_kind: write_kind),(addr_lifted: address_lifted),(size: nat))
    (is': outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* Are we (1) going to try committing a Write_mem (including
     write-conditionals, remember) as soon as we see it (eagerly doing remaining
     register transitions), or (2) somehow remember the bool continuation and
     progress (depending on some heavy constraints on what write-conditionals do
     'after' the write), or (3) commit the Write_mem as soon as we see it, but
     leave the instruction in a committed-but-not-yet-finished state, with the
     remaining register transitions still to do?  Option (3). *)

  (* THIS IS A BIT OUT OF DATE Our new scheme involves committing an instruction
     at the point it hits a write, but for write forwarding we have to be able
     to see a write that the pseudocode of an instruction has reached even if
     commit_cand is still false.  That suggests we should split the commit-write
     transition into two: one (T_potential_mem_write_plain) to note the write as
     potentially available for forwarding (but subject to restart) and one
     (T_commit_mem_write_plain) to commit that write, with an intermediate
     MOS_potential_mem_write micro-op state *)
  let addr = ensure_just (address_of_address_lifted addr_lifted)
               "Write_mem to a non-concrete address" in
  let (potential_write_addrs, c) =
    initiate_write_action params isa state iic (write_kind,addr,size) is' in
  [T_only (make_label state iic (T_mem_write_footprint potential_write_addrs) c)]


let pop_update_write_forwarding_values updated_writes it : instruction_tree 'i = 
  let update_write write =
    match List.find (fun w' -> w'.weiid = write.weiid) updated_writes with
    | Just w' -> w'
    | Nothing -> write
    end
  in
  let update_write_slices (writes: list (write * slices)) =
    [(update_write w, s) | forall ((w, s) MEM writes) | true] in
  let update_instruction i =
    let writes_read_from = i.subreads.sr_writes_read_from in
    let writes_read_from' = 
      [(rr, update_write_slices ws) 
         | forall ((rr, ws) MEM writes_read_from) | true] in
    let subreads' =
      <| i.subreads with sr_writes_read_from = writes_read_from' |> in
    <| i with subreads = subreads' |>
  in
  instruction_tree_map (fun _ i _ -> update_instruction i) [] it

let instantiate_write_action params
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (value: memory_value)
    (cont: bool -> outcome unit)
  = 
  let writes =
    Events.set_write_values
      value iic.iic_instance.subwrites.sw_potential_write_addresses [] in
  let c' = fun () ->
    let i' = instantiate_writes iic.iic_instance writes in
    let i' = <| i' with micro_op_state = MOS_potential_mem_write cont |> in
    let it' =
      if is_flat_model params then iic.subtree
      else pop_update_write_forwarding_values writes iic.subtree
    in
    let it'' = apply_tree_context iic.context (i', it') in
    <| state with instruction_tree = it'' |>
  in
  (writes,c')

let handle_write_memv_outcome params
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (value: memory_value)
    (cont: bool -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let () = ensure (iic.iic_instance.subwrites.sw_potential_write_addresses <> []) 
             "expected to have potential_write_addresses" in
  let (writes,c) = instantiate_write_action params state iic value cont in
  let c () = make_thread_cont_res {} {} (c ()) in
  [T_only (make_label state iic (T_mem_potential_write writes) c)]

let cache_maintenance_ic_action
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (addr:   address) 
    (o: outcome unit)
  =
  let c () =
    let i' = <| iic.iic_instance with micro_op_state = MOS_wait_IC o |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  c
    

let cache_maintenance_dc_action
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (addr:   address)
    (o:      outcome unit)
  =
  let c () =
    let i' = <| iic.iic_instance with micro_op_state = MOS_plain o |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  c



let mark_barrier_as_committed b i = 
  <| i with committed_barriers = b :: i.committed_barriers |>

let restart_fetch params i =
  match i.micro_op_state with
  | MOS_not_fetched ->
     starting_fetch_inst params i.instance_ioid i.program_loc
  | MOS_fetched _ ->
     starting_fetch_inst params i.instance_ioid i.program_loc
  | s -> i
  end 

let restart_all_fetches_that params it p = 
  instruction_tree_map
    (fun _ i _ -> if p i then restart_fetch params i else i)
    []
    it


let commit_isb_action_restart_fetches params it =
  restart_all_fetches_that params it (fun _ -> true)


let commit_barrier_action
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (bk:     barrier_kind)
    (is':    outcome unit)
  =
  let i = iic.iic_instance in
  let (b, i') = make_barrier_event_ii i state.thread bk in
  let c () =
    let i' = mark_barrier_as_committed b i in
    let i' = <| i' with  micro_op_state = MOS_plain is' |> in
    let it' = 
      if is_AArch64_isb_barrier (ik i)
      then commit_isb_action_restart_fetches params iic.subtree
      else iic.subtree
    in
    let it' = apply_tree_context iic.context (i', it') in
    let s' = <| state with instruction_tree = it' |> in
    match params.thread_model with
    | PLDI11_thread_model    -> pldi11_commit_barrier_action s' b
    | POP_thread_model _     -> s'
    | TSO_thread_model       -> s'
    | Promising_thread_model -> fail
    | Relaxed_thread_model   -> s'
    end
    $> make_thread_cont_res {} {}
  in
  (b,c)


let barrier_is_not_sent_to_storage params isa bk =
 (* Flat does not send barriers to the storage subsystem *)
 is_flat_model params
    (* barriers that are not sent to storage in POP *)
    (* see discussion on DMB LD in private notes60 *)
    || is_pop_instruction_barrier bk
    || is_AArch64_ld_barrier bk
    || (params.thread_model = TSO_thread_model && 
          isa.isa_model = RISCV && not (is_RISCV_fence_pw bk))
    || params.thread_model = Relaxed_thread_model


let barrier_commit_cand params isa state iic = 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_commit_cand state iic
  | POP_thread_model _     -> pop_commit_barrier_cand params isa iic
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end

let handle_barrier_outcome
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (bk:     barrier_kind)
    (is':    outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* Note: in the new scheme, it's more natural to do the whole barrier commit now *)
  (* NEWTODO: have to do the rest of the barrier action - check what we did in old ppcmem*)
  guard (barrier_commit_cand params isa state iic) >>
  let (b,c) = commit_barrier_action params isa state iic bk is' in
  if barrier_is_not_sent_to_storage params isa (ik iic.iic_instance)
  then [T_only (make_label state iic (T_commit_barrier b) c)]
  else [T_sync (T_propagate_barrier (make_label state iic b c)) ()]
  (* for barriers with acks (such as sync), how are the commit and the sync
     related?  Not at all - the test that the sync has been ack'd occurs
     elsewhere in the thread semantics, in the commit-cand and read-satisfy-cand
     checking for po-later instructions *)


let pseudo_register_read_action
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (r: reg_name)
      (c: register_value -> outcome unit)
  =

  (* pseudo registers have a predetermined values and the
  transition is T_internal *)
  let i = iic.iic_instance in
  let v = pseudo_register_value isa i.program_loc r in
  let c = fun () ->
    let regread = (r,[RRS_pseudoregister],v) in
    let i' = <| i with micro_op_state = MOS_plain (c v);
                       reg_reads = regread::i.reg_reads |> in
    let it' = apply_tree_context iic.context (i',iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  (v,c)

let regular_register_read_action
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (r: reg_name)
      (c: register_value -> outcome unit)
  =
  let i = iic.iic_instance in
  (* *don't* allow reading from reg writes by the same instruction,
     otherwise we get self-blocked. But some 2.06B pseudocode does
     read from self-writes; we allow that by patching the pseudocode
     (otherwise we'd need more fine-grained dependency tracking *)
  let full_prefix = iic.active_prefix ++ iic.old_prefix in
  let initial_values =
    Just (state.register_data, state.initial_register_state) in
  match find_reg_read initial_values r full_prefix  with
  | FRRO_blocked _ -> []
  | FRRO_not_found -> fail
  | FRRO_found (rrs:register_read_sources) (v:register_value) ->
     let c () = 
       let i' = 
         <| i with micro_op_state = MOS_plain (c v);
                   reg_reads = (r,rrs,v)::i.reg_reads;
         |> in
       let it' = apply_tree_context iic.context (i',iic.subtree) in
       let state' = <| state with instruction_tree = it' |> in
       make_thread_cont_res {} {} state'
     in
     [((rrs,v),c)]
  end


let handle_read_reg_outcome
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (r: reg_name)
      (c: register_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  if is_pseudo_register isa r then
    let (v,c) = pseudo_register_read_action isa state iic r c in
    [T_only (make_label state iic (T_pseudoreg_read r v) c)]
  else
    regular_register_read_action state iic r c >>= fun ((rrs,v), c) ->
    [T_only (make_label state iic (T_register_read r rrs v) c)]


let write_register_action
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    ((r: reg_name), (v: register_value))
    (is':    outcome unit)
  =
  let c () =
    let i = iic.iic_instance in
    let regwrite = (r, (current_reg_write_dependencies i, v)) in
    let i' =
      <| i with micro_op_state = MOS_plain is';
                reg_writes = regwrite :: i.reg_writes |>
    in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  c


let handle_write_reg_outcome
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    ((r: reg_name), (v: register_value))
    (is':    outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let c = write_register_action isa state iic (r,v) is' in
  let label =
    if is_pseudo_register isa r then
      (* the only pseudo_register we expect a write to is the NIA/PC register *)
      let () = ensure (register_base_name r = register_base_name isa.nia_reg)
                 ("write reg of non-NIA/PC pseudoregister (" ^ show r ^ ")")
      in
      T_pseudoreg_write r v
    else
      T_register_write r v
  in
  [T_only (make_label state iic label c)]


let handle_internal_outcome
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (_: (maybe string * maybe (unit -> string)))
    (is': outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let c () = 
    let i' = <| iic.iic_instance with micro_op_state = MOS_plain is' |> in
    let it' = apply_tree_context iic.context (i',iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic T_internal_outcome c)]


let handle_footprint_outcome
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (old_outcome : outcome unit)
    (is': outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let () = ensure (isa.isa_model = PPC) "expected PPC" in
  let state' = fun () ->
    let i = iic.iic_instance in
    let prefix = iic.active_prefix ++ iic.old_prefix in
    let i' = <| i with micro_op_state = MOS_plain is' |> in
    let i'' = recalculate_register_footprint isa i' old_outcome prefix in
    let it' = recalculate_ioids_feeding_address (i'' :: prefix) iic.subtree in
    let it' = apply_tree_context iic.context (i'',it') in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic T_footprint_outcome state')]




let read_reg
      initial_reg_state
      (prefix : list (instruction_instance 'i))
      (reg : reg_name) 
    : list (reg_name * register_read_sources * register_value)
  =
  match find_reg_read (Just initial_reg_state) reg prefix with
  | FRRO_found rrs v -> [(reg, rrs, v)]
  | _ -> []
  end

let read_reg_if_needed
      initial_reg_state
      (prefix : list (instruction_instance 'i))
      (maybe_reg : maybe reg_name) 
    : list (maybe (reg_name * register_read_sources * register_value))
  =
  match maybe_reg with
  | Just reg ->
      match find_reg_read (Just initial_reg_state) reg prefix with
      | FRRO_found rrs v -> [Just (reg, rrs, v)]
      | _ -> []
      end
  | Nothing -> [Nothing]
  end


let finish_cand params state iic = 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_finish_cand state iic
  | POP_thread_model _     -> pop_finish_cand params state iic
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end


let handle_done_outcome
      (params: thread_params)
      (isa: isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let instr = ensure_fetched iic.iic_instance.instruction in
  guard (finish_cand params state iic) >>
  let c () = finish_action isa state iic in
  let addr = iic.iic_instance.program_loc in
  [T_only (make_label state iic (T_finish addr instr) c)]


let handle_sail_error
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (msg: string)
    : list (thread_trans 'i (thread_state 'i))
  =
  guard (po_predecessors_all_finished iic) >>
  let c () = make_thread_cont_res {} {} state in
  [T_only (make_label state iic (T_exception (ET_ISA_error msg)) c)]


let enumerate_write_forward_transitions_pop_and_pldi11
    (params: thread_params)
    (isa: isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  iic.iic_instance.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (not (List.null unsat_slices || read_requested iic.iic_instance rr)) >>
  let (unsat_slices',sliced_writes') =
    pop_possible_write_forward_slices params isa state iic rr unsat_slices in
  guard (not (List.null sliced_writes')) >>
  let c () = pop_and_pldi11_satisfy_read_by_forwarding_action
               params state iic rr (unsat_slices', sliced_writes') in
  [T_only (make_label state iic (T_mem_forward_write rr sliced_writes') c)]


let enumerate_write_forward_transitions_relaxed
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (not (List.null unsat_slices || read_requested i rr)) >>
  let (unsat_slices,sliced_writes) =
    let write_slices =
      List.concatMap
        (fun i -> complete_writes i.subwrites.sw_potential_writes)
        iic.active_prefix
    in
    match_writes rr.r_addr unsat_slices write_slices []
  in
  guard (not (List.null sliced_writes)) >>
  let state' = fun () ->
    let writes_read_from = sliced_writes ++ sat_slices_of_read_request i rr in
    let i' = mark_read_as_satisfied i rr unsat_slices writes_read_from in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic (T_mem_forward_write rr sliced_writes) state')]


let enumerate_write_forward_transitions
      (params: thread_params)
      (isa:    isa 'i)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i)) =
  match params.thread_model with
  | PLDI11_thread_model ->
      enumerate_write_forward_transitions_pop_and_pldi11 params isa state iic c
  | POP_thread_model _ ->
      enumerate_write_forward_transitions_pop_and_pldi11 params isa state iic c
  | TSO_thread_model -> []
  | Promising_thread_model -> fail
  | Relaxed_thread_model ->
      enumerate_write_forward_transitions_relaxed state iic c
  end


let read_issue_action
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome unit)
  (rr,unsat_slices)
  =
  fun (mapped_memory: bool) ->
  let i = iic.iic_instance in
  if mapped_memory then
    let i' = mark_read_as_requested i rr unsat_slices in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state = <| state with instruction_tree = it' |> in
    let state' = add_read_to_pop_order state rr in
    make_thread_cont_res {} {} state'
  else
    read_unmapped_memory_action state iic rr unsat_slices


let enumerate_read_issue_transitions
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  guard (not (is_flat_model params) &&
         params.thread_model <> TSO_thread_model &&
         params.thread_model <> Relaxed_thread_model) >>
  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* no need to request satisfied reads, except for load-acquire, where we
     need the satisfied read to act as a token, and for load-exclusive where
     we need storage to know it needs to guarantee atomicity *)
  guard (not (List.null unsat_slices)
        || is_AArch64_load_acquire (ik i)
        || is_RISCV_load_strong_acquire (ik i)
        || is_atomic_load (ik i)) >>
  guard (not (read_requested i rr)) >>
  let c = read_issue_action params state iic c (rr, unsat_slices) in
  let successful_exclusives =
    if is_atomic_load (ik i) then
      let s = paired_atomic_stores i iic.subtree in
      let s = {i.instance_ioid | forall (i MEM s) 
                               | atomic_store_determined_to_succeed i} in
      if s <> {} then Just s else Nothing
    else Nothing
  in
  (* to guarantee single-copy atomicity, storage needs to know which
      writes the read has already read from. *)
  let writes_read_from = sat_slices_of_read_request i rr in
  let label = (rr, unsat_slices, writes_read_from, successful_exclusives) in
  [(T_sync (T_mem_read_request (make_label state iic label c)) ())]

      

let enumerate_pldi11_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  iic.iic_instance.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* for each read_request and its unsat_slices .. *)
  guard (read_requested iic.iic_instance rr && not (List.null unsat_slices)) >>
  let c = satisfy_read_action params state iic rr in
  let label = (make_label state iic (rr, unsat_slices) c) in
  [T_sync (T_PLDI11_mem_satisfy_read label) ()]


let enumerate_flat_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (not (read_requested i rr || List.null unsat_slices)) >>
  let c = function 
  | Just mrss ->
     let i' = mark_read_as_requested iic.iic_instance rr unsat_slices in
     let iic' = <| iic with iic_instance = i' |> in
     satisfy_read_action params state iic' rr mrss
  | Nothing ->
     read_unmapped_memory_action state iic rr unsat_slices
  end in
  let writes_read_from = sat_slices_of_read_request i rr in
  let successful_atomic_stores =
    if is_AArch64_load_exclusive (ik i) then
      let s = paired_atomic_stores i iic.subtree in
      let s = {i.instance_ioid | forall (i MEM s) 
                               | atomic_store_determined_to_succeed i} in
      if s <> {} then Just s else Nothing
    else Nothing
  in
  let label = (rr, unsat_slices, writes_read_from, successful_atomic_stores) in
  [(T_sync (T_Flat_mem_satisfy_read (make_label state iic label c)) ())]

  (* TODO SUBREADS: should forwarding be for sr_not_yet_requested or
     sr_requested?  If the latter, by requesting a rr we exclude the
     possibility of forwarding? *)

let enumerate_tso_read_satisfy_from_memory_transitions 
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  (* for each read request and unsat_slices .. *)
  guard (not (read_requested i rr || List.null unsat_slices)) >>
  let state' = function
    | Just mrss ->
       let i' = mark_read_as_requested i rr unsat_slices in
       let iic' = <| iic with iic_instance = i' |> in
       satisfy_read_action params state iic' rr mrss
    | Nothing ->
       read_unmapped_memory_action state iic rr unsat_slices
    end
  in
  [T_sync (T_TSO_mem_satisfy_read (make_label state iic rr state')) ()]


let enumerate_relaxed_read_satisfy_from_memory_transitions
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  (* for each unsatisfied slice .. *)
  i.subreads.sr_unsat_slices >>= fun (rr, unsat_slices) ->
  guard (not (read_requested i rr || List.null unsat_slices)) >>
  let state' = function
    | Just mrss ->
       let i' = mark_read_as_requested i rr unsat_slices in
       let iic' = <| iic with iic_instance = i' |> in
       satisfy_read_action params state iic' rr mrss
    | Nothing ->
       read_unmapped_memory_action state iic rr unsat_slices
    end
  in
  let writes_read_from = sat_slices_of_read_request i rr in
  let label = (rr, unsat_slices, writes_read_from, Nothing) in
  [(T_sync (T_Flat_mem_satisfy_read (make_label state iic label state')) ())]


let enumerate_read_satisfy_from_memory_transitions 
    (params: thread_params)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  match params.thread_model with
  | PLDI11_thread_model ->
      enumerate_pldi11_read_satisfy_from_memory_transitions params state iic c
  | POP_thread_model Standard_POP -> []
  | POP_thread_model Flat_POP ->
      enumerate_flat_read_satisfy_from_memory_transitions params state iic c
  | TSO_thread_model ->
      enumerate_tso_read_satisfy_from_memory_transitions params state iic c
  | Promising_thread_model -> fail
  | Relaxed_thread_model ->
      enumerate_flat_read_satisfy_from_memory_transitions params state iic c
  end


let load_needs_to_issue_token ik = 
  is_AArch64_load_acquire ik || 
  is_RISCV_load_strong_acquire ik || 
  is_atomic_load ik

let enumerate_actually_satisfy_transitions
      (params: thread_params)
      (state: thread_state 'i)
      (iic: instruction_in_context 'i)
      (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
    (* .. in case they were forwarded without it *)
  guard (all_read_writes_have_their_values i) >>
    (* in POP (not flat) for load-acquire, all the read-requests were
       issued (for the token); and (again not Flat) for
       load-exclusive, all the read-requests were issued (for
       atomicity) *) 
  guard ((load_needs_to_issue_token (ik i) && is_pop_not_flat_model params) -->
         all_read_requests_issued i) >>

  let sorted_writes_read_from =
    List.map snd
      (Sorting.sortByOrd
        (fun (lhs, _) (rhs, _) -> compare lhs.r_addr rhs.r_addr)
        i.subreads.sr_writes_read_from)
  in
  let value = List.concatMap value_of_write_slices sorted_writes_read_from in

  let state' = fun () ->
    let i' = mark_read_as_completed i value in
    let i' =  <| i' with micro_op_state = MOS_plain (c value) |> in
    let it' = apply_tree_context iic.context (i',iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  return (T_only (make_label state iic (T_actually_satisfy value) state'))


let read_request_cand params state iic = 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_memory_read_storage_cand state iic
  | POP_thread_model _     -> pop_memory_read_request_cand params iic
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end


let assert_is_RISCV_AMO i ioid_s = 
  ensure (is_RISCV_AMO (ik i))
    ("atomic_begin in a non-RISC-V-AMO instruction (ioid " ^ ioid_s ^ ")")

let assert_just_one_read_request i ioid_s = 
  let _ = ensure_singleton i.subreads.sr_writes_read_from
            ("AMO (ioid " ^ ioid_s ^") should have exactly one read-request") in
  ()

let assert_no_write_value_yet i ioid_s = 
  ensure (List.null i.subwrites.sw_potential_writes)
    ("AMO (ioid " ^ ioid_s ^ ") should have no instantiated writes (with value)")

let ensure_just_one_write_request i ioid_s = 
  let write = 
    ensure_singleton i.subwrites.sw_potential_write_addresses
      ("AMO (ioid " ^ ioid_s ^ ") should have exactly one initiated write") in
  write

(* check that the load and the store part could be done now *)
let take_AMO_lock_cand
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
  =
  let i = iic.iic_instance in
  let ioid_s = show i.instance_ioid in
  let () = assert_is_RISCV_AMO i ioid_s in
  let () = assert_just_one_read_request i ioid_s in
  let () = assert_no_write_value_yet i ioid_s in
  let write = ensure_just_one_write_request i ioid_s in

  (* check that the load can be satisfied *)
  read_request_cand params state iic &&

  (* check that the load part could be finished, except for the
     co-check. The co-check only works for satisfied loads, but
     should always hold due to the write commit/write propagate
     requirements below (an 'ensure' later checks that) *)
  pop_finish_simple_cand state iic &&
  pop_finish_load_cand_barrier_part state iic &&

  (* check that the store part can be committed and propagated *)
  match params.thread_model with
  | POP_thread_model _     ->
     pop_commit_store_cand state iic && 
     pop_write_co_check params state iic write
  | TSO_thread_model       -> true
  | PLDI11_thread_model    -> fail
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end

let handle_AMO_lock
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  guard (take_AMO_lock_cand params state iic) >>
  let state' = fun () ->
    let mos = MOS_pending_mem_read c in
    let i' = <| iic.iic_instance with micro_op_state = mos |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  return (T_only (make_label state iic T_RISCV_atomic_begin state'))


let handle_AMO_unlock
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (o:      outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () ->
    let i' = <| iic.iic_instance with micro_op_state = MOS_plain o |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  return (T_only (make_label state iic T_RISCV_atomic_end state'))


let handle_memory_read
    (params: thread_params)
    (isa : isa 'i)
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (c: memory_value -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  if all_reads_satisfied iic.iic_instance then
    enumerate_actually_satisfy_transitions params state iic c
  else
    guard (read_request_cand params state iic) >>
    enumerate_write_forward_transitions params isa state iic c ++
    enumerate_read_issue_transitions params state iic c ++
    enumerate_read_satisfy_from_memory_transitions params state iic c


let commit_store_cand params state iic= 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_commit_cand state iic
  | POP_thread_model _     -> pop_commit_store_cand state iic
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end

let enumerate_commit_store_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = ensure (not (is_RISCV_store_conditional (ik i)))
             "must not be a RISC-V store-conditional" in
  (* RISC-V store-conditional is handled elsewhere as it needs to
     commit and propagate at the same time *)
  guard (commit_store_cand params state iic) >>
  let state' = fun () ->
    let i' = mark_write_as_committed i in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic T_commit_store state')]


let propagate_write_cand params isa state iic write = 
  match params.thread_model with
  | PLDI11_thread_model    -> pldi11_propagateWritePrevMightSameAddress iic write
  | POP_thread_model _     -> pop_write_co_check params state iic write
  | TSO_thread_model       -> true
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end


let information_on_read_exclusives_that_read_from_write
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (write:  write)
    =
  guard (is_aarch64 isa.isa_model) >>
  guard (is_flat_model params) >>
  let successful_atomic_pairings =
    instruction_tree_fold_root (fun found _prefix ii it ->
      if is_atomic_load (ik ii) then
        let s = paired_atomic_stores ii it in
        let s = {i.instance_ioid | forall (i MEM s) | i.successful_atomic_store = Just true} in
        if s <> {} then Set.insert (ii, s) found else found
      else found
    ) {} [] iic.subtree
    $> Set.bigunion
    $> Set_extra.toList
  in
  (* for each load exclusive "loadx" successfully paired with "storexs" *)
  successful_atomic_pairings >>= fun (loadx,storexs) ->
  (* check all the writes loadx read from *)
  loadx.subreads.sr_writes_read_from >>= fun (read_request,writes_and_slices) ->
  (* and collect the parts (write',slices) reading from the write we're about to commit *)
  let rf = [(write',slices) | forall ((write',slices) MEM writes_and_slices) | write' = write] in
  (* unless this list is empty *)
  guard (rf <> []) >>
  (* and return the load exclusive's read_request, this list, and the store exclusive ioid *)
  return (read_request,rf,storexs)


let enumerate_propagate_write_transitions
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  (* RISC-V store-conditional is handled elsewhere *)
  let _ = ensure (not (is_RISCV_store_conditional (ik i)))
            "must not be a RISC-V store-conditional" in
  let _ = ensure (write_instantiated i) "the store has writes with no values" in
  (* for each potential write .. *)
  i.subwrites.sw_potential_writes >>= fun (write: write) ->
  guard (propagate_write_cand params isa state iic write) >>
  let exclusive_info = information_on_read_exclusives_that_read_from_write 
                         params isa state iic write in
  let state' = function
    | MWO_successful -> propagate_write_action params state iic write
    | MWO_unmapped_address ws -> write_unmapped_memory_action state iic ws
    | MWO_exclusive_failed -> fail
  end in
  let plain_write_transition =
    if write_was_subsumed params iic write then
      let state' = fun () -> state' MWO_successful in
      T_only (make_label state iic (T_POP_subsumed_write write) state')
    else
      let label = (write, Nothing, exclusive_info) in
      T_sync (T_propagate_write (make_label state iic label state')) ()
  in
  if is_atomic_store (ik i) then
    let paired_load = ensure_just (paired_atomic_load iic)
                        "atomic store not paired with atomic load" in
    (* FIXME: handle cases where fp is not equal *)
    if paired_load.subreads.sr_addr = (Just write.w_addr) then
      let r = ensure_singleton (read_requests_of_subreads paired_load.subreads)
                ("paired atomic load (ioid " ^ show paired_load.instance_ioid ^
                   ") has multiple/pair reads")
      in
      let label = (write, Just r, exclusive_info) in
      return (T_sync (T_propagate_write (make_label state iic label state')) ())
    else [plain_write_transition]
  else [plain_write_transition]


let assert_is_RISCV_store_conditional i = 
  ensure (is_RISCV_store_conditional (ik i))
    ("expected a RISC-V store-conditional (ioid " ^ show i.instance_ioid ^ ")")

let assert_all_writes_have_values i =
  ensure (i.subwrites.sw_potential_write_addresses = [])
    ("the store (ioid " ^ show i.instance_ioid ^ ") has writes with no values")

let ensure_has_single_write_with_value i = 
  ensure_singleton i.subwrites.sw_potential_writes
    ("store-conditional (ioid " ^ show i.instance_ioid ^
       ") should have exactly one write")

let commit_and_prop_RISCV_store_conditional_cand
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (write:  write)
  =
  match params.thread_model with
  | POP_thread_model _     ->
     pop_commit_store_cand state iic &&
     pop_write_co_check params state iic write
  | TSO_thread_model       -> true
  | PLDI11_thread_model    -> fail
  | Promising_thread_model -> fail
  | Relaxed_thread_model   -> true
  end

let ensure_RISCV_store_conditional_has_paired_load iic = 
  ensure_just (paired_atomic_load iic)
    ("about to commit a store-conditional (ioid " ^
       show iic.iic_instance.instance_ioid ^ ") that is not paired")

let assert_paired_load_entirely_satisfied load = 
  ensure (is_entirely_satisfied_load load) 
    ("expected the load-reserved (ioid " ^ show load.instance_ioid ^
       ") to have already been satisfied")

let ensure_paired_load_writes_read_from_singleton load = 
  ensure_singleton load.subreads.sr_writes_read_from
    ("can't handle atomic load (ioid " ^ show load.instance_ioid ^
       ") with multiple reads")

let ensure_paired_load_unsat_slices_singleton load = 
  ensure_singleton load.subreads.sr_unsat_slices
    ("can't handle atomic load (ioid " ^ show load.instance_ioid ^
       ") with multiple reads")


let enumerate_commit_and_prop_RISCV_store_cond_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = assert_is_RISCV_store_conditional i in
  let () = assert_all_writes_have_values i in
  let write = ensure_has_single_write_with_value i in

  guard (commit_and_prop_RISCV_store_conditional_cand params state iic write) >>

  let load = ensure_RISCV_store_conditional_has_paired_load iic  in
  (* the commit_cand above guarantees the paired load-reserved is finished *)
  let () = assert_paired_load_entirely_satisfied load in
  let (_, prev_writes) = ensure_paired_load_writes_read_from_singleton load in

  let state' = function
    | MWO_successful ->
       let i' = set_successful_atomic_store (mark_write_as_committed i) in
       let iic' = <| iic with iic_instance = i' |> in
       propagate_write_action params state iic' write
    | MWO_unmapped_address ws ->
       write_unmapped_memory_action state iic ws
    | MWO_exclusive_failed ->
       let i' = set_unsuccessful_atomic_store i in
       let iic' = <| iic with iic_instance = i' |> in
       failed_write_action state iic' write (MOS_plain (c false))
    end
  in
  let label = (make_label state iic (write, prev_writes) state') in
  [T_sync (T_Flat_try_commit_store_cond label) ()]


let enumerate_complete_store_transition
    (params: thread_params)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  let () = assert_all_writes_have_values i in
  let state' = fun () ->
    let i' =
      if is_RISCV_AMO (ik i) then
        let () = ensure (pop_finish_load_cand params state iic)
                   "completed AMO cannot finish load part" in
        <| i with micro_op_state = MOS_AMO_unlock (c true) |>
      else
        <| i with micro_op_state = MOS_plain (c true) |>
    in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic T_complete_store state')]


let handle_memory_write
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (c:      bool -> outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  if (not (write_committed i)) then
    if is_RISCV_store_conditional (ik i) then
      enumerate_commit_and_prop_RISCV_store_cond_transition params state iic c
    else
      enumerate_commit_store_transition params state iic
  else if List.null (i.subwrites.sw_potential_writes) then
    enumerate_complete_store_transition params state iic c 
  else
    enumerate_propagate_write_transitions params isa state iic

let last_preceding_instruction_finished iic = 
  match iic.active_prefix with 
  | iprev :: _ -> iprev.finished 
  | [] -> true 
  end

let handle_exception
    (state: thread_state 'i)
    (iic: instruction_in_context 'i)
    (e: exception_type 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let state' = fun () -> make_thread_cont_res {} {} state in
  match iic.iic_instance.micro_op_state with
  | MOS_pending_exception ET_loop_limit_reached ->
      guard (last_preceding_instruction_finished iic) >>
      [T_only (make_label state iic (T_exception e) state')]
  | _ ->
      guard (po_predecessors_all_finished iic) >>
      [T_only (make_label state iic (T_exception e) state')]
  end

let enumerate_previous_excl_res_outcome_transition
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  let i = iic.iic_instance in
  option_guard (i.successful_atomic_store) >>= fun success_bit ->
  let state' = fun () ->
    let i' = <| i with micro_op_state = MOS_plain (isa_cont success_bit) |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic (T_prev_excl_result success_bit) state')]


let enumerate_excl_res_fail_outcome_transition
    (params:   thread_params)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  guard (params.thread_model <> TSO_thread_model) >>
  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  let state' = fun () ->
    let i' =
      <| i with successful_atomic_store = Just false;
                reg_reads = []; (* see comment below *)
                micro_op_state = MOS_plain (isa_cont false);
      |>
    in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  [T_only (make_label state iic T_failed_store_excl state')]
(* reg_reads: as the store-conditional/exclusive will not be using
   these we want to dissever the dependency; this prevents restarts
   and allows the instruction to be finished.  this test should be
   allowed:

  a:R x=1             d:R y=1
    <addr>              <addr>
  b:W-exclusive z=1   e:W x=1
    <addr>
  c:W y=1
  *)


let excl_res_success_action
    (record_success: bool)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  fun () ->
    let i = iic.iic_instance in
    let i' = <| i with micro_op_state = MOS_plain (isa_cont true) |> in
    let i' = if record_success
             then <| i' with successful_atomic_store = Just true |>
             else i' in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'


let enumerate_excl_res_success_outcome_transition_pop
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  guard (params.thread_model = POP_thread_model Standard_POP) >>
  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  option_guard (paired_atomic_load iic) >>= fun load ->
  match isa.isa_model with
  | AARCH64 _ ->
     let state' = excl_res_success_action true state iic isa_cont in
      if List.null load.subreads.sr_requested then
        [(T_only (make_label state iic T_successful_store_excl state'))]
      else
        let (r, unsat_slices) = ensure_paired_load_unsat_slices_singleton load in
        let rf =
          if unsat_slices = [] then
            (* the read request is completely satisfied, hence it's not in
               storage, so we need to include its 'rf' in the transition *)
            Just (sat_slices_of_read_request load r)
          else
            (* the read request was requested but not satisfied yet, hence it's
               in storage, so no need to include its 'rf' in the transition *)
            Nothing
        in

        let label = (make_label state iic (r, rf, i.instance_ioid) state') in
        [(T_sync (T_try_store_excl label) ())]
  | RISCV ->
     let state' = excl_res_success_action false state iic isa_cont in
     [T_only (make_label state iic T_potential_store_cond state')]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end


let remove_unpropagated_writes_by_same_thread tid iic wss =
  [(w, slice) | forall ((w,slice) MEM wss)
              | w.w_thread = tid -->
                forall (iprev MEM iic.active_prefix).
                iprev.instance_ioid = w.w_ioid -->
                List.elem w iprev.subwrites.sw_propagated_writes]

let enumerate_excl_res_success_outcome_transition_flat
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  guard (is_flat_model params) >>
  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  option_guard (paired_atomic_load iic) >>= fun load ->
  match isa.isa_model with
  | AARCH64 _ ->
     let state' = excl_res_success_action true state iic isa_cont in
     if List.null load.subreads.sr_writes_read_from then
       [T_only (make_label state iic T_successful_store_excl state')]
     else
       let (r,rf) = ensure_paired_load_writes_read_from_singleton load in
       let rf = remove_unpropagated_writes_by_same_thread state.thread iic rf in
       let label = make_label state iic (r, Just rf, i.instance_ioid) state' in
       [T_sync (T_try_store_excl label) ()]
  | RISCV ->
     let state' = excl_res_success_action false state iic isa_cont in
     [T_only (make_label state iic T_potential_store_cond state')]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end

let enumerate_excl_res_success_outcome_transition_tso
    (params:   thread_params)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  guard (params.thread_model = TSO_thread_model) >>
  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  option_guard (paired_atomic_load iic) >>= fun load ->
  let state' = excl_res_success_action true state iic isa_cont in
  let (r,rf) = ensure_paired_load_writes_read_from_singleton load in
  let rf = remove_unpropagated_writes_by_same_thread state.thread iic rf in
  let label = (r, Just rf, i.instance_ioid) in
  [T_sync (T_try_store_excl (make_label state iic label state')) ()]


let enumerate_excl_res_success_outcome_transition_relaxed
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  guard (params.thread_model = Relaxed_thread_model) >>

  let i = iic.iic_instance in
  guard (i.successful_atomic_store = Nothing) >>
  match isa.isa_model with
  | AARCH64 _ ->
      let state' = excl_res_success_action true state iic isa_cont in
      [T_only (make_label state iic T_successful_store_excl state')]
  | RISCV ->
      let state' = excl_res_success_action false state iic isa_cont in
      [T_only (make_label state iic T_potential_store_cond state')]
  | PPC       -> failwith "not implemented for PPC"
  | MIPS      -> failwith "not implemented for MIPS"
  | X86       -> failwith "not implemented for x86"
  end


let enumerate_excl_res_success_outcome_transition
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  enumerate_excl_res_success_outcome_transition_pop params isa state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_flat params isa state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_tso params state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition_relaxed params isa state iic isa_cont

let handle_excl_res_outcome
    (params:   thread_params)
    (isa:      isa 'i)
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (isa_cont: bool -> outcome unit)
  =
  enumerate_previous_excl_res_outcome_transition state iic isa_cont ++
  enumerate_excl_res_success_outcome_transition params isa state iic isa_cont ++
  enumerate_excl_res_fail_outcome_transition params state iic isa_cont

let enumerate_finish_load_part_of_rmw
    (params: thread_params)
    (state:      thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let i = iic.iic_instance in
  guard (is_memory_rmw (ik i) && 
         not (is_RISCV_AMO (ik i)) &&
         i.rmw_finished_load_snapshot = Nothing &&
         is_entirely_satisfied_load i &&
         pop_finish_load_cand params state iic) >>

  let state' () =
    let snapshot =
      <| rfls_instance_id_state = i.instance_id_state;
         rfls_reg_reads         = i.reg_reads;
         rfls_reg_writes        = i.reg_writes;
         rfls_micro_op_state    = i.micro_op_state;
      |>
    in
    let i' = <| i with rmw_finished_load_snapshot = Just snapshot |> in
    let it' = apply_tree_context iic.context (i', iic.subtree) in
    let state' = <| state with instruction_tree = it' |> in
    make_thread_cont_res {} {} state'
  in
  return (T_only (make_label state iic T_finish_load_of_rmw state'))

(* handle_thread_start is a hack. It handles the fake instruction that
   signals a fork in rmem. We expect the Sail code for this
   instruction to do nothing. Here we generate register read
   transitions as needed, and then do the fork and write the result
   register at the same time.  Maybe it would be nicer to have Sail do
   the register reads and writes, but then we will need to add a fork
   outcome/effect to Sail and I'm not up to it right now. Also, it is
   not clear we want such effect in Sail as "fork" is not a real
   thing. *)
let handle_thread_start
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (is:     outcome unit)
    : list (thread_trans 'i (thread_state 'i))
  =
  let c = fun _ -> is in
  let start_info = isa.thread_start_info in
  let i = iic.iic_instance in

  if forall ((r, _, _) MEM i.reg_reads). r <> start_info.tsi_addr then
    handle_read_reg_outcome isa state iic start_info.tsi_addr c
  else if
    match start_info.tsi_toc with
    | Nothing -> false
    | Just tsi_toc ->
        forall ((r, _, _) MEM i.reg_reads). r <> tsi_toc
    end
  then
    let tsi_toc = ensure_just start_info.tsi_toc "fail" in
    handle_read_reg_outcome isa state iic tsi_toc c
  else if
    match start_info.tsi_extra with
    | Nothing -> false
    | Just tsi_extra ->
        forall ((r, _, _) MEM i.reg_reads). r <> tsi_extra
    end
  then
    let tsi_extra = ensure_just start_info.tsi_extra "fail" in
    handle_read_reg_outcome isa state iic tsi_extra c
  else
    guard (finish_cand params state iic) >>

    guard (forall (iprev MEM iic.active_prefix). 
           if is_pop_strong_memory_barrier (ik iprev)
           then iprev.finished else true) >>

    let addr_v =
      List.find (fun (r, _, _) -> r = start_info.tsi_addr) i.reg_reads
    in
    let (_, _, addr_v) = ensure_just addr_v "fail" in
    let toc_v =
      match start_info.tsi_toc with
      | Nothing -> Nothing
      | Just tsi_toc ->
          let v = List.find (fun (r, _, _) -> r = tsi_toc) i.reg_reads in
          let (_, _, v) = ensure_just v "fail" in
          Just v
      end
    in

    let thread_continuation = fun new_tid ->
      let new_tid_rv =
        match new_tid with
        | Just new_tid -> integerFromNat new_tid
        | Nothing      -> ~1 (* i.e. -1 *)
        end
        $> register_value_for_reg_of_integer start_info.tsi_return
      in
      let i' =
        <| i with
            reg_writes = (start_info.tsi_return, (current_reg_write_dependencies i, new_tid_rv))
              :: i.reg_writes;
            finished = true;
        |>
      in
      let it' = apply_tree_context iic.context (i',iic.subtree) in
      let state' = <| state with instruction_tree = it' |> in
      let state' = make_old_instructions isa state' in
      make_thread_cont_res {} {} state'
    in

    [T_thread_start (make_label state iic (addr_v, toc_v) thread_continuation)]




let handle_ic_ivau
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (value:    register_value)
    (outcome:  outcome unit)
  =
  let addr = ensure_just (address_of_register_value value)
               "TODO: handle_ic_ivau fail invalid addr" in
  guard (forall (iprev MEM iic.active_prefix).
         (is_AArch64_ic_wait_barrier (ik iprev) --> iprev.finished) ) >>
  let label = <| cmr_cmk = CM_IC; 
                 cmr_ioid = iic.iic_instance.instance_ioid; 
                 cmr_addr = addr; |> in
  let c = cache_maintenance_ic_action state iic addr outcome in
  [T_sync (T_propagate_cache_maintenance (make_label state iic label c)) ()]


let handle_dc_cvau
    (state:    thread_state 'i)
    (iic:      instruction_in_context 'i)
    (value:    register_value)
    (outcome:  outcome unit)
  =
  let addr = ensure_just (address_of_register_value value)
               "TODO: handle_dc_cvau fail invalid addr" in
  (* wait for po-previous DMB/DSB *)
  guard (forall (iprev MEM iic.active_prefix).
         (is_AArch64_dc_wait_barrier (ik iprev) --> iprev.finished) ) >>
  let lbl = <| cmr_cmk = CM_DC;
               cmr_ioid = iic.iic_instance.instance_ioid;
               cmr_addr = addr |> in
  let c = cache_maintenance_dc_action state iic addr outcome in
  [T_sync (T_propagate_cache_maintenance (make_label state iic lbl c)) ()]


let create_opcode mrs =
  match maybe_all (List.map byte_of_byte_lifted (mrs.mrs_value)) with
  | Nothing -> failwith ("create_opcode lifted byte: " ^ (show mrs.mrs_value))
  | Just [b0; b1; b2; b3] ->
      let endianness = E_little_endian in (* TODO: hook this into the arch? *)
      match endianness with
      | E_big_endian -> opcode_of_bytes b0 b1 b2 b3
      | E_little_endian -> opcode_of_bytes b3 b2 b1 b0
      end
  | Just _ -> failwith "create_fdo unexpected number of bytes"
  end


let create_fdo isa (a : address) (mrs : memory_read_source) 
    : fetch_and_decode_outcome 'i =
  let opcode = create_opcode mrs in
  let fdo = isa.instruction_semantics.decode_to_instruction a opcode in
  fdo


let enumerate_fetch_transitions_of_instruction
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =
  let i = iic.iic_instance in
  guard (i.micro_op_state = MOS_not_fetched) >>

  (* let fetch_kind =
    if not prev_i.finished
        && exists (nia IN prev_iic.iic_instance.nias). nia = NIA_indirect_address
    then FK_unfixed
    else if Set.size all_fetch_addrs > 1 then FK_multiple_fixed
    else FK_normal
  in *)
  let fetch_kind = FK_normal in
  let addr = i.program_loc in
  let thread_cont = get_fetch_instruction_continuation isa state iic addr in
  let make_fr addr fk =
    <| fr_addr = addr;
       fr_kind = fk;
       fr_tid = state.thread;
       fr_decode = create_fdo isa;
    |>
  in
  let label = (make_fr addr fetch_kind) in
  [T_sync (T_fetch (make_label state iic label thread_cont)) ()]


let successful_decode_action params state iic addr opcode inst =
  let i = iic.iic_instance in
  let prefix = (i :: iic.active_prefix ++ iic.old_prefix) in
  let i' = starting_inst_instance params
             i.instance_ioid opcode inst addr prefix in
  let it' = apply_tree_context iic.context (i',iic.subtree) in
  let state' = <| state with instruction_tree = it' |> in
  let state' = make_old_instructions params state' in
  make_thread_cont_res {} {} state'
  

let decode_error_action params state iic fdo = 
  let i = iic.iic_instance in
  let fde =
    match fdo with
    | FDO_address_not_concrete -> FDE_non_concrete_fetch_address_error
    | FDO_illegal_fetch_address -> FDE_illegal_fetch_address_error i.program_loc
    | FDO_decode_error de -> FDE_decode_error de i.program_loc
    | _ -> failwith "impossible"
    end
  in
  let mos = MOS_pending_exception (ET_fetch_and_decode fde) in
  let i' = <| i with micro_op_state = mos |> in
  let it' = apply_tree_context iic.context (i',iic.subtree) in
  let state' = <| state with instruction_tree = it' |> in
  let state' = make_old_instructions params state' in
  make_thread_cont_res {} {} state'

let enumerate_decode_transitions_of_instruction params
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =
  let i = iic.iic_instance in
  (* Can only decode after fetched *)
  guard (has_fetched i && not (has_decoded i)) >>
  (* only decode if program-order previous decoded ISBs are finished *)
  guard (forall (iprev MEM iic.active_prefix).
         is_AArch64_isb_barrier (ik iprev) --> iprev.finished) >>
  (* Can only decode after parent has decoded or initial fetch *)
  guard (match iic.active_prefix ++ iic.old_prefix with
         | hd::_ -> has_decoded hd
         | [] -> true
         end) >>
  let f = ensure_mos_fetched i.micro_op_state in
  let cont () = match fdo_from_fetch_result f with
    | FDO_success addr opcode inst ->
       successful_decode_action params state iic addr opcode inst
    | err -> decode_error_action params state iic err
  end in
  [T_only (make_label state iic (T_decode i.program_loc f) cont)]


let enumerate_transitions_of_instruction
    (params: thread_params)
    (isa:    isa 'i)
    (s:      thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  let is_sequential = params.thread_restriction <> RestrictionNone in
  guard (is_sequential --> forall (p MEM iic.active_prefix). p.finished) >>

  match iic.iic_instance.micro_op_state with
  | MOS_unpredictable -> []
  | MOS_not_fetched -> enumerate_fetch_transitions_of_instruction isa s iic
  | MOS_fetched _ -> enumerate_decode_transitions_of_instruction isa s iic
  | MOS_wait_IC _ -> []
  | MOS_plain is ->
    match is with

    (* IC *)
    | O_Write_reg (Reg "instruction_cache_operation_IVAU" 63 64 D_decreasing, v) o ->
      handle_ic_ivau s iic v o

    (* DC *)
    | O_Write_reg (Reg "data_cache_operation_CVAU" 63 64 D_decreasing, v) o ->
      handle_dc_cvau s iic v o

    (* normal outcomes *)
    | O_Read_mem descr c     -> handle_read_mem_outcome     params isa s iic descr c
    | O_Write_ea descr o     -> handle_write_ea_outcome     params isa s iic descr o
    | O_Write_memv descr c   -> handle_write_memv_outcome   params s iic descr c
    | O_Excl_res c           -> handle_excl_res_outcome     params isa s iic c
    | O_Barrier descr o      -> handle_barrier_outcome      params isa s iic descr o
    | O_Read_reg descr c     -> handle_read_reg_outcome     isa s iic descr c
    | O_Write_reg descr o    -> handle_write_reg_outcome    isa s iic descr o
    | O_Internal descr o     -> handle_internal_outcome     s iic descr o
    | O_Footprint o          -> handle_footprint_outcome    isa s iic is o
    | O_Done ()              ->
       let instr = ensure_fetched iic.iic_instance.instruction in
       if isa.is_thread_start_instruction instr
       then handle_thread_start params isa s iic is
       else handle_done_outcome params isa s iic

    | O_Escape (Just msg)    -> handle_sail_error     s iic ("Escape: " ^ msg)
    | O_Escape Nothing       -> handle_sail_error     s iic ("Escape")
    | O_Error msg            -> handle_sail_error     s iic ("Error: " ^ msg)
    | O_Fail (Just msg)      -> handle_sail_error     s iic ("Fail: " ^ msg)
    | O_Fail Nothing         -> handle_sail_error     s iic ("Fail")
    end

  | MOS_pending_mem_read c    -> handle_memory_read  params isa s iic c
  | MOS_potential_mem_write c -> handle_memory_write params isa s iic c
  | MOS_AMO_lock c            -> handle_AMO_lock     params s iic c
  | MOS_AMO_unlock o          -> handle_AMO_unlock   s iic o
  | MOS_pending_exception e   -> handle_exception    s iic e
  end ++
  enumerate_finish_load_part_of_rmw params s iic



(** enumerate all fetch transitions of thread *)

(* are instruction fetches going to be done with satisfy_read transitions?  Not
   in the first instance, as that's confusing wrt the (lack of) icache
   synchronisation.  Are they going to be done from the same memory?  No, they
   come from distinct parts of the ELF file to the other mapped memory.  *)


(* NEWTODO when instructions feeding into LR/CR register values get restarted,
   and when new prediction addresses become available, how are we going to do
   the newly enabled fetches after branches? *)

(* val debug_print : string -> unit *)
(* declare ocaml target_rep function debug_print s = `Printf.eprintf` "%s%!" s *)

(* TODO: proper fixed-point or enumerate all addrs *)

let potential_next_addresses_of_instruction_relaxed
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : set address
  =
  let next_addresses_of_not_decoded_instruction () = 
    let branch_targets = Map.findWithDefault state.thread Map.empty
                           params.branch_targets in
    let addrs = Map.findWithDefault iic.iic_instance.program_loc
                  Set.empty branch_targets in
    let succ = successor_fetch_address iic.iic_instance in
    if Set.null addrs then Set.singleton succ else addrs
  in
  if has_decoded iic.iic_instance
  then potential_next_addresses_of_instruction params isa state iic
  else next_addresses_of_not_decoded_instruction ()


let init_fetch_of_instruction_cand
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    (already_fetched_addrs: list address)
  =
  let i = iic.iic_instance in

  match params.thread_restriction with
    | RestrictionNone    -> true
    | RestrictionSC      -> i.finished
    | RestrictionSCANASC -> i.finished
  end &&

  (params.thread_model = TSO_thread_model --> i.finished) &&
  (i.micro_op_state <> MOS_pending_exception ET_loop_limit_reached) &&

  let not_decoded_instructions =
    List.filter (comb not has_decoded) iic.active_prefix in
  match params.thread_fetch_limit with
  | Just lim -> lim > List.length not_decoded_instructions
  | Nothing -> true
  end &&

  (* init only after previous have been decoded *)
  (params.thread_fetch_order = Fetch_Sequential --> has_decoded i) &&

  (params.thread_allow_tree_speculation || List.null already_fetched_addrs) 


let enumerate_init_fetch_transitions_of_instruction
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (iic:    instruction_in_context 'i)
    : list (thread_trans 'i (thread_state 'i))
    =

  let i = iic.iic_instance in
  let (T iits) = iic.subtree in
  let already_fetched_addrs = 
    [i.program_loc | forall ((i,_) MEM iits) | true] in

  guard (init_fetch_of_instruction_cand
           params isa state iic already_fetched_addrs) >>

  (* TODO: make potential_next_addresses of init fetch be unconstrained *)
  let all_fetch_addrs =
    match params.thread_fetch_order with
    | Fetch_Sequential ->
       potential_next_addresses_of_instruction params isa state iic
    | Fetch_Unrestricted ->
       potential_next_addresses_of_instruction_relaxed params isa state iic
    end
  in

  let possible_fetch_addrs =
    [addr | forall (addr MEM Set_extra.toList all_fetch_addrs) 
          | not (List.elem addr already_fetched_addrs) &&
            addr <> state.return_address] in


  possible_fetch_addrs >>= fun addr -> (* for each addr .. *)

  let prefix = (i :: iic.active_prefix ++ iic.old_prefix) in

  let state' addr = fun () ->
    let (id_state', i') = init_fetch_instruction params state prefix addr in
    let it' = T (iits ++ [(i', T[])]) in
    let it' = apply_tree_context iic.context (i, it') in
    let state' =  <| state with instruction_tree = it'; 
                                id_state = id_state' |> in
    make_thread_cont_res {} {} state'
  in
  let multiple = Set.size all_fetch_addrs > 1 in
  [T_only (make_label state iic (T_init_fetch addr multiple) (state' addr))]


let initial_fetch_transition_of_thread
    (params: thread_params)
    (isa:    isa 'i)
    (state:  thread_state 'i)
    (maybe_addr:  maybe address)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* if we haven't done anything yet, fetch initial instruction *)
  guard (state.instruction_tree = T [] && state.old_instructions = []) >>
  option_guard maybe_addr >>= fun addr ->
  (* if the thread has no instruction the initial address will also be
     the return address *)
  guard (addr <> state.return_address) >>
  (* this is a dummy ioid - morally the ioid of the (nonexistent) preceding instruction *)
  let (ioid, state) =
    let (ioid, id_state') = FreshIds.gen_fresh_id state.id_state in
    (ioid, <| state with id_state = id_state' |>)
  in
  let thread_cont = fun a ->
    let (id_state', i') = init_fetch_instruction params state [] addr in
    let it' = T [(i',T [])] in
    let state' = <| state with instruction_tree = it';
                               id_state = id_state' |> in
    make_thread_cont_res {} {} state'
  in
  let label = T_init_fetch addr false in
  let tl = make_label' state.thread ioid label thread_cont in
  [T_only tl]



let enumerate_transitions_of_thread
    (params: thread_params)
    (isa : isa 'i)
    (state: thread_state 'i)
    : list (thread_trans 'i (thread_state 'i))
  =
  (* initial fetch transition *)
  initial_fetch_transition_of_thread params isa state state.initial_fetch_address ++

  (* possible transitions of inflight instructions *)
  (in_flight_instructions state >>= fun iic ->
    catch_thread_errors state.thread iic.iic_instance.instance_ioid $ fun () ->
      enumerate_transitions_of_instruction params isa state iic) ++

  (* transitions for initialising the fetch of successor instructions *)
  (un_old_instructions state >>= fun iic ->
    catch_thread_errors state.thread iic.iic_instance.instance_ioid $ fun () ->
      enumerate_init_fetch_transitions_of_instruction params isa state iic)


let pop_receive_satisfy_read_transition params isa state rr mrs = 
  let iic =
    ensure_just
      (find_ioid_instruction_in_context state rr.r_ioid)
      ("cannot find the ioid " ^ show rr.r_ioid ^ " in the instruction tree")
  in
  let state' = fun () -> satisfy_read_action params state iic rr [mrs] in
  Just (make_cont state.thread iic.iic_instance.instance_ioid state')


let pldi11_receive_acknowledge_sync_barrier_transition params isa state b = 
  let state' () =
    let s = pldi11_mark_barrier_as_acknowledged state b in
    let s' = make_old_instructions isa s in
    make_thread_cont_res {} {} s'
  in
  Just <| tc_tid = state.thread; tc_ioid = b.b_ioid; tc_cont = state' |>

let flat_receive_finish_ic_transition params isa state (cmr : cache_maintenance_request) = 
  let state' () = 
    let iic =
      ensure_just (find_ioid_instruction_in_context state cmr.cmr_ioid)
        ("cannot find the ioid " ^ show cmr.cmr_ioid ^
           " in the instruction tree")
    in
    let i = iic.iic_instance in
    match i.micro_op_state with
    | MOS_wait_IC o ->
       let i' = <| i with micro_op_state = MOS_plain o |> in
       let it' = apply_tree_context iic.context (i', iic.subtree) in
       let state' = <| state with instruction_tree = it' |> in
       make_thread_cont_res {} {} state'
    | _ -> failwith "flat finish IC:  wasn't MOS_wait_IC"
    end
  in
  Just <| tc_tid = state.thread; tc_ioid = cmr.cmr_ioid; tc_cont = state' |>

let flat_receive_ic_clear_transition params isa state (cmr : cache_maintenance_request) = 
  let state' = fun () ->
    let it = state.instruction_tree in
    let it' = restart_all_fetches_that params it
                (fun i -> i.program_loc = cmr.cmr_addr) in
    let state' = <| state with instruction_tree= it' |> in
    make_thread_cont_res {} {} state'
  in
  Just <| tc_tid = state.thread; tc_ioid = cmr.cmr_ioid; tc_cont = state' |>

let thread_receive_transition
      (params: thread_params)
      (isa:    isa 'i)
      (state:  thread_state 'i)
      label 
  =
  match label with
  (* PLDI transitions: *)
  | SS_PLDI11_acknowledge_sync_barrier b ->
     pldi11_receive_acknowledge_sync_barrier_transition params isa state b
  (* POP transitions: *)
  | SS_POP_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  (* Flowing transitions: *)
  | SS_Flowing_seg_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  | SS_Flowing_mem_read_response rr mrs ->
     pop_receive_satisfy_read_transition params isa state rr mrs
  (* Flat Transitions *)
  | SS_Flat_ic_finish cmr ->
     flat_receive_finish_ic_transition params isa state cmr
  | SS_Flat_thread_ic cmr _ ->
     flat_receive_ic_clear_transition params isa state cmr
  end

(* based on CandidateExecution.footprints_of_cex_instruction_instance *)
let footprints_of_instruction_instance (i:instruction_instance 'i) : set footprint =
  Set.fromList
    ([w.w_addr | forall ((w,sls) MEM (List.concat (snd (List.unzip i.subreads.sr_writes_read_from)))) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_potential_write_addresses) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_potential_writes) | true]
     ++ [w.w_addr | forall (w MEM i.subwrites.sw_propagated_writes) | true]
     ++ [r.r_addr | forall ((r,_) MEM i.subreads.sr_writes_read_from) | true]
     ++ [r.r_addr | forall ((r,_) MEM i.subreads.sr_requested) | true])


val machine_thread : forall 'i. threadSubsystem 'i (thread_state 'i)
let machine_thread = 
  <| ts_tid = fun ts -> ts.thread;
     ts_initial_fetch_address = fun ts -> ts.initial_fetch_address;
     ts_initial_reg_state = fun ts -> ts.initial_register_state;
     ts_initial_thread_state = initial_thread_state;
     ts_final_reg_state = registers_final_state;
     ts_instruction_tree = fun ts -> (ts.old_instructions,ts.instruction_tree);
     ts_update_initial_register_state = machine_update_initial_register_state;
     ts_update_initial_fetch_address = machine_update_initial_fetch_address;
     ts_is_final_state = thread_is_final_state;
     ts_return_address = fun ts -> ts.return_address;
     (* ts_make_ui_thread_state = make_ui_machine_thread_state; *)
     ts_enumerate_transitions_of_thread = enumerate_transitions_of_thread;
     ts_receive_transition = thread_receive_transition;
 |>

