(*========================================================================================*)
(*                                                                                        *)
(*                rmem executable model                                                   *)
(*                =====================                                                   *)
(*                                                                                        *)
(*  This file is:                                                                         *)
(*                                                                                        *)
(*  Copyright Christopher Pulte, University of Cambridge                      2015-2018   *)
(*  Copyright Shaked Flur, University of Cambridge                            2014-2018   *)
(*  Copyright Peter Sewell, University of Cambridge                           2014-2017   *)
(*  Copyright Jon French, University of Cambridge                             2017-2018   *)
(*  Copyright Susmit Sarkar, University of St Andrews                              2014   *)
(*  Copyright Robert Norton-Wright, University of Cambridge                   2016-2017   *)
(*  Copyright Linden Ralph, University of Cambridge (when this work was done)      2017   *)
(*  Copyright Ohad Kammar, University of Cambridge (when this work was done)       2013   *)
(*  Copyright Kathy Gray, University of Cambridge (when this work was done)        2015   *)
(*                                                                                        *)
(*  All rights reserved.                                                                  *)
(*                                                                                        *)
(*  It is part of the rmem tool, distributed under the 2-clause BSD licence in            *)
(*  LICENCE.txt.                                                                          *)
(*                                                                                        *)
(*========================================================================================*)

open import Pervasives_extra

(* emacs fontification -*-caml-*- *)

(* TODO: check if this is still true: naming convention: 'load' and
   'store' are used for instructions; 'read' and 'write' for memory
   actions.  Unqualifed 'load'/'store'/'read'/'write' do not include
   any reserve/conditional or acquire/release variants *)

open import Sail_impl_base
open import FreshIds
open import Events
open import Fragments
open import ExceptionTypes
open import Isa
open import RegUtils
open import UiTypes
open import Params
open import Utils
open import InstructionSemantics
open import InstructionKindPredicates



(** instruction kinds *)

(*
- the PLDI-style ppcmem PPC model uses Sync, LwSync, and Eieio
- the PLDI-style ppcmem ARM model uses Sync for the ARM DMB and does not support DMB_ST, DMB_LD, or DSB (it translates those to Sync microops)
- the Flowing/POP ppcmem ARM model does not use Sync, LwSync and Eieio, and does support DSB, DSB_ST, DSB_LD, DMB, DMB_ST, DMB_LD *)

(* Assume:
    Read_mem outcomes and E_read_mem events only arise from IK_mem_read
    Write_mem outcomes and E_write_mem events only arise from IK_mem_write
    Barrier outcomes and E_barrier events only arise from IK_barrier

    ...and for all the above, the read_kind, write_kind, or
     barrier_kind from the outcome or event is equal to that of the
     instruction (so no instruction is both a Write_plain and
     Write_conditional, for example)

    Read_reg, Write_reg, outcomes and E_read_reg, E_write_reg events
     may arise from any instructions
*)

(*: \section{The Storage Subsystem Model} :*)


(** ***********************  storage subsystem states ************)
(*: \subsection{Storage Subsystem States} :*)


(* PLDI11 storage subsystem *)

type tracked_event =
       | SWrite of (write * slices)
       | SBarrier of barrier

(* type class instantiations *)

let {coq; ocaml} tracked_eventEqual t1 t2 =
  match (t1, t2) with
  | (SWrite w1, SWrite w2) -> w1 = w2
  | (SBarrier b1, SBarrier b2) -> b1 = b2
  | _ -> false
  end
let inline {hol; isabelle} tracked_eventEqual = unsafe_structural_equality

let {coq; ocaml} tracked_eventInequal t1 t2 = not (tracked_eventEqual t1 t2)
let inline {hol; isabelle} tracked_eventInequal = unsafe_structural_inequality

instance (Eq tracked_event)
  let (=)  = tracked_eventEqual
  let (<>) = tracked_eventInequal
end

let stringFromTracked_event t =
  match t with
  | SWrite (w, sls) -> show (w,sls)
  | SBarrier b -> show b
  end

instance (Show tracked_event)
  let show = stringFromTracked_event
end


(* TODO: the storage subsystem state will also need to know the set of mapped addresses *)
type pldi11_storage_subsystem_state =
    <|
  (*: the set of thread ids that exist in the system :*)
    threads : set thread_id;

    writes_seen : set write;

    (*: set of pairs (w1,w2) for which potential_coherence_commitment_cand holds :*)
    potential_coherence_commitment_cands : set (write * write);

  (*: for each address, a strict partial order over the writes to
      that address that the storage subsystem has received from the
      threads, giving the current constraints on the coherence
      order over those writes. We record the union of those
      orders. We encode the
      partial order as a set of pairs of writes. :*)
    coherence : Relation.rel write write;

    new_coherence_basis: set footprint;
      (* the domain of new_coherence *)
    new_coherence : map footprint (Relation.rel write write);
      (* the coherence order for each maximally split footprint, as a strict partial order over all writes (received by the storage subsystem) that overlap that footprint. We encode the partial order as a set of pairs of writes *)

    (*: the set of writes that have reached their coherence points. :*)
    writes_past_coherence_point : set write ;

    (*: for each thread, the writes that have been propagated to it by the
      storage subsystem, together with the barriers that have been
      propagated to that thread. These are all placed in a
      linear (per-thread) order corresponding to that thread's view of
      time, most recent at the end of the list.  :*)
    events_propagated_to : thread_id -> list tracked_event;

    (*: pairs (w,tid') such that w has not been propagated to tid' :*)
    writes_not_propagated_to : set (write * thread_id);

    (*: the set of [[sync]] barriers that have not yet been acknowledged
        back to their originating thread :*)
    unacknowledged_sync_requests : set barrier;
|>


(**************** flowing events (used in flowing and pop storage subsystems *****)

type flowing_event =
  | FWrite of write
  | FFWrite of read_request * set ioid
  (* the 'slices' of FRead are the unsatisfied slices
  and the 'list (write * slices)' are the satisfied slices.
  The writes might be from write-forwarding and as such they might
  have an unknown value; when comparing with committed write use weiid
  instead of the polymorphic compare as the committed write will have
  a value. *)
  | FRead of read_request * slices * list (write * slices)
  | FBarrier of barrier



instance (Show flowing_event)
  let show = function
  | FWrite w      -> show w
  | FFWrite r _   -> ("W(future, paired with '" ^ show r ^ "')")
  | FRead r _ _   -> show r
  | FBarrier b    -> show b
  end
end

let flowing_eventCompare fe1 fe2 =
  match (fe1,fe2) with
  | (FWrite w1,         FWrite w2)         -> compare w1 w2
  | (FFWrite r1 i1,     FFWrite r2 i2)     ->
      match compare r1 r2 with
      | EQ -> compare (Set_extra.toOrderedList i1) (Set_extra.toOrderedList i2)
      | x -> x
      end
  | (FRead r1 sls1 ws1, FRead r2 sls2 ws2) -> compare (r1, sls1, ws1) (r2, sls2, ws2)
  | (FBarrier b1,       FBarrier b2)       -> compare b1 b2
  | (FWrite _, _)                          -> LT
  | (_, FWrite _)                          -> GT
  | (FFWrite _ _, _)                       -> LT
  | (_, FFWrite _ _)                       -> GT
  | (FRead _ _ _, _)                       -> LT
  | (_, FRead _ _ _)                       -> GT
  (* | (FBarrier _, _)                        -> LT
   * | (_, FBarrier _)                        -> GT *)
  end
(* even with the sets contained in flowing_events ocaml's Pset implementation of sets should
be fine *)

let flowing_eventLess fe1 fe2      = flowing_eventCompare fe1 fe2 =  LT
let flowing_eventLessEq fe1 fe2    = flowing_eventCompare fe1 fe2 <> GT
let flowing_eventGreater fe1 fe2   = flowing_eventCompare fe1 fe2 =  GT
let flowing_eventGreaterEq fe1 fe2 = flowing_eventCompare fe1 fe2 <> LT
(*
let inline {ocaml} flowing_eventLess      = defaultLess
let inline {ocaml} flowing_eventLessEq    = defaultLessEq
let inline {ocaml} flowing_eventGreater   = defaultGreater
let inline {ocaml} flowing_eventGreaterEq = defaultGreaterEq
 *)
instance (Ord flowing_event)
  let compare = flowing_eventCompare
  let (<)  = flowing_eventLess
  let (<=) = flowing_eventLessEq
  let (>)  = flowing_eventGreater
  let (>=) = flowing_eventGreaterEq
end

let {ocaml;coq} flowing_eventEqual fe1 fe2 = compare fe1 fe2 = EQ
(* for Isabelle and HOL the set equality in read_requests is no problem *)
let inline {isabelle;hol} flowing_eventEqual = unsafe_structural_equality

let {ocaml;coq} flowing_eventInequal fe1 fe2 = compare fe1 fe2 <> EQ
(* for Isabelle and HOL the set equality in read_requests is no problem *)
let inline {isabelle;hol} flowing_eventInequal = unsafe_structural_inequality

instance (Eq flowing_event)
  let (=)  = flowing_eventEqual
  let (<>) = flowing_eventInequal
end

instance (SetType flowing_event)
  let setElemCompare = compare
end

let tryFWrite : flowing_event -> maybe write = function
  | FWrite w -> Just w
  | _ -> Nothing
  end

let tryFFWrite : flowing_event -> maybe (read_request * set ioid) = function
  | FFWrite r i -> Just (r, i)
  | _ -> Nothing
  end

let tryFRead : flowing_event -> maybe (read_request * slices * list (write * slices)) = function
  | FRead r s rf -> Just (r, s, rf)
  | _ -> Nothing
  end

let tryFBarrier : flowing_event -> maybe barrier = function
  | FBarrier b -> Just b
  | _ -> Nothing
  end

let unsafeFWrite (e: flowing_event) : write =
  e $> tryFWrite $> Maybe_extra.fromJust

let unsafeFFWrite (e: flowing_event) : (read_request * set ioid) =
  e $> tryFFWrite $> Maybe_extra.fromJust

let unsafeFRead (e: flowing_event) : read_request * slices * list (write * slices) =
  e $> tryFRead $> Maybe_extra.fromJust

let unsafeFBarrier (e: flowing_event) : barrier =
  e $> tryFBarrier $> Maybe_extra.fromJust

let thread_of_flowing_event = function
  | FWrite w      -> w.w_thread
  | FFWrite r _   -> r.r_thread
  | FRead r _ _   -> r.r_thread
  | FBarrier b    -> b.b_thread
  end

let principal_ioid_of_flowing_event = function
  | FWrite w      -> w.w_ioid
  | FFWrite _ _   -> fail
  | FRead rr _ _  -> rr.r_ioid
  | FBarrier b    -> b.b_ioid
  end

let ioid_of_flowing_event = function
  | FWrite w      -> w.w_ioid
  | FFWrite _ _   -> fail
  | FRead rr _ _  -> rr.r_ioid
  | FBarrier b    -> b.b_ioid
  end

let address_of_flowing_event = function
  | FWrite w      -> w.w_addr
  | FFWrite r _   -> r.r_addr
  | FRead r _ _   -> r.r_addr
  | FBarrier _    -> fail
  end

let is_fe_read = function
  | FRead _ _ _-> true
  | _ -> false
  end

let is_fe_read_acquire = function
  | FRead r _ _ -> is_read_acquire r
  | _ -> false
  end

let is_fe_read_exclusive = function
  | FRead r _ _ -> is_read_exclusive r
  | _ -> false
  end

let is_fe_write = function
  | FWrite _ -> true
  | _ -> false
  end

let is_fe_future_write = function
  | FFWrite _ _ -> true
  | _ -> false
  end

let is_fe_write_release = function
  | FWrite w -> is_write_release w
  | _ -> false
  end

let is_fe_write_exclusive = function
  | FWrite w -> is_write_exclusive w
  | _ -> false
  end

let is_fe_read_or_write fe = is_fe_read fe || is_fe_write fe

let is_fe_barrier = function
  | FBarrier _ -> true
  | _ -> false
  end

let is_fe_barrier_ld = function
  | FBarrier b -> is_barrier_ld b
  | _ -> false
  end

let is_fe_barrier_st = function
  | FBarrier b -> is_barrier_st b
  | _ -> false
  end

let is_fe_barrier_lwsync = function
  | FBarrier b -> b.b_barrier_kind = Barrier_LwSync
  | _ -> false
  end

let is_fe_barrier_eieio = function
  | FBarrier b -> b.b_barrier_kind = Barrier_Eieio
  | _ -> false
  end

let is_fe_strong_memory_barrier = function
  | FBarrier b ->
      match b.b_barrier_kind with
      | Barrier_DSB (_, A64_barrier_all) -> true
      | Barrier_DMB (_, A64_barrier_all) -> true
      | Barrier_Sync -> true
      | Barrier_MIPS_SYNC -> true
      | _ -> false
      end
  | _ -> false
  end

(******************** Flowing Storage Subsystem ********************)

type flowing_segment = nat
let flowing_segment_initial : flowing_segment = 0
let flowing_segment_successor segment : flowing_segment = segment + 1

type flowing_tree =
  | FT_join of flowing_segment * (list flowing_tree)

type flowing_storage_subsystem_state =
  <|  (* the set of thread ids that exist in the system *)
      flowing_ss_threads : set thread_id;
      (* the segments topology *)
      flowing_ss_topology : flowing_tree;
      (* associate a segment with each thread *)
      flowing_ss_thread_to_segment : map thread_id flowing_segment;

      (* a map from tree segment to the list of events in that segment
         Invariant: a finite map with domain topology.segments *)
      flowing_ss_buffers : map flowing_segment (list flowing_event);
      (* the pairs of flowing events that have been reordered and so
         should not be reordered again in the current segment.
         the first event in the pair is the event that was newer before
         the reordering. *)
      flowing_ss_reordered : set (flowing_event * flowing_event);

      (* map read_requests of load-exclusives that are paired with store-exclusive
      that is guaranteed to succeed, to the writes they read from, and to the
      write of the paired store exclusive. Initially, when the load-exclusive is
      issued, or when the success of a store-exclusive is guaranteed, we use FFWrite
      to represent the future-write; later, when the write is propagated to storage
      this is replaced with the actual FWrite. *)
      flowing_ss_exclusive_reads: map read_request (list (write * slices) * flowing_event);
      (* map writes of store-exclusives that are guaranteed to succeed,
      to the read_request of the paired load-exclusive; this read_request
      can be found in flowing_ss_exclusive_reads *)
      flowing_ss_exclusive_writes: map write read_request;

      (* the currently visible write-slices in memory;
      invariant: no overlapping slices *)
      flowing_ss_memory_writes : list (write * slices);
      (* record writes that flowed to memory in the order in which they
      flowed (head is new); we need this to reconstruct coherence *)
      flowing_ss_old_writes : list write;
  |>


(******************** Flat Storage Subsystem ********************)
type icache =
  <| ic_memory: list (write * slices);
     ic_tid: thread_id;
  |>

type cache_maintenance_kind =
    | CM_DC
    | CM_IC


type cache_maintenance_request = 
    <| cmr_addr: address;
       cmr_ioid: ioid;
       cmr_cmk: cache_maintenance_kind
    |>


type flat_storage_subsystem_state =
  <|  (* the currently visible write-slices in memory;
      invariant: no overlapping slices *)
      flat_ss_memory_writes : list (write * slices);
      (* the per-thread icache *)
      flat_ss_icaches : map thread_id icache;
      (* set of addresses to be IC'd *)
      flat_ss_ic_writes : map address (cache_maintenance_request * (list thread_id));
      (* the global buffer of writes that can be fetched from *)
      flat_ss_fetch_buf : list write;
      (* record writes that propagated to memory in the order in which they
      propagated (head is new); we need this to reconstruct coherence *)
      flat_ss_old_writes : list write;
      (* map read_requests of load-exclusives that are paired with store-exclusive
      that is guaranteed to succeed, to the writes they read from *)
      flat_ss_exclusive_reads: map read_request (list (write * slices) * set ioid);
  |>

(********************** POP Storage Subsystem **********************)

type pop_storage_subsystem_state =
  <|  (* The set of thread ids that exist in the system. *)
      pop_ss_threads : set thread_id;
      (* The set of events the storage subsystem has seen. *)
      pop_ss_events_seen : map flowing_event (set thread_id);
      (* The order constraints.
      For (e1, e2) IN pop_ss_order_constraints_closure, e1 must be before e2. *)
      (* I tried to handle the transitivity issue of LDAR and DMB LD
      by recording the non-transitive order but it does not work due
      to coherence violations in WWC+poss and RWC+poss *)
      pop_ss_order_constraints_closure : Relation.rel flowing_event flowing_event;

      (* map read_requests of load-exclusives that are paired with store-exclusive
      that is guaranteed to succeed, to the writes they read from *)
      pop_ss_exclusive_reads: map read_request (list (write * slices) * flowing_event);
      (* map writes of store-exclusives that are guaranteed to succeed,
      to the read_request of the paired load-exclusive; this read_request
      can be found in pop_ss_exclusive_reads *)
      pop_ss_exclusive_writes: map write read_request;
  |>

(******************** TSO Storage Subsystem ************************)

type tso_storage_subsystem_state =
  <|  (* a map from thread id to the list of writes in that thread *)
      tso_ss_buffers : map thread_id (list write);

      (* "Just tid" iff thread tid has the lock *)
      tso_ss_lock : maybe thread_id;

      (* the currently visible write-slices in memory;
      invariant: no overlapping slices *)
      tso_ss_memory_writes : list (write * slices);

      (* record writes that flowed to memory in the order in which they
      flowed (head is new); we need this to reconstruct coherence *)
      tso_ss_old_writes : list write;
  |>


(** ********************** instruction instance states **************)

(* we need an explicit type of instruction states (we can't just build
*thread_state* continuations) because the rest of the thread has to be
able to evolve while a read request is outstanding... *)

type fetch_result 'i =
  | Fetched_FDO of fetch_and_decode_outcome 'i  (* for programs without machine code (like litmus tests) *)
  | Fetched_Mem of memory_read_source * fetch_and_decode_outcome 'i

let fdo_from_fetch_result = function
  | Fetched_FDO fdo -> fdo
  | Fetched_Mem _ fdo -> fdo
end


type micro_op_state 'i =
  | MOS_not_fetched
  | MOS_fetched             of fetch_result 'i
  | MOS_wait_IC             of outcome unit
  | MOS_plain               of outcome unit
  | MOS_pending_mem_read    of (memory_value -> outcome unit)
  | MOS_potential_mem_write of (bool -> outcome unit)
  | MOS_AMO_lock            of (memory_value -> outcome unit)
  | MOS_AMO_unlock          of outcome unit
  | MOS_pending_exception   of exception_type 'i
  | MOS_unpredictable

(* misaligned writes must be split into multiple subwrites *)

(* MachineDefThreadSubsystemUtils has utility functions for subreads *)
type subwrites =
  <|  (* the footprint of the whole write, when known *)
      sw_addr : maybe footprint;
      (* sw_potential_write_addresses, sw_potential_writes and sw_propagated_writes
      are mutually exclusive. A write starts its life when the ISA model
      generates a Write_ea outcome. The write is recorded in
      sw_potential_write_addresses with w_value set to Nothing.
      In non-MCA ARM, those writes can already be ("symbolically") forwarded to reads. *)
      sw_potential_write_addresses: list write;
      (* When the ISA model generates a Write_memv w_value is set to the
      appropriate value and the write is moved to sw_potential_writes. *)
      sw_potential_writes: list write;
      (* when the write is propagated to storage it is moved to sw_propagated_writes. *)
      sw_propagated_writes: list write;

      sw_committed: bool;
  |>

let initial_subwrites = 
  <|  sw_addr =                      Nothing;
      sw_potential_write_addresses = [];
      sw_potential_writes =          [];
      sw_propagated_writes =         [];
      sw_committed =                 false;
  |>


let empty_subwrites subwrites = 
  <| subwrites with sw_potential_write_addresses = [];
                    sw_potential_writes =          [];
                    sw_propagated_writes =         []; |>


(* misaligned reads must be split into multiple subreads that can be
satisfied at different points, but with a single thread-state
continuation in the MOS_pending_mem_read for when they have all been
satisfied *)

(* MachineDefThreadSubsystemUtils has utility functions for subreads *)
type subreads =
  <|  (* the footprint of the whole read, when known *)
      sr_addr : maybe footprint;
      (* ASSUME: the domains of sr_unsat_slices and sr_writes_read_from
      are always identical and are the set of all current read requests
      of the instruction *)
      (* map read to its unsatisfied slices *)
      sr_unsat_slices : list (read_request * slices);
      (* map read to the writes it reads from, writes might overlap,
      head covers tail.
      In non-MCA ARM, some writes might have an unknown value due to early
      write-forwarding. The value will be set when we handle the Write_memv
      outcome *)
      sr_writes_read_from : list (read_request * write_slices);
      (* map read to the slices that were requested from storage.
      we don't remove the request even after we get the response. This
      is important for load-acquires: if a write was forwarded to a load-acquire
      that write can be propagated only after the load-acquire token has
      been passed to storage. This is also important for load-exclusive
      when we determine if the paired store-exclusive can be successful *)
      sr_requested : list (read_request * slices);
      (* the assembled memory value, starts from Nothing and changes
      to Just .. after all read requests are fully satisfied *)
      sr_assembled_value : maybe memory_value;
  |>

(* these are the fields of instruction_instance we need for doing a
partial restart of an rmw instruction *)
type rmw_finished_load_snapshot 'i =
  <|  rfls_instance_id_state: id_state ioid;
      rfls_reg_reads:         list (reg_name * register_read_sources * register_value);
      rfls_reg_writes:        list (reg_name * (list register_write_dependency * register_value));
      rfls_micro_op_state:    micro_op_state 'i;
  |>

type instruction_instance 'i =
       <| instance_ioid: ioid; (*: Chosen to make every instance unique :*)
          instance_id_state: id_state ioid; (*: generating unique IDs for events :*)
          program_loc: address;  (*: record fetched address :*)
          program_opcode: maybe opcode;  (*: record fetched opcode :*)
          instruction: instruction 'i; (*:  assembly AST instruction,:*)

          (* statically analysed data about the instruction*)
          instruction_kind: instruction_kind;
          initial_micro_op_state: micro_op_state 'i;
          (* for all instructions except lswx/stswx, the regs_in, regs_out,
              and regs_feeding_address fields will be constant and the
              "initial" variants will be identical.  For lswx, those
              three can change dynamically, and the initial variants
              are kept to properly restart an lswx instruction to its
              initial state*)
          initial_regs_in: set reg_name;         (*: The input registers, for ease of dependency calculation :*)
          initial_regs_out: set reg_name;        (*: The output registers, for ease of dependency calculation :*)
          initial_regs_in_feeding_address: set reg_name;         (*: The input registers that feed into a read or write address :*)
          regs_in: set reg_name;         (*: The input registers, for ease of dependency calculation :*)
          regs_out: set reg_name;        (*: The output registers, for ease of dependency calculation
              Currently in PPC and AArch64, if a register is in regs_out
              eventually it will also be in reg_writes. Hence regs_out
              can be calculated once and safely used for dependency
              calculations.
              regs_out block dependencies as long as
              the instruction is not finished (TODO: should be committed???).
              After the instruction is finished we only use reg_writes.
              A more relaxed model might requier us to recalculate
              regs_out before the instruction is finished  :*)
          regs_in_feeding_address: set reg_name;         (*: The input registers that feed into a read or write address :*)
          ioids_feeding_address: set ioid; (*: the previous instructions that write input registers that feed into a read or write address :*)
          (* invariant: regs_in, regs_out, and ioids_feeding_addresses
              do not include the Power pseudoregisters CIA and NIA *)
          nias: set nia;
          (* the size of nias is greater than 1 iff the instruction is a conditional branch *)
          mips_dia: dia;

          (* dynamic info *)
          (*reg_read_from_ioids: set ioid;  (*: the instructions this instruction has done register reads from :*)*)

          (* reg_reads: accumulated register reads, most recent at head
          (possibly including pseudoregister reads), used for:
          - recalculate_register_footprint
          - track dependencies to register writes *)
          reg_reads: list (reg_name * register_read_sources * register_value);

          (* accumulated register writes, most recent at head (possibly
          including pseudoregister writes to NIA) - subject to restart.
          the 'list register_write_dependency' is used by commitDataflow *)
          reg_writes: list (reg_name * (list register_write_dependency * register_value));

(*SUBSUMED BY writes_read_from??          read_responses : set read_response ; (*: Read responses :*)*)
(*           writes_read_from: set (write*slices);  (*: Tracking writes read from, to determine restart candidates at invalidates. This component starts out empty and evolves through time - subject to restart :*) *)

          subreads:  subreads;
          subwrites: subwrites;

          successful_atomic_store: maybe bool;
            (* after setting to 'Just b' it will never change, not even
            when restarted *)
            (* AArch64: 'true' for committed to succeed; 'false' for
            committed to fail *)
            (* RISC-V: 'true' only after the atomic-store is completed;
            'false' if chosen to fail early or after propagation fails; *)

          committed_barriers: list barrier; (* barriers sent to storage subsystem on commit *)

          finished:  bool; (*: committed and no more microops :*)

          micro_op_state: micro_op_state 'i;  (* evolving over time *)

          rmw_finished_load_snapshot: maybe (rmw_finished_load_snapshot 'i);
    |>


(* NOTE: we compare only the ioid of the instruction!
use 'set instruction_instance' only when you are sure the instructions
are not going to change *)
(* instance forall. (SetType instruction_instance)
 *   let setElemCompare i1 i2 = compare i1.instance_ioid i2.instance_ioid
 * end
 * 
 * instance forall. (Eq instruction_instance)
 *   let (=) inst1 inst2 = inst1.instance_ioid = inst2.instance_ioid
 *   let (<>) inst1 inst2 = not (inst1.instance_ioid = inst2.instance_ioid)
 * end *)


let inline ik ii = ii.instruction_kind


let has_fetched inst =
  inst.micro_op_state <> MOS_not_fetched

let has_decoded inst = 
  match inst.micro_op_state with
  | MOS_not_fetched -> false
  | MOS_fetched _ -> false
  | _ -> true
  end


let ensure_mos_fetched = function
  | MOS_fetched f -> f
  | _ -> fail
end



(** *********************  thread states **********************)

type instruction_tree 'i =
  | T of list (instruction_instance 'i * instruction_tree 'i)

type instruction_tree_context_node 'i (*name="itc*"*) =
  | ITC_node of (list (instruction_instance 'i * instruction_tree 'i))
      * instruction_instance 'i (* context hole *)
      * (list (instruction_instance 'i * instruction_tree 'i))

type instruction_tree_context 'i =
  | ITC_innermost of
      (list (instruction_instance 'i * instruction_tree 'i))
        (* instruction and subtree hole *)
        * (list (instruction_instance 'i * instruction_tree 'i))
        * list (instruction_tree_context_node 'i)
          (* list of the outer left- and right- context pairs, innermost at the head *)

type instruction_prefix 'i =
    list (instruction_instance 'i)
      (* the po-prefix, most recent at the head*)

type instruction_in_context 'i =
   <| iic_instance: instruction_instance 'i;
      context: instruction_tree_context 'i;
      subtree: instruction_tree 'i;
      active_prefix: instruction_prefix 'i (*in-flight or finished*);
      old_prefix: instruction_prefix 'i (*old*);
   |>


type pldi11_thread_substate =
  <| (* Barrier acknowledgements not yet received *)
     unacknowledged_syncs: set barrier;
  |>


type pop_thread_substate =
  <|  (* Track the order in which read_requests are issued (i.e.
      passed to storage). head is the last request that was issued. We use
      the order to determine if a read request needs to be restarted. See
      MP+dmb+pos-fri-rfi-ctrlisb for example.  Also see private notes84: TYPES1 *)
      read_issuing_order : relon read_request;
  |>

type thread_substate =
  | PLDI11_thread of pldi11_thread_substate
  | POP_thread of pop_thread_substate
  | No_substate

let get_pldi11_thread_substate thread =
  match thread with
  | PLDI11_thread thread_substate -> thread_substate
  | _ -> fail
  end

let get_pop_thread_substate thread =
  match thread with
  | POP_thread thread_substate -> thread_substate
  | _ -> fail
  end

(* TODO: register data is in both here and in the isa_info part of thread_params *)
type thread_state 'i =
  <| (* the id of this thread, for reference *)
     thread: thread_id;

     id_state: id_state thread_id;

     (* the address where the thread should end up when execution is
     completed. We use this address to detect when we should stop
     fetching instructions.
     ELF threads will have a return/branch instruction that tries to
     jump to that address;
     This is the address of the last instruction (dummy/end_ins) in litmus
     tests (inserted by translate.ml), the one before last instruction
     will have this address as the successor instruction *)
     return_address: address;

     (* the registers with their direction, width, and initial index *)
     register_data: registerdata;

     (* Map from registers to values *)
     initial_register_state: (reg_base_name -> register_value);
     (* ...replace with a fake multiple-register-write instruction?  *)

     (* the address from which to fetch the first instruction *)
     initial_fetch_address: maybe address; (* Nothing for a thread which has not yet started*)

     (* maximal contiguous prefix of instructions that            *)
     (* (1) have been finished and                                *)
     (* (2) whose successors have all been fetched and            *)
     (* (3) all sync-acks have been received, most-recent at the  *)
     (*     head                                                  *)
     (* ...and we might replace the old ones by fake instructions *)
     (* that just have enough register writes...?                 *)
     old_instructions: list (instruction_instance 'i);

     instruction_tree: instruction_tree 'i;
     (* ...for the above two, it'd be nice to be able to find the *)
     (* right place in the tree without a big search?             *)

     (* the part of the state that is unique to each model *)
     thread_substate: thread_substate;
  |>

(** whole system state *)
(*: \subsection{Whole-system state} :*)


(** ***************   transitions ******************************)

(** storage subsystem transitions *)

(* storage-subsystem initiated transitions that don't involve other subsystems *)
type ss_only_trans =
  (*** PLDI11 transitions: ***)
  | SS_PLDI11_partial_coherence_commit of write * write
  (* TODO: the next 2 are whole writes or fragments? *)
  | SS_PLDI11_propagate_write_to_thread of (write * slices) * thread_id
  | SS_PLDI11_write_reaches_coherence_point of write
  (* TODO: should we be able to do reassembly, so set (set write_fragment) is returned for read requests? *)
  | SS_PLDI11_propagate_barrier_to_thread of barrier * thread_id
  (*** POP transitions: ***)
  | SS_POP_propagate_event_to_thread of flowing_event * thread_id
  | SS_POP_partially_satisfy_read of read_request * list (write * slices)
  (*** Flowing transitions: ***)
  | SS_Flowing_flow_write_to_memory of write
  | SS_Flowing_flow_barrier_to_memory of barrier
  | SS_Flowing_flow_satisfied_read_to_memory of read_request
  | SS_Flowing_reorder_events of flowing_event * flowing_event
  | SS_Flowing_flow_to_segment of flowing_event
  | SS_Flowing_partially_satisfy_read of read_request * list (write * slices)
  (*** TSO transitions: ***)
  | SS_TSO_propagate_write_to_memory of write
  (*** Flat ifetch transitions ***)
  | SS_Flat_icache_update of thread_id * address * (write * slices)

let principal_ioid_of_ss_only_trans = function
  | SS_PLDI11_partial_coherence_commit w1 _      -> Just w1.w_ioid (* or maybe the other one? *)
  | SS_PLDI11_propagate_write_to_thread (w, _) _ -> Just w.w_ioid
  | SS_PLDI11_write_reaches_coherence_point w    -> Just w.w_ioid
  | SS_PLDI11_propagate_barrier_to_thread b _    -> Just b.b_ioid
  | SS_POP_propagate_event_to_thread e tid       -> Just (principal_ioid_of_flowing_event e)
  | SS_POP_partially_satisfy_read r _            -> Just r.r_ioid
  | SS_Flowing_flow_write_to_memory w            -> Just w.w_ioid
  | SS_Flowing_flow_barrier_to_memory b          -> Just b.b_ioid
  | SS_Flowing_flow_satisfied_read_to_memory r   -> Just r.r_ioid
  | SS_Flowing_reorder_events e1 _               -> Just (principal_ioid_of_flowing_event e1)
  | SS_Flowing_flow_to_segment e                 -> Just (principal_ioid_of_flowing_event e)
  | SS_Flowing_partially_satisfy_read r _        -> Just r.r_ioid
  | SS_TSO_propagate_write_to_memory w           -> Just w.w_ioid
  | SS_Flat_icache_update _ _ _                  -> Nothing
  end

(* transitions that are initiated by the storage subsystem but also change the thread state *)
type ss_sync_trans =
  (*** PLDI11 transitions: ***)
  | SS_PLDI11_acknowledge_sync_barrier of barrier
  (*** POP transitions: ***)
  | SS_POP_read_response of read_request * memory_read_source
  (*** Flowing transitions: ***)
  | SS_Flowing_seg_read_response of read_request * memory_read_source
  | SS_Flowing_mem_read_response of read_request * memory_read_source
  (*** Flat transitions ***)
  | SS_Flat_thread_ic of cache_maintenance_request * thread_id
  | SS_Flat_ic_finish of cache_maintenance_request

let tid_of_ss_sync_trans = function
  | SS_PLDI11_acknowledge_sync_barrier b -> b.b_thread
  | SS_POP_read_response rr _            -> rr.r_thread
  | SS_Flowing_seg_read_response rr _    -> rr.r_thread
  | SS_Flowing_mem_read_response rr _    -> rr.r_thread
  | SS_Flat_thread_ic _ tid              -> tid
  | SS_Flat_ic_finish cmr -> fst (cmr.cmr_ioid)
  end

let principal_ioid_of_ss_sync_trans = function
  | SS_PLDI11_acknowledge_sync_barrier b -> b.b_ioid
  | SS_POP_read_response rr _            -> rr.r_ioid
  | SS_Flowing_seg_read_response rr _    -> rr.r_ioid
  | SS_Flowing_mem_read_response rr _    -> rr.r_ioid
  | SS_Flat_thread_ic cmr _ -> cmr.cmr_ioid
  | SS_Flat_ic_finish cmr -> cmr.cmr_ioid
  end

type thread_cont_res 'ts =
  <|  tcr_state:          'ts;
      tcr_inst_restarted: set ioid;
      tcr_inst_discarded: set ioid;
  |>

(* the continuation returns the next thread state and, if needed, the
read-requests that are still active so that the storage-subsystem can
remove the old ones *)
type thread_cont 'answer 'ts =
  <|  tc_tid:  thread_id;
      tc_ioid: ioid;
      tc_cont: 'answer -> thread_cont_res 'ts;
  |>

(* all storage subsystem transitions *)
type ss_trans_t 'ss 'tc =
  | SS_only of ss_only_trans * (unit -> 'ss)
  | SS_sync of ss_sync_trans * (unit -> 'ss) * 'tc (* 'tc: see types below *)

(* when the transition is generated by the storage 'tc is unit; after
the transition is synced with the thread 'tc is the thread continuation *)
type ss_trans 'ss         = ss_trans_t 'ss unit
type sys_ss_trans 'ts 'ss = ss_trans_t 'ss (maybe (thread_cont unit 'ts))

let principal_ioid_of_ss_trans = function
  | SS_only t _   -> principal_ioid_of_ss_only_trans t
  | SS_sync t _ _ -> Just (principal_ioid_of_ss_sync_trans t)
  end

(** thread transitions *)

type fetch_kind =
  | FK_normal (* the fetch is the only successor, and it's fixed, e.g., following
              a non-branch instruction, or following a conditional branch where
              both branches are hard coded to the same target *)
  | FK_multiple_fixed (* the fetch is part of multiple fixed successor, e.g.,
                      following a conditional branch where both branches are
                      hard coded *)
  | FK_unfixed  (* the fetch is part of (potentially) multiple successors
                of which some of them might not be known yet, e.g., following
                a branch register *)

(* memory_write_outcome is what we feed the thread continuation after
committing a write *)
type memory_write_outcome 'a =
  | MWO_successful
  | MWO_unmapped_address of list write  (* trying to access unmapped address *)
  | MWO_exclusive_failed                (* write-exclusive failed *)

type thread_label 'request 'answer 'ts =
  <|  tl_label: 'request;
      tl_suppl: maybe 'answer;
      tl_cont:  thread_cont 'answer 'ts;
  |>

let next_thread_of_tl tl : thread_cont_res 'ts =
  match tl.tl_suppl with
  | Just s  -> tl.tl_cont.tc_cont s
  | Nothing -> fail
  end

type thread_only_trans 'i =
  (** internal transitions: *)
  | T_internal_outcome (* only from interpreter, not shallow embedding? *)
  | T_pending_memory_read_request
  | T_pseudoreg_read      of reg_name * register_value
  | T_pseudoreg_write     of reg_name * register_value
  | T_footprint_outcome
  | T_actually_satisfy    of memory_value
  | T_init_fetch of address * bool  (* (addr, multiple_speculative_successors?) *)
  | T_decode of address * fetch_result 'i
  (** not internal transitions: *)
  | T_register_read       of reg_name * register_read_sources * register_value
  | T_register_write      of reg_name * register_value
  | T_mem_forward_write   of read_request * list (write * slices)
  | T_mem_write_footprint of list write
  | T_mem_potential_write of list write
  | T_finish              of address * 'i
  | T_finish_load_of_rmw
  | T_exception           of exception_type 'i
  | T_commit_store   (* at this point the store is guaranteed to happen *)
  | T_complete_store (* at this point all writes have been propagated to storage *)
  | T_successful_store_excl (* see also T_try_store_excl for when we need the storage *)
  | T_potential_store_cond
  | T_failed_store_excl
  | T_prev_excl_result    of bool
  | T_commit_barrier      of barrier (* commit isb/isync/dmb ld *)
  | T_POP_subsumed_write  of write (* like T_propagate_write but for subsumed writes; after
                                      this transition the write cannot be forwarded *)
  (** although these two transitions are thread-only, they change the
  system lock *)
  | T_RISCV_atomic_begin (* begin the memory access of an AMO *)
  | T_RISCV_atomic_end   (* end the memory access of an AMO *)

let show_thread_only_label = function
  (** internal transitions: *)
  | T_internal_outcome -> "T_internal_outcome"
  | T_pending_memory_read_request -> "T_pending_memory_read_request"
  | T_pseudoreg_read _ _ -> "T_pseudoreg_read"
  | T_pseudoreg_write _ _ -> "T_pseudoreg_write"
  | T_footprint_outcome -> "T_footprint_outcome"
  | T_actually_satisfy _ -> "T_actually_satisfy"
  | T_init_fetch _ _ -> "T_init_fetch"
  | T_decode _ _ -> "T_decode"
  (** not internal transitions: *)
  | T_register_read _ _ _ -> "T_register_read"
  | T_register_write _ _ -> "T_register write"
  | T_mem_forward_write _ _ -> "T_mem_forward_write"
  | T_mem_write_footprint _ -> "T_mem_write_footprint"
  | T_mem_potential_write _ -> "T_mem_potential_write"
  | T_finish _ _ -> "T_finish"
  | T_finish_load_of_rmw -> "T_finish_load_of_rmw"
  | T_exception _ -> "T_exception"
  | T_commit_store -> "T_commit_store"
  | T_complete_store -> "T_complete_store"
  | T_successful_store_excl -> "T_successful_store_Excl"
  | T_potential_store_cond -> "T_potential_store_cont"
  | T_failed_store_excl -> "T_failed_store_excl"
  | T_prev_excl_result  _-> "T_prev_excl_result"
  | T_commit_barrier _ -> "T_commit_barrier"
  | T_POP_subsumed_write _ -> "T_POP_subsumed_write"
  | T_RISCV_atomic_begin -> "T_RISCV_atomic_begin"
  | T_RISCV_atomic_end -> "T_RISCV_atomic_end"
end

(* thread transitions which involve interaction with the storage
subsystem when taken *)
type fetch_request 'i =
    <| fr_addr : address;
       fr_kind : fetch_kind;
       fr_tid : thread_id;
       fr_decode : address -> memory_read_source -> fetch_and_decode_outcome 'i;
    |>



(** NOTE: ALL THE CONSTRUCTORS SHOULD HAVE THE TYPE "thread_label 'l 's" *)
type thread_sync_label 'i 'ts =
  | T_fetch of thread_label
      (fetch_request 'i)
      (fetch_result 'i)  (* the value we fetched *)
      'ts
  | T_propagate_cache_maintenance of thread_label
      cache_maintenance_request
      unit
      'ts
  | T_mem_read_request of thread_label
      (read_request * slices (* the slices we're requesting *)
          * list (write * slices) (* the writes that have previously been forwarded to the read*)
          * maybe (set ioid)) (* for load-exclusive: the set of paired successful store-exclusives *)
      bool (* 'false' for read from unmapped memory *)
      'ts
  | T_propagate_write of thread_label
          (write (* the write itself *)
          * maybe read_request (* maybe an exclusive read_request in case of a write-exclusive  *)
          * list (read_request * list (write * slices) * set ioid)) (* the rf-by-forwarding information *)
      (memory_write_outcome unit)
      'ts
  | T_propagate_barrier of thread_label barrier unit 'ts
  | T_try_store_excl    of thread_label (* see also T_successful_store_excl for when we don't need the storage *)
      (* the maybe: Nothing if the paired read was requested and not satisfied yet;
      subreads.sr_writes_read_from of the paired read if it was requested and satisfied *)
      (read_request * maybe (list (write * slices)) * ioid)
      unit
      'ts
  (*** PLDI11: ***)
  | T_PLDI11_mem_satisfy_read of thread_label (read_request * slices) (list memory_read_source) 'ts
  (* TODO  | T_commit_mem_write_cond *)
  (*** Flat: ***)
  | T_Flat_mem_satisfy_read of thread_label
      (read_request * slices * list (write * slices) * maybe (set ioid))
        (* rr, unsat_slices, rf, paired_stores *)
      (maybe (list memory_read_source)) (* 'Nothing' for read from unmapped memory *)
      'ts
  (* RISC-V-style commit and propagate store-conditional: *)
  | T_Flat_try_commit_store_cond of thread_label
      (write * list (write * slices)) (* the conditional write and the
                                      writes the load-reserve read from *)
      (memory_write_outcome unit)
      'ts
  (*** TSO: ***)
  | T_TSO_mem_satisfy_read of thread_label
      read_request
      (maybe (list memory_read_source)) (* 'Nothing' for read from unmapped memory *)
      'ts

let tid_of_thread_sync_trans = function
  | T_fetch tl                                -> tl.tl_cont.tc_tid
  | T_propagate_cache_maintenance tl          -> tl.tl_cont.tc_tid
  | T_mem_read_request tl                     -> tl.tl_cont.tc_tid
  | T_propagate_write tl                      -> tl.tl_cont.tc_tid
  | T_propagate_barrier tl                    -> tl.tl_cont.tc_tid
  | T_PLDI11_mem_satisfy_read tl              -> tl.tl_cont.tc_tid
  | T_try_store_excl tl                       -> tl.tl_cont.tc_tid
  | T_Flat_mem_satisfy_read tl                -> tl.tl_cont.tc_tid
  | T_Flat_try_commit_store_cond tl           -> tl.tl_cont.tc_tid
  | T_TSO_mem_satisfy_read tl                 -> tl.tl_cont.tc_tid
  end

let ioid_of_thread_sync_trans = function
  | T_fetch tl                                -> tl.tl_cont.tc_ioid
  | T_propagate_cache_maintenance tl          -> tl.tl_cont.tc_ioid
  | T_mem_read_request tl                     -> tl.tl_cont.tc_ioid
  | T_propagate_write tl                      -> tl.tl_cont.tc_ioid
  | T_propagate_barrier tl                    -> tl.tl_cont.tc_ioid
  | T_PLDI11_mem_satisfy_read tl              -> tl.tl_cont.tc_ioid
  | T_try_store_excl tl                       -> tl.tl_cont.tc_ioid
  | T_Flat_mem_satisfy_read tl                -> tl.tl_cont.tc_ioid
  | T_Flat_try_commit_store_cond tl           -> tl.tl_cont.tc_ioid
  | T_TSO_mem_satisfy_read tl                 -> tl.tl_cont.tc_ioid
  end

(* all the thread transitions; this is a union of 'thread_label's with
different specializations, depending on the type of the actual label
and the type of the argument the thread continuation expects *)
(** NOTE: if you need to add transitions that are not in one of the
categories below, maybe you should add a new category; try not to add
orphan transitions, like T_thread_start! *)
type thread_trans_t 'i 'ssc 'ts =
  | T_only         of thread_label (thread_only_trans 'i) unit 'ts
  | T_sync         of thread_sync_label 'i 'ts * 'ssc (* 'ssc: see types below *)
  | T_thread_start of
      thread_label
        (register_value * maybe register_value) (* (opd address, opd toc), only PPCGEN has toc *)
        (maybe thread_id) (* the tid of the new thread *)
        'ts

(* when the transition is generated by the thread 'ssc is unit; after
the transition is synced with storage 'ssc is the storage continuation *)
type thread_trans 'i 'ts         = thread_trans_t 'i unit 'ts
type sys_thread_trans 'i 'ts 'ss = thread_trans_t 'i (maybe (unit -> 'ss)) 'ts

let tid_of_thread_trans = function
  | T_only tl         -> tl.tl_cont.tc_tid
  | T_sync tsl _      -> tid_of_thread_sync_trans tsl
  | T_thread_start tl -> tl.tl_cont.tc_tid
  end

let ioid_of_thread_trans = function
  | T_only tl         -> tl.tl_cont.tc_ioid
  | T_sync tsl _      -> ioid_of_thread_sync_trans tsl
  | T_thread_start tl -> tl.tl_cont.tc_ioid
  end

let is_t_sync = function
  | T_only _ -> false
  | T_sync _ _ -> true
  | T_thread_start _ -> false
  end


(** whole-system states and transitions *)

(* all the system transitions; this is a union of the storage and thread
transitions, with 'tc and 'ssc (respectively) providing extra continuations
for the synced counter part (thread/storage) *)
type trans 'i 'ts 'ss =
  | SS_trans of sys_ss_trans 'ts 'ss
  | T_trans  of sys_thread_trans 'i 'ts 'ss

let principal_ioid_of_trans (t: trans 'i 'ts 'ss) =
  match t with
  | SS_trans t -> principal_ioid_of_ss_trans t
  | T_trans t  -> Just (ioid_of_thread_trans t)
  end
   
let is_storage_transition : trans 'i 'ts 'ss -> bool = function
  | SS_trans _ -> true
  | T_trans _  -> false
  end

let ioid_of_thread_transition : trans 'i 'ts 'ss -> maybe ioid = function
  | SS_trans _ -> Nothing
  | T_trans t  -> Just (ioid_of_thread_trans t)
  end

let is_transition_of_ioid (target_ioid: ioid) (transition: trans 'i 'ts 'ss) : bool =
  ioid_of_thread_transition transition
  $> Maybe.map ((=) target_ioid)
  $> fromMaybe false

let thread_id_of_thread_transition : trans 'i 'ts 'ss -> maybe thread_id = function
  | SS_trans _ -> Nothing
  | T_trans t  -> Just (tid_of_thread_trans t)
  end

let is_transition_of_thread (target_tid : nat) (transition: trans 'i 'ts 'ss) : bool =
  thread_id_of_thread_transition transition
  $> Maybe.map ((=) target_tid)
  $> fromMaybe false

let is_thread_transition = function
  | SS_trans _ -> false
  | T_trans _ -> true
end

(** ***********************  UI auxiliary types ******************)


type ui_trans 'i 'ts 'ss = nat * trans 'i 'ts 'ss
(* not doing change colouration for transitions *)


type pldi11_ui_storage_subsystem_state 'i 'ts 'ss =
  <| ui_threads: list thread_id;
     ui_writes_seen: list (changed2 write);
     ui_coherence: list (changed2 (write*write));
     ui_new_coherence: list (changed3 (footprint * list (changed2 (write*write))));
     ui_writes_past_coherence_point: list (changed2 write) ;
     ui_events_propagated_to: list (thread_id * list (changed2 tracked_event));
     ui_unacknowledged_sync_requests: list (changed3 barrier);
     ui_ss_transitions_pcc: list (ui_trans 'i 'ts 'ss);
     ui_ss_transitions_cp: list (ui_trans 'i 'ts 'ss);
     ui_ss_transitions_prop: list (ui_trans 'i 'ts 'ss);
     ui_ss_transitions_ack_sync: list (ui_trans 'i 'ts 'ss);
  |>

type flowing_ui_storage_subsystem_state 'i 'ts 'ss =
  <|  (* storage state *)
      ui_flowing_ss_threads : list thread_id;
      ui_flowing_ss_topology : flowing_tree;
      ui_flowing_ss_segment_to_thread : flowing_segment -> thread_id;
      ui_flowing_ss_buffers : flowing_segment -> (list (list (ui_trans 'i 'ts 'ss) * flowing_event));
      ui_flowing_ss_reordered : list (changed3 (flowing_event * flowing_event));
      ui_flowing_ss_memory_writes : list (changed3 (write * slices));

      (* storage transitions *)
      ui_flowing_transitions_write_to_mem:           list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_barrier_to_mem:         list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_satisfied_read_to_mem:  list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_reorder:                list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_flow_to_seg:            list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_partially_satisfy_read: list (ui_trans 'i 'ts 'ss);
      ui_flowing_transitions_read_response:          list (ui_trans 'i 'ts 'ss);
  |>

type pop_ui_storage_subsystem_state 'i 'ts 'ss =
  <| (* storage state *)
     ui_pop_ss_threads: list thread_id;
     ui_pop_ss_events_seen: list (changed3 flowing_event);
     ui_pop_ss_order_constraints_closure: list (changed3 (flowing_event * flowing_event));
     ui_pop_ss_events_propagated_to: list (thread_id * list (changed3 flowing_event));
     (*ui_pop_ss_store_exclusive_map: list (changed2 (write * write));*)
     (* storage transitions *)
     ui_pop_ss_transitions_prop_event:             list (ui_trans 'i 'ts 'ss);
     ui_pop_ss_transitions_partially_satisfy_read: list (ui_trans 'i 'ts 'ss);
     ui_pop_ss_transitions_read_response:          list (ui_trans 'i 'ts 'ss);
  |>

type ui_icache =
  <| ui_ic_memory: list (changed3 (write * slices));
     ui_ic_tid: thread_id;
  |>

type flat_ui_storage_subsystem_state 'i 'ts 'ss =
  <|  (* storage state *)
      ui_flat_ss_memory_writes : list (changed3 (write * slices));
      (* storage transitions: none *)
      ui_flat_ss_old_writes : list (changed3 write);
      (* set of addresses to be IC'd *)
      ui_flat_ss_ic_writes : map address (cache_maintenance_request * (list (changed3 thread_id)));
      (* the set of instruction caches *)
      ui_flat_ss_icaches : map thread_id ui_icache;
      (* the global buffer of writes that can be fetched from *)
      ui_flat_ss_fetch_buf : list (changed3 write);
      ui_flat_ss_transitions_icache_update: list (ui_trans 'i 'ts 'ss);
  |>

type tso_ui_storage_subsystem_state 'i 'ts 'ss =
  <|  (* storage state *)
      ui_tso_ss_buffers:                  map thread_id (list write);
      ui_tso_ss_lock:                     changed2b (maybe thread_id);
      ui_tso_ss_memory_writes:            list (changed3 (write * slices));
      (* storage transitions: some *)
      ui_tso_transitions_propagate_write: list (ui_trans 'i 'ts 'ss);
  |>


type ui_storage_subsystem_state 'i 'ts 'ss =
  | PLDI11_UI_storage  of pldi11_ui_storage_subsystem_state 'i 'ts 'ss
  | Flowing_UI_storage of flowing_ui_storage_subsystem_state 'i 'ts 'ss
  | Flat_UI_storage    of flat_ui_storage_subsystem_state 'i 'ts 'ss
  | POP_UI_storage     of pop_ui_storage_subsystem_state 'i 'ts 'ss
  | TSO_UI_storage     of tso_ui_storage_subsystem_state 'i 'ts 'ss


type ui_subwrites =
  <|  ui_sw_addr : maybe footprint;
      ui_sw_potential_write_addresses: list (changed2 write);
      ui_sw_potential_writes : list ((* changed2 *) write);
      ui_sw_propagated_writes: list (changed2 write);
      ui_sw_committed: changed2b bool;
  |>

type ui_subreads =
  <|  ui_sr_addr : maybe footprint;
      ui_sr_unsat_slices : list (read_request * (list (changed3 slice)));
      ui_sr_writes_read_from : list (read_request * (list (changed3 (write * slices))));
      ui_sr_requested : list (read_request * (list (changed3 slice)));
      ui_sr_assembled_value : maybe memory_value;
  |>

type ui_instruction_instance 'i 'ts 'ss =
    <|
    ui_instance_ioid: ioid; 
    ui_program_loc: address; 
    ui_program_opcode: maybe opcode;  
    ui_instruction: instruction 'i;
    ui_instruction_kind: instruction_kind;
    ui_initial_micro_op_state: (micro_op_state 'i);
    ui_regs_in: list (changed3 reg_name);    
    ui_regs_out: list (changed3 reg_name);   
    ui_ioids_feeding_address: list (changed3 ioid);
    ui_nias: list nia;
    ui_dia: dia;
    (*ui_reg_read_from_ioids: list (changed3 ioid);*)
    ui_reg_reads: list (changed3 (reg_name * register_read_sources * register_value));
    ui_reg_writes: list (changed3 (reg_name * register_value)); 
    (*ui_writes_read_from: list (changed3 (write*slices));  *)
    ui_subreads : ui_subreads;
    ui_subwrites : ui_subwrites;
    ui_successful_atomic_store : changed2b (maybe bool);
    ui_committed_barriers: list (changed2 barrier); 
    ui_finished: changed2b bool; 
    ui_micro_op_state: changed2b (micro_op_state 'i);
    (*  ui_show_micro_op_state: bool; *)
    ui_instruction_transitions: list (ui_trans 'i 'ts 'ss); (* the T_only_trans, T_lazy_trans, and TSS_... cases *)
    |>

type ui_instruction_tree 'i 'ts 'ss =
  | UI_T of list ((changed3 (ui_instruction_instance 'i 'ts 'ss)) * (ui_instruction_tree 'i 'ts 'ss))
   (* the above changed3 relates to the existence of the instruction
   instance in the tree; it doesn't record changes internal to the
   state of that instruction *)

type ui_instruction_list 'i 'ts 'ss =
  list (changed3 (ui_instruction_instance 'i 'ts 'ss))

type ui_thread_state 'i 'ts 'ss =
    <|
    ui_thread: thread_id ;           
    ui_register_data: registerdata;
    ui_initial_register_state: (reg_base_name -> register_value);
    ui_initial_fetch_address: changed2b (maybe address);
    (* ui_old_instructions: list (changed2 ui_instruction_instance);  *)
    ui_instruction_tree: ui_instruction_tree 'i 'ts 'ss;

    (* PLDI11_thread: *)
    ui_unacknowledged_syncs: maybe (list (changed3 barrier));
    (* POP_thread: *)
    ui_read_issuing_order: maybe (list (changed3 (read_request * read_request)));
    (* transitions: *)
    ui_initial_fetch_transitions: list (ui_trans 'i 'ts 'ss) (* the initial T_only(T_fetch ...) transition if present *)
    |>

type ui_system_state 'i 'ts 'ss =
  <| ui_program_memory: (address -> fetch_and_decode_outcome 'i);
     ui_initial_writes: list write;
     ui_thread_states: list (thread_id * ui_thread_state 'i 'ts 'ss);
     ui_storage_subsystem: ui_storage_subsystem_state 'i 'ts 'ss;
     ui_model: model_params;
     ui_riscv_AMO_lock: changed2b (maybe ioid);
     ui_transition_history: list (trans 'i 'ts 'ss);
  |>



type threadSubsystem 'i 'ts =

  <| ts_tid : 'ts -> thread_id;
     ts_initial_fetch_address : 'ts -> maybe address;
     ts_initial_reg_state : 'ts -> reg_base_name -> register_value;
     ts_instruction_tree : 'ts -> list (instruction_instance 'i) * instruction_tree 'i;
     ts_final_reg_state : 'ts -> list (reg_base_name * maybe register_value);
     ts_update_initial_register_state : 'ts -> list (reg_base_name * register_value) -> 'ts;
     ts_update_initial_fetch_address : 'ts -> address -> 'ts;

     ts_is_final_state : 'ts -> bool;

     ts_initial_thread_state :
       thread_params ->
       thread_id ->
       address ->
       registerdata ->
       (reg_base_name -> register_value) ->
       maybe address ->
       'ts;

     ts_return_address : 'ts -> address;

     ts_enumerate_transitions_of_thread: thread_params -> isa 'i -> 'ts -> list (thread_trans 'i 'ts);

     ts_receive_transition : thread_params -> isa 'i -> 'ts -> ss_sync_trans -> maybe (thread_cont unit 'ts)

  |>


type storageSubsystem 'i 'ts 'ss =
  <| ss_initial_state : ss_params  -> set thread_id -> list write -> 'ss ;
     ss_is_final_state : ss_params -> 'ss -> bool;
     ss_coherence : ss_params -> 'ss -> Relation.rel write write;
     ss_thread_memory_value_of_footprint : ss_params ->
       'ss -> thread_id -> footprint -> memory_value;
     ss_clean_reads : ss_params -> 'ss -> thread_id -> set ioid -> set ioid -> maybe 'ss;

     ss_enumerate_transitions : ss_params -> 'ss -> list (ss_trans 'ss);

     ss_receive_transition : isa 'i -> ss_params ->
       'ss -> thread_sync_label 'i 'ts ->
       (* no-one except Flat returns more than one *)
       list (thread_sync_label 'i 'ts * maybe (unit -> 'ss));

     ss_make_ui_storage_state : 
       maybe 'ss -> 'ss -> list (ui_trans 'i 'ts 'ss) -> 
       ui_storage_subsystem_state 'i 'ts 'ss;
  |>
     

type system_state 'i 'ts 'ss =
  <| program_memory:        (address -> fetch_and_decode_outcome 'i);
     initial_writes:        list write;
     thread_states:         map thread_id 'ts;
     storage_subsystem:     'ss;
     model:                 model_params;
     isa:                   isa 'i;
     t_model:               threadSubsystem 'i 'ts;
     s_model:               storageSubsystem 'i 'ts 'ss;
     transition_history:    list (trans 'i 'ts 'ss);    (* most recent first *)
      (* recording the transition history might have a bad effect on performance; we'll see *)

     riscv_AMO_lock:        maybe ioid;
  |>




type system_state_and_transitions 'i 'ts 'ss =
  <| sst_state:               system_state 'i 'ts 'ss;
     sst_system_transitions:  list (trans 'i 'ts 'ss);
     sst_storage_transitions: list (ss_trans 'ss);
     sst_thread_transitions:  map thread_id (list (thread_trans 'i 'ts));
     sst_sys_thread_transitions:  map thread_id (list (trans 'i 'ts 'ss * bool));

     (* the following are true iff the transition leading to sst_state
     included instruction restarts or discarded instructions (respectively) *)
     sst_inst_restarted:      bool;
     sst_inst_discarded:      bool;
  |>




